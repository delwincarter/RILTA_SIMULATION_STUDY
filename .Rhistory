theme(
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.minor.y = element_blank(),
axis.text.x = element_text(size = 8),
axis.ticks = element_line(color = "black", linewidth = 0.5),
legend.position = "bottom",
legend.title = element_blank(),
text = element_text(family = "Times New Roman"),
axis.title.x = element_text(margin = margin(t = 10, b = 10)),
legend.margin = margin(t = -10),
plot.caption = element_text(hjust = 0, margin = margin(t = 10))
)
create_plot <- function(data, title_suffix) {
# Detect which legend items to show
present_categories <- c("Parameter Bias", "Standard Error Bias")  # Base categories
if (any(data$Coverage_Dic == 0)) present_categories <- c(present_categories, "Coverage Failure")
if (any(data$Power_Dic == 0)) present_categories <- c(present_categories, "Power Failure")
# Define colors and shapes for different categories
colors <- c("Parameter Bias" = "#7030A0", "Standard Error Bias" = "#C830CC",
"Coverage Failure" = "#7030A0", "Power Failure" = "black")
shapes <- c("Parameter Bias" = 16, "Standard Error Bias" = 18,
"Coverage Failure" = 1, "Power Failure" = 4)
# Filter colors and shapes based on detected categories
filtered_colors <- colors[present_categories]
filtered_shapes <- shapes[present_categories]
base_plot <- ggplot(data, aes(x = Lambda, y = Parameter_Bias, color = "Parameter Bias", group = Population_Label)) +
geom_line(aes(group = Population_Label), linewidth = .7, linetype = "solid") +
geom_line(aes(y = SE_Bias, group = Population_Label, color = "Standard Error Bias"), linewidth = .7, linetype = "solid") +
geom_point(aes(y = Parameter_Bias), shape = shapes["Parameter Bias"], size = 1.5, fill = colors["Parameter Bias"], alpha = 1) +
geom_point(aes(y = SE_Bias, color = "Standard Error Bias"), shape = shapes["Standard Error Bias"], size = 2, fill = colors["Standard Error Bias"], alpha = 1) +
geom_point(data = subset(data, Coverage_Dic == 0), aes(y = Parameter_Bias, color = "Coverage Failure"), shape = shapes["Coverage Failure"], size = 2.5, fill = colors["Coverage Failure"], alpha = 1) +
geom_point(data = subset(data, Power_Dic == 0), aes(y = Parameter_Bias, color = "Power Failure"), shape = shapes["Power Failure"], size = 2, fill = colors["Power Failure"], alpha = 1) +
scale_color_manual(values = filtered_colors, labels = present_categories, breaks = present_categories, guide = guide_legend(override.aes = list(shape = filtered_shapes))
) +
labs(
x = "Lambda Loadings on the RI",
y = "Bias (%)",
color = "",
title = paste("RILTA Generated, LTA Analyzed with", title_suffix, "Transition Probabilities")
) +
facet_grid(Population_Label ~ N, scales = "free_x", labeller = label_parsed) +
scale_x_continuous(breaks = seq(0, 3, by = 0.5), labels = scales::number_format(accuracy = 0.1)) +
common_theme +
geom_hline(yintercept = c(-10, 10), linetype = "dashed", color = "#7030A0", linewidth = 0.4) +
geom_hline(yintercept = c(-5, 5), linetype = "dashed", color = "#C830CC", linewidth = 0.4)
# Set y-axis limits based on the plot type
if (title_suffix == "Stayer") {
base_plot <- base_plot + scale_y_continuous(limits = c(-20, 20), breaks = seq(-20, 20, by = 10))
} else {  # Assume "Mover"
# Manually specify breaks to include 160
base_plot <- base_plot + scale_y_continuous(limits = c(-20, 20), breaks = seq(-20, 20, by = 10))
}
return(base_plot)
}
# Create and print plot for Mover
plot_mover <- create_plot(subset_mover, "Mover")
#| column: screen
#| fig-format: svg
print(plot_mover)
# Remove title for the saved version
plot_mover_no_title <- plot_mover + labs(title = NULL)
# Save Mover plot without title as .svg
ggsave(here('Simulations', 'STUDY_1', '3 Time Points', "zFigures", "x3t_rilta_rilta_plots", "plot_mover.svg"), plot = plot_mover_no_title, width = 6, height = 3, dpi = 300, device = "svg")
# Create and print plot for Stayer
plot_stayer <- create_plot(subset_stayer, "Stayer")
#| column: screen
#| fig-format: svg
print(plot_stayer)
# Remove title for the saved version
plot_stayer_no_title <- plot_stayer + labs(title = NULL)
# Save Stayer plot without title as .svg
ggsave(here('Simulations', 'STUDY_1', '3 Time Points', "zFigures", "x3t_rilta_rilta_plots", "plot_stayer.svg"), plot = plot_stayer_no_title, width = 6, height = 3, dpi = 300, device = "svg")
#| label: "summarize-errors"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
library(parallel)
extract_errors_from_file <- function(filepath, total_replications) {
lines <- readLines(filepath)
results <- vector("list", total_replications)
error_keywords <- c("NON-POSITIVE DEFINITE", "SADDLE")
# Initialize results for every replication
for (rep in 1:total_replications) {
results[[rep]] <- tibble(
FileName = basename(filepath),
Replication = rep,
Message = "None",
MessageType = "None"
)
}
current_replication <- NULL
for (line in lines) {
if (str_detect(line, "REPLICATION")) {
current_replication <- as.integer(str_extract(line, "\\d+"))
}
if (!is.null(current_replication) && current_replication <= total_replications &&
any(sapply(error_keywords, grepl, line, ignore.case = TRUE))) {
results[[current_replication]] <- tibble(
FileName = basename(filepath),
Replication = current_replication,
Message = str_trim(line),
MessageType = "Error"
)
}
}
return(bind_rows(results))
}
# Step 2: Extract Completed Replications
extract_completed_replications <- function(filepath) {
lines <- readLines(filepath)
completed_line <- lines[grepl("Completed", lines, ignore.case = TRUE)]
completed <- as.integer(str_match(completed_line, "Completed\\s+(\\d+)")[, 2])
if (length(completed) == 0) completed <- 0
tibble(FileName = basename(filepath), CompletedReplications = completed)
}
# Step 3: Extract Requested Replications
extract_requested_replications <- function(filepath) {
lines <- readLines(filepath)
requested_line <- lines[grepl("Requested", lines, ignore.case = TRUE)]
requested <- as.integer(str_match(requested_line, "Requested\\s+(\\d+)")[, 2])
if (length(requested) == 0) requested <- 0
tibble(FileName = basename(filepath), RequestedReplications = requested)
}
calculate_replication_summary <- function(error_summary, completed_replications, requested_replications) {
summary <- error_summary %>%
group_by(FileName) %>%
summarise(
ErrorReplications = n_distinct(Replication[MessageType == "Error"]),
.groups = "drop"
)
full_summary <- requested_replications %>%
left_join(completed_replications, by = "FileName") %>%
left_join(summary, by = "FileName") %>%
mutate(
ErrorReplications = coalesce(ErrorReplications, 0),
GoodReplications = CompletedReplications - ErrorReplications,
ErrorRate = if_else(CompletedReplications > 0, (ErrorReplications / CompletedReplications) * 100, 0)
) %>%
select(FileName, RequestedReplications, CompletedReplications, ErrorReplications, GoodReplications, ErrorRate)
full_summary
}
# Step 4: Parallelized Processing (Windows/Mac/Linux Compatible)
output_folder <- here('Simulations', 'STUDY_1', '2 Time Points', "1_2T_LTA_GEN_LTA_ANALYZED")  # Adjust to your folder path
#| label: "load-libraries"
#| echo: true
#| message: false
#| warning: false
library(tidyverse)
library(MplusAutomation)
library(here)
library(gt)
library(janitor)
library(glue)
library(ggtext)
library(rlang)
library(knitr)
library(kableExtra)
library(parallel)
library(tools)
#| label: "summarize-errors"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
library(parallel)
extract_errors_from_file <- function(filepath, total_replications) {
lines <- readLines(filepath)
results <- vector("list", total_replications)
error_keywords <- c("NON-POSITIVE DEFINITE", "SADDLE")
# Initialize results for every replication
for (rep in 1:total_replications) {
results[[rep]] <- tibble(
FileName = basename(filepath),
Replication = rep,
Message = "None",
MessageType = "None"
)
}
current_replication <- NULL
for (line in lines) {
if (str_detect(line, "REPLICATION")) {
current_replication <- as.integer(str_extract(line, "\\d+"))
}
if (!is.null(current_replication) && current_replication <= total_replications &&
any(sapply(error_keywords, grepl, line, ignore.case = TRUE))) {
results[[current_replication]] <- tibble(
FileName = basename(filepath),
Replication = current_replication,
Message = str_trim(line),
MessageType = "Error"
)
}
}
return(bind_rows(results))
}
# Step 2: Extract Completed Replications
extract_completed_replications <- function(filepath) {
lines <- readLines(filepath)
completed_line <- lines[grepl("Completed", lines, ignore.case = TRUE)]
completed <- as.integer(str_match(completed_line, "Completed\\s+(\\d+)")[, 2])
if (length(completed) == 0) completed <- 0
tibble(FileName = basename(filepath), CompletedReplications = completed)
}
# Step 3: Extract Requested Replications
extract_requested_replications <- function(filepath) {
lines <- readLines(filepath)
requested_line <- lines[grepl("Requested", lines, ignore.case = TRUE)]
requested <- as.integer(str_match(requested_line, "Requested\\s+(\\d+)")[, 2])
if (length(requested) == 0) requested <- 0
tibble(FileName = basename(filepath), RequestedReplications = requested)
}
calculate_replication_summary <- function(error_summary, completed_replications, requested_replications) {
summary <- error_summary %>%
group_by(FileName) %>%
summarise(
ErrorReplications = n_distinct(Replication[MessageType == "Error"]),
.groups = "drop"
)
full_summary <- requested_replications %>%
left_join(completed_replications, by = "FileName") %>%
left_join(summary, by = "FileName") %>%
mutate(
ErrorReplications = coalesce(ErrorReplications, 0),
GoodReplications = CompletedReplications - ErrorReplications,
ErrorRate = if_else(CompletedReplications > 0, (ErrorReplications / CompletedReplications) * 100, 0)
) %>%
select(FileName, RequestedReplications, CompletedReplications, ErrorReplications, GoodReplications, ErrorRate)
full_summary
}
# Step 4: Parallelized Processing (Windows/Mac/Linux Compatible)
output_folder <- here('Simulations', 'STUDY_1', '2 Time Points', "1_2T_LTA_GEN_LTA_ANALYZED")  # Adjust to your folder path
file_list <- list.files(output_folder, pattern = "\\.out$", full.names = TRUE)
# Step 5: Detect OS and Set Up Cluster
cluster_type <- ifelse(.Platform$OS.type == "windows", "PSOCK", "FORK")
num_cores <- detectCores() - 1  # Use all but one core
cl <- makeCluster(num_cores, type = cluster_type)
# Export necessary libraries and functions to the cluster
invisible(clusterExport(cl, c("extract_errors_from_file", "extract_completed_replications", "extract_requested_replications")))
invisible(clusterEvalQ(cl, library(tidyverse)))
# Step 6: Parallel Processing
# Calculate completed replications first
completed_rep_list <- parLapply(cl, file_list, extract_completed_replications)
# Extract errors while passing the total number of completed replications to the function
error_summary <- bind_rows(mapply(function(filepath, completed_data) {
extract_errors_from_file(filepath, completed_data$CompletedReplications)
}, file_list, completed_rep_list, SIMPLIFY = FALSE))
completed_replications <- bind_rows(parLapply(cl, file_list, extract_completed_replications))
requested_replications <- bind_rows(parLapply(cl, file_list, extract_requested_replications))
# Stop the cluster
stopCluster(cl)
# Step 7: Calculate Replication Summary
replication_summary <- calculate_replication_summary(error_summary, completed_replications, requested_replications)
# Step 8: Create and Display the Table with Error Rate
replication_summary_table <- replication_summary %>%
gt() %>%
tab_header(
title = "Replication Summary",
subtitle = paste0("Folder: ", output_folder)
) %>%
fmt_number(columns = c(CompletedReplications, RequestedReplications, ErrorReplications, GoodReplications, ErrorRate), decimals = 2) %>%
cols_label(
FileName = "File Name",
CompletedReplications = "Completed Replications",
RequestedReplications = "Requested Replications",
ErrorReplications = "Replications with Errors",
GoodReplications = "Good Replications",
ErrorRate = "Error Rate (%)"
) %>%
tab_options(
table.font.size = "small",
heading.title.font.size = "medium",
heading.subtitle.font.size = "small"
)
# Display the table
replication_summary_table
completed_replications <- completed_replications %>%
mutate(FileName = str_replace(FileName, "\\.out$", ""),
FileName = tolower(FileName),
FileName = str_trim(FileName))
error_summary <- error_summary %>%
mutate(FileName = str_replace(FileName, "\\.out$", ""),
FileName = tolower(FileName),
FileName = str_trim(FileName))
final_data_with_actuals <- final_data_with_actuals %>%
mutate(FileName = tolower(FileName),
FileName = str_trim(FileName))
replication_summary <- replication_summary %>%
mutate(FileName = str_replace(FileName, "\\.out$", ""),
FileName = tolower(FileName),
FileName = str_trim(FileName))
cat("Rows in final_data_with_actuals:", nrow(final_data_with_actuals), "\n")
# Output the final number of rows to confirm data handling
cat("Number of rows in error_summary: ", nrow(error_summary), "\n")
cat("Number of rows in replication_summary: ", nrow(replication_summary), "\n")
#| label: "combine-csv-files-parallel"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
# Step 1: Set the correct CSV directory
csv_directory <- here('Simulations', 'STUDY_1', '2 Time Points', '1_2T_LTA_GEN_LTA_ANALYZED')
# Step 2: Source the child document
source(here('Child_Docs', 'data_scraping.R'))
#| label: "scrape-rows-process-data-parallel"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
# Step 2: Process the data using the child script
source(here('Child_Docs', 'step2_2t_LTA.R'))
#| label: "convert-logits-to-probabilities"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
# Step 3 and 4: Process the data and return results
source(here('Child_Docs', 'step_3.R'))
# The objects `final_data_with_actuals` and `violators` should now be in the global environment
#| label: "summarize-errors"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
library(parallel)
extract_errors_from_file <- function(filepath, total_replications) {
lines <- readLines(filepath)
results <- vector("list", total_replications)
error_keywords <- c("NON-POSITIVE DEFINITE", "SADDLE")
# Initialize results for every replication
for (rep in 1:total_replications) {
results[[rep]] <- tibble(
FileName = basename(filepath),
Replication = rep,
Message = "None",
MessageType = "None"
)
}
current_replication <- NULL
for (line in lines) {
if (str_detect(line, "REPLICATION")) {
current_replication <- as.integer(str_extract(line, "\\d+"))
}
if (!is.null(current_replication) && current_replication <= total_replications &&
any(sapply(error_keywords, grepl, line, ignore.case = TRUE))) {
results[[current_replication]] <- tibble(
FileName = basename(filepath),
Replication = current_replication,
Message = str_trim(line),
MessageType = "Error"
)
}
}
return(bind_rows(results))
}
# Step 2: Extract Completed Replications
extract_completed_replications <- function(filepath) {
lines <- readLines(filepath)
completed_line <- lines[grepl("Completed", lines, ignore.case = TRUE)]
completed <- as.integer(str_match(completed_line, "Completed\\s+(\\d+)")[, 2])
if (length(completed) == 0) completed <- 0
tibble(FileName = basename(filepath), CompletedReplications = completed)
}
# Step 3: Extract Requested Replications
extract_requested_replications <- function(filepath) {
lines <- readLines(filepath)
requested_line <- lines[grepl("Requested", lines, ignore.case = TRUE)]
requested <- as.integer(str_match(requested_line, "Requested\\s+(\\d+)")[, 2])
if (length(requested) == 0) requested <- 0
tibble(FileName = basename(filepath), RequestedReplications = requested)
}
calculate_replication_summary <- function(error_summary, completed_replications, requested_replications) {
summary <- error_summary %>%
group_by(FileName) %>%
summarise(
ErrorReplications = n_distinct(Replication[MessageType == "Error"]),
.groups = "drop"
)
full_summary <- requested_replications %>%
left_join(completed_replications, by = "FileName") %>%
left_join(summary, by = "FileName") %>%
mutate(
ErrorReplications = coalesce(ErrorReplications, 0),
GoodReplications = CompletedReplications - ErrorReplications,
ErrorRate = if_else(CompletedReplications > 0, (ErrorReplications / CompletedReplications) * 100, 0)
) %>%
select(FileName, RequestedReplications, CompletedReplications, ErrorReplications, GoodReplications, ErrorRate)
full_summary
}
# Step 4: Parallelized Processing (Windows/Mac/Linux Compatible)
output_folder <- here('Simulations', 'STUDY_1', '2 Time Points', "1_2T_LTA_GEN_LTA_ANALYZED")  # Adjust to your folder path
file_list <- list.files(output_folder, pattern = "\\.out$", full.names = TRUE)
# Step 5: Detect OS and Set Up Cluster
cluster_type <- ifelse(.Platform$OS.type == "windows", "PSOCK", "FORK")
num_cores <- detectCores() - 1  # Use all but one core
cl <- makeCluster(num_cores, type = cluster_type)
# Export necessary libraries and functions to the cluster
invisible(clusterExport(cl, c("extract_errors_from_file", "extract_completed_replications", "extract_requested_replications")))
invisible(clusterEvalQ(cl, library(tidyverse)))
# Step 6: Parallel Processing
# Calculate completed replications first
completed_rep_list <- parLapply(cl, file_list, extract_completed_replications)
# Extract errors while passing the total number of completed replications to the function
error_summary <- bind_rows(mapply(function(filepath, completed_data) {
extract_errors_from_file(filepath, completed_data$CompletedReplications)
}, file_list, completed_rep_list, SIMPLIFY = FALSE))
completed_replications <- bind_rows(parLapply(cl, file_list, extract_completed_replications))
requested_replications <- bind_rows(parLapply(cl, file_list, extract_requested_replications))
# Stop the cluster
stopCluster(cl)
# Step 7: Calculate Replication Summary
replication_summary <- calculate_replication_summary(error_summary, completed_replications, requested_replications)
# Step 8: Create and Display the Table with Error Rate
replication_summary_table <- replication_summary %>%
gt() %>%
tab_header(
title = "Replication Summary",
subtitle = paste0("Folder: ", output_folder)
) %>%
fmt_number(columns = c(CompletedReplications, RequestedReplications, ErrorReplications, GoodReplications, ErrorRate), decimals = 2) %>%
cols_label(
FileName = "File Name",
CompletedReplications = "Completed Replications",
RequestedReplications = "Requested Replications",
ErrorReplications = "Replications with Errors",
GoodReplications = "Good Replications",
ErrorRate = "Error Rate (%)"
) %>%
tab_options(
table.font.size = "small",
heading.title.font.size = "medium",
heading.subtitle.font.size = "small"
)
# Display the table
replication_summary_table
completed_replications <- completed_replications %>%
mutate(FileName = str_replace(FileName, "\\.out$", ""),
FileName = tolower(FileName),
FileName = str_trim(FileName))
error_summary <- error_summary %>%
mutate(FileName = str_replace(FileName, "\\.out$", ""),
FileName = tolower(FileName),
FileName = str_trim(FileName))
final_data_with_actuals <- final_data_with_actuals %>%
mutate(FileName = tolower(FileName),
FileName = str_trim(FileName))
replication_summary <- replication_summary %>%
mutate(FileName = str_replace(FileName, "\\.out$", ""),
FileName = tolower(FileName),
FileName = str_trim(FileName))
cat("Rows in final_data_with_actuals:", nrow(final_data_with_actuals), "\n")
# Output the final number of rows to confirm data handling
cat("Number of rows in error_summary: ", nrow(error_summary), "\n")
cat("Number of rows in replication_summary: ", nrow(replication_summary), "\n")
# Set the directory containing your files
file_directory <- here("Simulations", 'STUDY_1', '2 Time Points', '1_2T_LTA_GEN_LTA_ANALYZED')
# Load the here package
library(here)
# Set the directory containing your files
file_directory <- here("Simulations", 'STUDY_1', '2 Time Points', '1_2T_LTA_GEN_LTA_ANALYZED')
# List all files in the directory
files <- list.files(path = file_directory, full.names = TRUE)
# Function to modify filenames
rename_files <- function(full_path) {
# Extract filename from full path
filename <- basename(full_path)
# Convert filename to lowercase
new_filename <- tolower(filename)
# Replace "TH =" with "th_" and remove spaces around it
new_filename <- gsub("th = ", "th_", new_filename)
new_filename <- gsub(" =", "_", new_filename)
# Remove "_wd" at the end before the file extension
new_filename <- gsub("_wd\\.out$", ".out", new_filename)
new_filename <- gsub("_wd\\.inp$", ".inp", new_filename)
new_filename <- gsub("_wd\\.csv$", ".csv", new_filename)
# Full path of the new file
new_full_path <- file.path(dirname(full_path), new_filename)
# Rename the file
file.rename(full_path, new_full_path)
}
# Apply the function to each file
sapply(files, rename_files)
# Load the here package
library(here)
# Set the directory containing your files
file_directory <- here("Simulations", 'STUDY_1', '2 Time Points', '1_2T_LTA_GEN_LTA_ANALYZED_REP')
# List all files in the directory
files <- list.files(path = file_directory, full.names = TRUE)
# Function to modify filenames
rename_files <- function(full_path) {
# Extract filename from full path
filename <- basename(full_path)
# Convert filename to lowercase
new_filename <- tolower(filename)
# Replace "TH =" with "th_" and remove spaces around it
new_filename <- gsub("th = ", "th_", new_filename)
new_filename <- gsub(" =", "_", new_filename)
# Remove "_wd" at the end before the file extension
new_filename <- gsub("_wd\\.out$", ".out", new_filename)
new_filename <- gsub("_wd\\.inp$", ".inp", new_filename)
new_filename <- gsub("_wd\\.csv$", ".csv", new_filename)
# Full path of the new file
new_full_path <- file.path(dirname(full_path), new_filename)
# Rename the file
file.rename(full_path, new_full_path)
}
# Apply the function to each file
sapply(files, rename_files)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, tidy.opts=list(width.cutoff=60))
# Step 1: Read the output file
output <- readLines(here("enum", "c3_bully.out"), warn = FALSE)
