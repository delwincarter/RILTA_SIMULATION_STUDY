# Filter out rows with errors using error_results
final_data_with_actuals <- final_data_with_actuals %>%
anti_join(
error_results %>% filter(ErrorFlag == 1) %>% select(FileName, Rep),
by = c("FileName", "Rep")
)
# Sanity check to confirm no errors remain
error_check <- final_data_with_actuals %>%
semi_join(
error_results %>% filter(ErrorFlag == 1) %>% select(FileName, Rep),
by = c("FileName", "Rep")
)
if (nrow(error_check) > 0) {
warning("Some error rows were not successfully removed.")
} else {
message("Error rows successfully removed. Proceeding with clean data.")
}
View(final_data_with_actuals)
cat("Rows in final_data_with_actuals (before deletion):", nrow(final_data_with_actuals), "\n")
cat("Rows in error_results:", nrow(error_results), "\n")
cat("Error cases in error_results:", nrow(error_results %>% filter(ErrorFlag == 1)), "\n")
# Ensure matching column types
final_data_with_actuals <- final_data_with_actuals %>%
mutate(Rep = as.character(Rep))
error_results <- error_results %>%
mutate(Rep = as.character(Rep))
# Remove rows with errors
final_data_with_actuals <- final_data_with_actuals %>%
anti_join(
error_results %>% filter(ErrorFlag == 1),
by = c("FileName", "Rep")
)
# Validate the updated row count
cat("Rows in final_data_with_actuals (before deletion):", 138832, "\n") # Original dataset row count
cat("Rows in error_results:", nrow(error_results), "\n")               # Error dataset row count
cat("Rows in final_data_with_actuals (after deletion):", nrow(final_data_with_actuals), "\n")
# Check if any error cases remain
remaining_errors <- final_data_with_actuals %>%
semi_join(
error_results %>% filter(ErrorFlag == 1),
by = c("FileName", "Rep")
)
if (nrow(remaining_errors) > 0) {
warning("Some error rows were not successfully removed:")
print(remaining_errors)
} else {
message("All error rows successfully removed.")
}
# Ensure matching column types
final_data_with_actuals <- final_data_with_actuals %>%
mutate(Rep = as.character(Rep))
error_results <- error_results %>%
mutate(Rep = as.character(Rep))
# Check the number of error rows in error_results
cat("Number of error rows in error_results:", sum(error_results$ErrorFlag == 1), "\n")
# Check if there are any matching rows in final_data_with_actuals that should be removed
matching_rows <- final_data_with_actuals %>%
semi_join(
error_results %>% filter(ErrorFlag == 1),
by = c("FileName", "Rep")
)
cat("Number of matching rows to remove:", nrow(matching_rows), "\n")
# Now remove the error rows
final_data_with_actuals <- final_data_with_actuals %>%
anti_join(
error_results %>% filter(ErrorFlag == 1),
by = c("FileName", "Rep")
)
# Validate the updated row count
cat("Rows in final_data_with_actuals (before deletion):", 138832, "\n") # Original dataset row count
cat("Rows in error_results:", nrow(error_results), "\n")               # Error dataset row count
cat("Rows in final_data_with_actuals (after deletion):", nrow(final_data_with_actuals), "\n")
# Check if any error cases remain
remaining_errors <- final_data_with_actuals %>%
semi_join(
error_results %>% filter(ErrorFlag == 1),
by = c("FileName", "Rep")
)
if (nrow(remaining_errors) > 0) {
warning("Some error rows were not successfully removed:")
print(remaining_errors)
} else {
message("All error rows successfully removed.")
}
# Check ErrorFlag in final_data_with_actuals
cat("Unique values of ErrorFlag in final_data_with_actuals:", unique(final_data_with_actuals$ErrorFlag), "\n")
# Check ErrorFlag in error_results
cat("Unique values of ErrorFlag in error_results:", unique(error_results$ErrorFlag), "\n")
cat("Type of Rep in final_data_with_actuals:", typeof(final_data_with_actuals$Rep), "\n")
cat("Type of Rep in error_results:", typeof(error_results$Rep), "\n")
# Test the anti_join without filtering for errors
final_data_check <- final_data_with_actuals %>%
anti_join(error_results, by = c("FileName", "Rep"))
# Check the number of rows after the join
cat("Rows after anti_join (no error filtering):", nrow(final_data_check), "\n")
# Remove error rows by joining with error_results (only rows where ErrorFlag == 1)
final_data_with_actuals_cleaned <- final_data_with_actuals %>%
anti_join(
error_results %>% filter(ErrorFlag == 1),
by = c("FileName", "Rep")
)
# Check the number of rows after deletion
cat("Rows in final_data_with_actuals after deleting errors:", nrow(final_data_with_actuals_cleaned), "\n")
# Check if there are still error rows in final_data_with_actuals_cleaned
remaining_errors <- final_data_with_actuals_cleaned %>%
semi_join(
error_results %>% filter(ErrorFlag == 1),
by = c("FileName", "Rep")
)
if (nrow(remaining_errors) > 0) {
warning("Some error rows were not successfully removed:")
print(remaining_errors)
} else {
message("All error rows successfully removed.")
}
# Check for duplicates in final_data_with_actuals
cat("Number of duplicates in final_data_with_actuals:", nrow(final_data_with_actuals) - nrow(unique(final_data_with_actuals)), "\n")
# Check for duplicates in error_results
cat("Number of duplicates in error_results:", nrow(error_results) - nrow(unique(error_results)), "\n")
# Remove '.out' from the 'FileName' column in both datasets
final_data_with_actuals <- final_data_with_actuals %>%
mutate(FileName = str_remove(FileName, "\\.out$"))  # Remove '.out' at the end of the string
error_results <- error_results %>%
mutate(FileName = str_remove(FileName, "\\.out$"))  # Remove '.out' at the end of the string
# Normalize the 'FileName' and 'Rep' columns in both datasets
final_data_with_actuals <- final_data_with_actuals %>%
mutate(
FileName = str_trim(tolower(FileName)),  # Trim spaces and convert to lowercase
Rep = str_trim(tolower(Rep))             # Trim spaces and convert to lowercase
)
error_results <- error_results %>%
mutate(
FileName = str_trim(tolower(FileName)),  # Trim spaces and convert to lowercase
Rep = str_trim(tolower(Rep))             # Trim spaces and convert to lowercase
)
# Filter out rows that match error_results
final_data_with_actuals_cleaned <- final_data_with_actuals %>%
filter(!paste(FileName, Rep) %in% paste(error_results$FileName, error_results$Rep))
# Check the number of rows after deletion
cat("Rows in final_data_with_actuals after deletion:", nrow(final_data_with_actuals_cleaned), "\n")
matching_rows <- final_data_with_actuals %>%
filter(paste(FileName, Rep) %in% paste(error_results$FileName, error_results$Rep))
cat("Number of matching rows between final_data_with_actuals and error_results: ", nrow(matching_rows), "\n")
duplicates_in_error_results <- error_results %>%
group_by(FileName, Rep) %>%
filter(n() > 1)  # Check for duplicates
cat("Number of duplicates in error_results: ", nrow(duplicates_in_error_results), "\n")
matching_rows_check <- final_data_with_actuals %>%
filter(paste(FileName, Rep) %in% paste(error_results$FileName, error_results$Rep)) %>%
head(10)  # Check the first 10 matching rows
print(matching_rows_check)
# Check for any differences in FileName and Rep between the two datasets
file_name_diff <- setdiff(final_data_with_actuals$FileName, error_results$FileName)
rep_diff <- setdiff(final_data_with_actuals$Rep, error_results$Rep)
cat("Differences in FileName: ", length(file_name_diff), "\n")
cat("Differences in Rep: ", length(rep_diff), "\n")
# Check the first few rows after anti_join to confirm deletion behavior
rows_after_anti_join <- anti_join(final_data_with_actuals, error_results, by = c("FileName", "Rep"))
# Display a sample of rows to verify
head(rows_after_anti_join)
View(rows_after_anti_join)
#| label: "combine-csv-files-parallel"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
# Step 1: Set the correct CSV directory
csv_directory <- here('2 Time Points', '4_2T_RILTA_GEN_RILTA_ANALYZED')
# Step 2: Source the child document
source(here('Child_Docs', 'data_scraping.R'))
#| label: "scrape-rows-process-data-parallel"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
# Step 2: Process the data using the child script
source(here('Child_Docs', 'step2_2t_RILTA.R'))
#| label: "scrape-csv-files-part 2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
# Step 1: Set the correct CSV directory
csv_directory <- here('2 Time Points', '4_2T_RILTA_GEN_RILTA_ANALYZED_REP')
# Step 2: Source the child document
source(here('Child_Docs', 'data_scraping.R'))
#| label: "scrape-rows-process-data-parallel2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
# Step 2: Process the data using the child script
source(here('Child_Docs', 'step2_2t_RILTA.R'))
#| label: "load-libraries"
#| echo: true
#| message: false
#| warning: false
library(tidyverse)
library(MplusAutomation)
library(here)
library(gt)
library(janitor)
library(glue)
library(ggtext)
library(rlang)
library(knitr)
library(parallel)
library(tools)
library(tidyr)
#| label: "scrape-csv-files-part 2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
# Step 1: Set the correct CSV directory
csv_directory <- here('2 Time Points', '4_2T_RILTA_GEN_RILTA_ANALYZED_REP')
# Step 2: Source the child document
source(here('Child_Docs', 'data_scraping.R'))
#| label: "scrape-rows-process-data-parallel2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
# Step 2: Process the data using the child script
source(here('Child_Docs', 'step2_2t_RILTA.R'))
#| label: "convert-logits-to-probabilities2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
# Step 3 and 4: Process the data and return results
source(here('Child_Docs', 'steps_3_and_4.R'))
# The objects `final_data_with_actuals` and `violators` should now be in the global environment
#| label: "data-processing"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
library(parallel)
library(tidyverse)
# Define helper functions
extract_errors_from_file <- function(filepath) {
lines <- readLines(filepath)
error_keywords <- c("SINGULARITY", "NON-POSITIVE DEFINITE")
completed_line <- lines[grepl("Completed", lines, ignore.case = TRUE)]
total_replications <- as.integer(str_match(completed_line, "Completed\\s+(\\d+)")[, 2])
if (is.na(total_replications) || length(total_replications) == 0) total_replications <- 0
results <- tibble(
FileName = basename(filepath),
Rep = 1:total_replications,  # Rename 'Replication' to 'Rep'
ErrorFlag = 0,
Message = "None"
)
current_replication <- NULL
for (line in lines) {
replication_match <- str_match(line, "REPLICATION (\\d+):")
if (!is.na(replication_match[1])) {
current_replication <- as.integer(replication_match[2])
}
if (!is.null(current_replication) && any(sapply(error_keywords, grepl, line, ignore.case = TRUE))) {
results <- results %>%
mutate(
ErrorFlag = if_else(Rep == current_replication, 1, ErrorFlag),
Message = if_else(Rep == current_replication,
paste0(Message, "; ", str_trim(line)),
Message
)
)
}
}
results <- results %>%
mutate(
Message = if_else(Message == "None", "No Errors or Warnings", Message)
)
return(results)
}
extract_completed_replications <- function(filepath) {
lines <- readLines(filepath)
completed_line <- lines[grepl("Completed", lines, ignore.case = TRUE)]
completed <- as.integer(str_match(completed_line, "Completed\\s+(\\d+)")[, 2])
if (length(completed) == 0) completed <- 0
tibble(FileName = basename(filepath), CompletedReplications = completed)
}
extract_requested_replications <- function(filepath) {
lines <- readLines(filepath)
requested_line <- lines[grepl("Requested", lines, ignore.case = TRUE)]
requested <- as.integer(str_match(requested_line, "Requested\\s+(\\d+)")[, 2])
if (length(requested) == 0) requested <- 0
tibble(FileName = basename(filepath), RequestedReplications = requested)
}
# Function to calculate the replication summary
calculate_replication_summary <- function(all_reps) {
# Aggregate file-level summary
full_summary <- all_reps %>%
group_by(FileName) %>%
summarise(
CompletedReplications = n_distinct(Rep),
ErrorReplications = sum(ErrorFlag),
RequestedReplications = max(Rep), # Assuming all replications are sequentially numbered
.groups = "drop"
) %>%
mutate(
GoodReplications = CompletedReplications - ErrorReplications,
ErrorRate = if_else(RequestedReplications > 0, (ErrorReplications / RequestedReplications) * 100, 0)
)
return(full_summary)
}
# Parallel processing
output_folder <- "4_2T_RILTA_GEN_RILTA_ANALYZED_REP"
file_list <- list.files(output_folder, pattern = "\\.out$", full.names = TRUE)
cluster_type <- ifelse(.Platform$OS.type == "windows", "PSOCK", "FORK")
num_cores <- detectCores() - 1
cl <- makeCluster(num_cores, type = cluster_type)
# Export functions to cluster
clusterExport(cl, c("extract_errors_from_file", "extract_completed_replications", "extract_requested_replications", "str_match"))
clusterEvalQ(cl, library(tidyverse))
error_summary <- bind_rows(parLapply(cl, file_list, extract_errors_from_file)) %>%
mutate(FileName = tolower(gsub("\\.out$", "", FileName)))  # Normalize FileName
completed_replications <- bind_rows(parLapply(cl, file_list, extract_completed_replications)) %>%
mutate(FileName = tolower(gsub("\\.out$", "", FileName)))  # Normalize FileName
requested_replications <- bind_rows(parLapply(cl, file_list, extract_requested_replications)) %>%
mutate(FileName = tolower(gsub("\\.out$", "", FileName)))  # Normalize FileName
# Stop the cluster
stopCluster(cl)
# After stopping the cluster, consolidate and summarize the data once
all_reps <- error_summary %>%
left_join(completed_replications, by = "FileName") %>%
left_join(requested_replications, by = "FileName")
# Add the 'Rep' column to ensure it's available for summarization
all_reps <- all_reps %>%
mutate(Rep = 1:nrow(all_reps))  # Ensure Rep column is added
# Now calculate the replication summary with correct column order and summary
# Assuming the error_summary, completed_replications, and requested_replications
# are correctly populated with the right data including a 'Rep' column if needed.
# Adjusting the summarization for RequestedReplications
replication_summary <- all_reps %>%
group_by(FileName) %>%
summarise(
CompletedReplications = n_distinct(Rep),
RequestedReplications = first(RequestedReplications),  # Or use max(RequestedReplications) since all values are the same for each file
ErrorReplications = sum(ErrorFlag),
GoodReplications = CompletedReplications - ErrorReplications,
ErrorRate = if_else(RequestedReplications > 0, (ErrorReplications / RequestedReplications) * 100, 0),
.groups = 'drop'
)
# Ensure correct column ordering
replication_summary <- replication_summary %>%
select(FileName, CompletedReplications, RequestedReplications, ErrorReplications, GoodReplications, ErrorRate)
# Output the final number of rows to confirm data handling
cat("Number of rows in all_reps: ", nrow(all_reps), "\n")
cat("Number of rows in replication_summary: ", nrow(replication_summary), "\n")
#| label: "visualization"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
# Check for errors and create the table if applicable
if (nrow(replication_summary) > 0 && any(replication_summary$ErrorReplications > 0)) {
replication_summary_table <- replication_summary %>%
gt() %>%
tab_header(
title = "Replication Summary",
subtitle = paste0("Folder: ", output_folder)
) %>%
fmt_number(columns = c(CompletedReplications, RequestedReplications, ErrorReplications, GoodReplications, ErrorRate), decimals = 2) %>%
cols_label(
FileName = "File Name",
CompletedReplications = "Completed Replications",
RequestedReplications = "Requested Replications",
ErrorReplications = "Replications with Errors",
GoodReplications = "Good Replications",
ErrorRate = "Error Rate (%)"
) %>%
tab_options(
table.font.size = "small",
heading.title.font.size = "medium",
heading.subtitle.font.size = "small"
)
print(replication_summary_table)
} else {
message("No errors or warnings detected. No table to display.")
}
# Filter for valid replications
clean_data <- all_reps %>%
filter(ErrorFlag == 0) %>%  # Keep only rows without errors
select(FileName, Rep)  # Select only required columns
# Summarize valid replications
cat("Number of valid replications per file:\n")
clean_data_summary <- clean_data %>%
group_by(FileName) %>%
summarise(ValidReplications = n(), .groups = "drop")
# Step 1: Summarize error information for each file
error_results_summary <- all_reps %>%
group_by(FileName) %>%
summarise(
TotalReplications = n(),  # Count all replications
ErrorReplications = sum(ErrorFlag == 1),  # Count error instances
RemainingReplications = sum(ErrorFlag == 0),  # Count successful (non-error) replications
.groups = "drop"
)
# Step 2: Compute Derived Metrics
error_results_summary <- error_results_summary %>%
mutate(
ComputedAfterErrors = TotalReplications - ErrorReplications,  # Alternative name for RemainingReplications
ErrorRate = if_else(
TotalReplications > 0,
(ErrorReplications / TotalReplications) * 100,
0
)  # Percentage of errors
)
# Step 3: Validate Computations
validation_check <- error_results_summary %>%
filter(ComputedAfterErrors != RemainingReplications)
if (nrow(validation_check) > 0) {
warning("Mismatch detected between ComputedAfterErrors and RemainingReplications!")
print(validation_check)
} else {
message("Validation successful: All computations are consistent.")
}
# Now 'error_results_summary' includes TotalReplications, ErrorReplications, RemainingReplications, ComputedAfterErrors, and ErrorRate.
#| label: "visualize_data_post_errors"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
# Render the error_results_summary table
error_results_summary%>%
gt() %>%
tab_header(
title = "Replication Summary",
subtitle = paste0("Folder: ", output_folder)
) %>%
fmt_number(
columns = c(TotalReplications, ErrorReplications, RemainingReplications, ComputedAfterErrors, ErrorRate),
decimals = 2
) %>%
cols_label(
FileName = "File Name",
TotalReplications = "Total Replications",
ErrorReplications = "Error Replications",
RemainingReplications = "Remaining Replications",
ComputedAfterErrors = "Computed After Errors",
ErrorRate = "Error Rate (%)"
) %>%
tab_options(
table.font.size = "small",
heading.title.font.size = "medium",
heading.subtitle.font.size = "small"
)
# Remove '.out' from the 'FileName' column in both datasets
final_data_with_actuals <- final_data_with_actuals %>%
mutate(FileName = str_remove(FileName, "\\.out$"))  # Remove '.out' at the end of the string
error_results <- error_results %>%
mutate(FileName = str_remove(FileName, "\\.out$"))  # Remove '.out' at the end of the string
# Normalize the 'FileName' and 'Rep' columns in both datasets
final_data_with_actuals <- final_data_with_actuals %>%
mutate(
FileName = str_trim(tolower(FileName)),  # Trim spaces and convert to lowercase
Rep = str_trim(tolower(Rep))             # Trim spaces and convert to lowercase
)
error_results <- error_results %>%
mutate(
FileName = str_trim(tolower(FileName)),  # Trim spaces and convert to lowercase
Rep = str_trim(tolower(Rep))             # Trim spaces and convert to lowercase
)
# Step 1: Add the ErrorFlag column from error_results (or error_summary) to final_data_with_actuals
final_data_with_actuals <- final_data_with_actuals %>%
left_join(error_results %>% select(FileName, Rep, ErrorFlag), by = c("FileName", "Rep"))
# Step 2: Filter out rows where ErrorFlag == 1 (i.e., errors)
final_data_without_errors <- final_data_with_actuals %>%
filter(ErrorFlag == 0)
# Step 3: Check the number of rows before and after deletion
cat("Rows in final_data_with_actuals (before deletion):", nrow(final_data_with_actuals), "\n")
cat("Rows in final_data_without_errors (after deletion):", nrow(final_data_without_errors), "\n")
cat("Number of error rows removed:", nrow(final_data_with_actuals) - nrow(final_data_without_errors), "\n")
View(final_data_with_actuals)
str(final_data_with_actuals$FileName)
str(error_summary$FileName)
final_data_with_actuals$FileName <- as.character(final_data_with_actuals$FileName)
error_summary$FileName <- as.character(error_summary$FileName)
head(final_data_with_actuals)
final_data_with_actuals <- final_data_with_actuals %>%
left_join(error_summary, by = "FileName")
#| label: "load-libraries"
#| echo: true
#| message: false
#| warning: false
library(tidyverse)
library(MplusAutomation)
library(here)
library(gt)
library(janitor)
library(glue)
library(ggtext)
library(rlang)
library(knitr)
library(parallel)
library(tools)
library(tidyr)
# Check the current memory limit
memory.limit()
# Increase the memory limit (if your system allows)
memory.limit(size = 64000)  # Set to 64 GB, for example
#| label: "scrape-csv-files-part 2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
# Step 1: Set the correct CSV directory
csv_directory <- here('2 Time Points', '4_2T_RILTA_GEN_RILTA_ANALYZED_REP')
# Step 2: Source the child document
source(here('Child_Docs', 'data_scraping.R'))
