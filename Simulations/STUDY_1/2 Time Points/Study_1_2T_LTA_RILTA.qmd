---
title: "Understanding the Performance of Random Intercepts Latent Transition Analysis (RI-LTA): A Monte Carlo Simulation Study using MplusAutomation"
subtitle: "Study 1.2: LTA Generated, RILTA Analyzed with Two Timepoints"
author: "Delwin Carter"
date: "`r format(Sys.time(), '%B %d, %Y')`"

format:
  html:
    toc: true
    toc-title: "Overview"
    toc-depth: 3
    toc-float:
      collapsed: false
      smooth-scroll: true
    theme: flatly
    fig-format: svg
    font:
      main: "Avenir Next LT Pro, Arial, sans-serif"
    page-layout: full
    code-tools: true

editor: visual

knitr:
  opts_chunk:
    echo: true
    out.width: "100%"
    fig.align: "center"
---

------------------------------------------------------------------------

::: {layout-ncol="2"}
![](images/LVG%20FINAL.png){width="300"}

![](images/UCSB_Gauchos_logo_PNG2.png){width="300"}
:::

------------------------------------------------------------------------

# Introduction

## Study 1.2: LTA Generated, RILTA Analyzed

------------------------------------------------------------------------

![](images/LTA_RILTA.png){width="354"}

------------------------------------------------------------------------

Load Packages

```{r, message=FALSE, warning=FALSE}
#| label: "load-libraries"
#| echo: true
#| message: false
#| warning: false

library(tidyverse)
library(MplusAutomation)
library(here)
library(gt)
library(janitor)
library(glue)
library(ggtext)
library(rlang)
library(knitr)
library(kableExtra)
library(parallel)
library(tools)
library(officer)
library(flextable)
```

------------------------------------------------------------------------

# Simulation

------------------------------------------------------------------------

## Part 1: Conduct Simulation

> In this section, I am conducting a simulation where I am generating data as Latent Transition Analysis and analyzing it as Random Intercepts Latent Transition Analysis to fully explore the model's performance. The simulation consists of 24 conditions, combining four sample sizes (N = 500, 1000, 2000, 4000) with six transition probabilities linked to logits (*betas;* 1.385, .85, .41, -.41, -.85, -1.385), corresponding to probabilities of .8, .7, .6, .4, .3, and .2. These conditions are iterated over programmatically using MplusAutomation to set up and execute the models. To speed up the process, I employ parallel processing, which distributes computations across multiple CPU cores, enabling efficient completion of the simulations across all scenarios.

Conditions:

Sample Size: N = 500, 1000, 2000, 4000

Transition logit (Probability): TPs = 1.385 (.8), .85 (.7), .41 (.6), -.41 (.4), -.85 (.3), -1.385 (.2)

![](images/clipboard-3344253592.png){width="450"}

### Setting up the Simulation ConditionsÂ 

```{r}
#| label: "simulation-conditions"
#| echo: true
#| message: false
#| warning: false

p1 <- expand.grid(N = c(500, 1000, 2000, 4000),
TPs = c(1.385, .85, .41, -.41, -.85, -1.385),
TH = c(1))
       
# Display the matrix using gt
p1 %>%
  gt() %>%
  tab_header(
    title = "Simulation Conditions Matrix",
    subtitle = "Combinations of Sample Sizes, Transition Probabilities, and Mixtures"
  ) %>%
  cols_align(
    align = "center",
    columns = everything() # Centers all columns
  )
```

## Run Initial Simulation

```{r,eval = FALSE}
#| label: "lta-rilta-simulation"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

library(parallel)
# Step 1: Create the cluster for parallel processing
num_cores <- detectCores() - 1  # Detect the number of available cores (minus 1)
cl <- makeCluster(num_cores, type = "PSOCK")  # Create the PSOCK cluster

lta_rilta_func <- function(N, TPs, TH) {
  
  LTA_RILTA <- mplusObject(
    TITLE = glue("Generate LTA_RILTA_N_{N}_TP_{TPs}_{TH}"),

    MONTECARLO =
      glue("NAMES = u11-u15 u21-u25;
      GENERATE = u11-u15 u21-u25(1);
      CATEGORICAL = u11-u15 u21-u25;
      GENCLASSES = c1(2) c2(2);
      CLASSES = c1(2) c2(2);
      NOBSERVATIONS = {N};
      SEED = 07252005;
      NREPS = 500;
      !!SAVE = repM1*.dat;
      RESULTS = LTA_RILTA_N_{N}_TP_{TPs}_TH_{TH}.csv;"),

    ANALYSIS =
      "TYPE = MIXTURE;
      algorithm = integration;
      processors = 24;
      starts= 140 30;
      logcriterion=0.00001;
      mconv=0.00001;",
    
      OUTPUT = "TECH9",

    MODELPOPULATION = glue("	
        %OVERALL%

       [c1#1-c2#1*0];
      	c2#1 on c1#1*{TPs};

      MODEL POPULATION-c1:
        %c1#1%
     [u11$1*{TH} u12$1*{TH} u13$1*{TH} u14$1*{TH} u15$1*{TH}] (p111-p115);

        %c1#2%
     [u11$1*-{TH} u12$1*-{TH} u13$1*-{TH} u14$1*-{TH} u15$1*-{TH}] (p121-p125);

      MODEL POPULATION-c2:  
        %c2#1%
     [u21$1*{TH} u22$1*{TH} u23$1*{TH} u24$1*{TH} u25$1*{TH}] (p111-p115);

        %c2#2%
     [u21$1*-{TH} u22$1*-{TH} u23$1*-{TH} u24$1*-{TH} u25$1*-{TH}] (p121-p125);
       "),
     

    MODEL =
      glue("	
        %OVERALL%
          [c1#1-c2#1*0](par1-par2);
        	c2#1 on c1#1*{TPs} (par11);
        	
        f by u11* u12 u13 u14-u15 (p1-p5)
             u21 u22 u23 u24 u25 (p1-p5);
      	f@1;
        [f@0];

     MODEL c1:
        %c1#1%
     [u11$1*{TH} u12$1*{TH} u13$1*{TH} u14$1*{TH} u15$1*{TH}] (p111-p115);

        %c1#2%
     [u11$1*-{TH} u12$1*-{TH} u13$1*-{TH} u14$1*-{TH} u15$1*-{TH}] (p121-p125);

    MODEL c2: 	
        %c2#1%
     [u21$1*{TH} u22$1*{TH} u23$1*{TH} u24$1*{TH} u25$1*{TH}] (p111-p115);

        %c2#2%
     [u21$1*-{TH} u22$1*-{TH} u23$1*-{TH} u24$1*-{TH} u25$1*-{TH}] (p121-p125);
	      "),
      

    MODELCONSTRAINT =
      if (TPs == 1.385) {
        glue("
        New(
        trans11*.80 trans12*.20 trans21*.5 trans22*.5
        prob11*.5 prob12*.5 prob21*.65 prob22*.35);
        trans11 = 1/(1+exp(-(par2+par11)));
        trans12 = 1-trans11;
        trans21 = 1/(1+exp(-par2));
        trans22 = 1- trans21;
        !marginal probabilities at T1 and T2:
        prob11 = 1/(1+exp(-par1));
        prob12 = 1 - prob11;
        prob21 = prob11*trans11+prob12*trans21;
        prob22 = 1- prob21;
        ")
      } 
             else if (TPs == .85) {
        glue("
        New(
        trans11*.70 trans12*.30 trans21*.5 trans22*.5
        prob11*.5 prob12*.5 prob21*.60 prob22*.4);
        trans11 = 1/(1+exp(-(par2+par11)));
        trans12 = 1-trans11;
        trans21 = 1/(1+exp(-par2));
        trans22 = 1- trans21;
        !marginal probabilities at T1 and T2:
        prob11 = 1/(1+exp(-par1));
        prob12 = 1 - prob11;
        prob21 = prob11*trans11+prob12*trans21;
        prob22 = 1- prob21;
        ")
              } 
            else  if (TPs == .41) {
        glue("
        New(
        trans11*.60 trans12*.40 trans21*.5 trans22*.5
        prob11*.5 prob12*.5 prob21*.55 prob22*.45);
        trans11 = 1/(1+exp(-(par2+par11)));
        trans12 = 1-trans11;
        trans21 = 1/(1+exp(-par2));
        trans22 = 1- trans21;
        !marginal probabilities at T1 and T2:
        prob11 = 1/(1+exp(-par1));
        prob12 = 1 - prob11;
        prob21 = prob11*trans11+prob12*trans21;
        prob22 = 1- prob21;
        ")
              } 
             else if (TPs == -.41) {
        glue("
        New(
        trans11*.40 trans12*.60 trans21*.5 trans22*.5
        prob11*.5 prob12*.5 prob21*.45 prob22*.55);
        trans11 = 1/(1+exp(-(par2+par11)));
        trans12 = 1-trans11;
        trans21 = 1/(1+exp(-par2));
        trans22 = 1- trans21;
        !marginal probabilities at T1 and T2:
        prob11 = 1/(1+exp(-par1));
        prob12 = 1 - prob11;
        prob21 = prob11*trans11+prob12*trans21;
        prob22 = 1- prob21;
        ")
              } 
             else if (TPs == -.85) {
        glue("
        New(
        trans11*.30 trans12*.70 trans21*.5 trans22*.5
        prob11*.5 prob12*.5 prob21*.40 prob22*.60);
        trans11 = 1/(1+exp(-(par2+par11)));
        trans12 = 1-trans11;
        trans21 = 1/(1+exp(-par2));
        trans22 = 1- trans21;
        !marginal probabilities at T1 and T2:
        prob11 = 1/(1+exp(-par1));
        prob12 = 1 - prob11;
        prob21 = prob11*trans11+prob12*trans21;
        prob22 = 1- prob21;
        ")
              } 
        
        else if (TPs == -1.385) {
        glue("
         New(
        trans11*.20 trans12*.80 trans21*.5 trans22*.5
        prob11*.5 prob12*.5 prob21*.35 prob22*.65);

        trans11 = 1/(1+exp(-(par2+par11)));
        trans12 = 1-trans11;
        trans21 = 1/(1+exp(-par2));
        trans22 = 1- trans21;
        !marginal probabilities at T1 and T2:
        prob11 = 1/(1+exp(-par1));
        prob12 = 1 - prob11;
        prob21 = prob11*trans11+prob12*trans21;
        prob22 = 1- prob21;")
      }
  )

  # Run Mplus model
  LTA_RILTA_Model<- mplusModeler(LTA_RILTA, 
                                   dataout = here('Simulations', 'STUDY_1', '2 Time Points', "2_2T_LTA_GEN_RILTA_ANALYZED", glue("LTA_RILTA_N_{N}_TP_{TPs}_TH_{TH}.dat")),
                                   modelout = glue(here('Simulations', 'STUDY_1', '2 Time Points', "2_2T_LTA_GEN_RILTA_ANALYZED", "LTA_RILTA_N_{N}_TP_{TPs}_TH_{TH}.inp")),
                                   check = TRUE, run = TRUE, hashfilename = FALSE)
return(LTA_RILTA_Model)
}

# Step 3: Export necessary objects to the cluster
clusterExport(cl, c("lta_rilta_func", "p1", "here", "glue", "mplusModeler", "mplusObject"))

# Ensure necessary libraries are loaded on each cluster node
clusterEvalQ(cl, {
  library(MplusAutomation)
  library(glue)
  library(here)
})

# Step 4: Run the simulation in parallel using the cluster
result_list <- parLapply(cl, 1:nrow(p1), function(i) {
  lta_rilta_func(p1$N[i], p1$TPs[i], p1$TH[i])
})

# Step 5: Stop the cluster after the simulation
stopCluster(cl)

```

------------------------------------------------------------------------

# Data Processing and Verification

------------------------------------------------------------------------

## Check for Label Switching and Errors

> In this section: .csv files are first merged into a single data frame, from which specific parameters are extracted. Logit values are then converted to probabilities, and known class values are incorporated into the data frame. A subset of cases involving label switching is dplyr::selected randomly and plotted for visual review. Output files are scanned for errors, which are subsequently merged back into the original data file. Additional columns derived from the file name are added, and the percentage of violations is calculated. Both errors and label switching violations are visually represented, and the total number of corrected replications is reported.

### Scrape Mplus CSV Files

*First, Load all CSV files and combine them into a single data frame.*

```{r}
#| label: "combine-csv-files-parallel"
#| echo: true
#| message: false
#| warning: false
#| code-fold: false

# Step 1: Set the correct CSV directory
csv_directory <- here('Simulations', 'Study_1', '2 Time Points', '2_2T_LTA_GEN_RILTA_ANALYZED')

# Step 2: Source the child document
source(here('Child_Docs', 'data_scraping.R'))

# Will populate combined_data dataframe in the global environment
```

### Slice Data / Extract Parameters

*Extract data from the appropriate rows from each 9-row chunk and prepare the data for further processing.*

```{r}
#| label: "scrape-rows-process-data-parallel"
#| echo: true
#| message: false
#| warning: false
#| code-fold: false

# Step 2: Process the data using the child script
source(here('Child_Docs', 'step2_2t_RILTA.R'))

final_combined_data <- final_combined_data %>%
  mutate(
    TRANS11 = as.numeric(TRANS11),
    SE_11 = as.numeric(SE_11),
    across(starts_with("Ec"), as.numeric),  # Convert all Ec columns
    ll_csv = as.numeric(ll_csv)  # Convert Log-Likelihood values
  )

# Will populate final_combined_data dataframe in global environment
```

### Wrangle Data

*Convert the logits to probabilities and add the known actual values to each row.*

```{r}
#| label: "convert-logits-to-probabilities"
#| echo: true
#| message: false
#| warning: false
#| code-fold: false

# Step 3: Process the data and return results
source(here('Child_Docs', 'step_3.R'))

# The objects `final_data_with_actuals` and `violators` should now be in the global environment

```

### Generate Plots of Label Switching

*Generate plots of randomly sampled violators for visual inspection using parallel processing.*

```{r, eval=FALSE}
#| label: "plot-violators"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Set plot width and height
plot_width <- 8
plot_height <- 6

# Take a random sample of up to 250 violators (ensure not to exceed the total number of violators)
set.seed(123)  # For reproducibility
sample_size <- min(nrow(violators), 250)  # Handle cases where fewer than 250 violators exist
sampled_violators <- violators[sample(nrow(violators), sample_size), ]

# Define the function to create plots sequentially
plot_violator <- function(i) {
  row_data <- sampled_violators[i, ]
  
  # Extract the file name from the current row
  file_name <- row_data$FileName

  # Extract probability values for EC1 and EC2 (estimated probabilities) and AC1 and AC2 (actuals)
  estimated_probabilities <- c(
    as.numeric(row_data[c("Ec1u1", "Ec1u2", "Ec1u3", "Ec1u4", "Ec1u5")]),
    as.numeric(row_data[c("Ec2u1", "Ec2u2", "Ec2u3", "Ec2u4", "Ec2u5")])
  )
  
  actual_values <- c(
    as.numeric(row_data[c("Ac1u1", "Ac1u2", "Ac1u3", "Ac1u4", "Ac1u5")]),
    as.numeric(row_data[c("Ac2u1", "Ac2u2", "Ac2u3", "Ac2u4", "Ac2u5")])
  )
  
  # Create labels for the legend with actual values directly from the dataset
  labels <- c(
    paste0("EC1: (", round(row_data$Ec1u1, 3), ", ", round(row_data$Ec1u2, 3), ", ", round(row_data$Ec1u3, 3), ", ", round(row_data$Ec1u4, 3), ", ", round(row_data$Ec1u5, 3), ")"),
    paste0("EC2: (", round(row_data$Ec2u1, 3), ", ", round(row_data$Ec2u2, 3), ", ", round(row_data$Ec2u3, 3), ", ", round(row_data$Ec2u4, 3), ", ", round(row_data$Ec2u5, 3), ")"),
    paste0("AC1: (", round(row_data$Ac1u1, 3), ", ", round(row_data$Ac1u2, 3), ", ", round(row_data$Ac1u3, 3), ", ", round(row_data$Ac1u4, 3), ", ", round(row_data$Ac1u5, 3), ")"),
    paste0("AC2: (", round(row_data$Ac2u1, 3), ", ", round(row_data$Ac2u2, 3), ", ", round(row_data$Ac2u3, 3), ", ", round(row_data$Ac2u4, 3), ", ", round(row_data$Ac2u5, 3), ")")
  )

  # Step 6: Create a data frame for plotting
  plot_data <- data.frame(
    Items = rep(1:5, 4),
    Probabilities = c(estimated_probabilities, actual_values),
    Class = rep(labels, each = 5)
  )

  # Step 7: Create the plot with the file name in the title
  p <- ggplot(plot_data, aes(x = Items, y = Probabilities, color = Class, group = Class)) +
    geom_line(size = 1.2) +
    geom_point(size = 3) +
    labs(title = file_name, x = "Items", y = "Probabilities") +  # Only the file name in the title
    theme_minimal(base_size = 16) +
    theme(panel.background = element_rect(fill = "white"),
          plot.background = element_rect(fill = "white"),
          plot.title = element_text(size = 14, hjust = 0.5)) +  # Adjust title size and center
    scale_color_manual(values = c(
      "darkblue", "darkgreen",  # EC1 and EC2 (Estimated Probabilities)
      "lightblue", "lightgreen"  # AC1 and AC2 (Actual Values)
    ))

  ggsave(filename = file.path("z2t_lta_rilta_violator_plots", paste0("violator_plot_", i, "_", file_name, ".png")),
         plot = p, width = plot_width, height = plot_height)
}

# Apply the function to generate plots sequentially (without parallelization)
invisible(lapply(1:sample_size, plot_violator))

```

------------------------------------------------------------------------

# Error Handling

------------------------------------------------------------------------

### Scrape for Errors

*Scrape output files for errors*

```{r}
#| label: "process-out-files-parallel"
#| echo: true
#| message: false
#| warning: false

# ===================================================== #
#  â SECTION 1 Scrape Output Files for Errors and LL Values
# ===================================================== #

# Step 1: Set the correct output directory for .out files
output_folder <- here('Simulations', 'STUDY_1', '2 Time Points', '2_2T_LTA_GEN_RILTA_ANALYZED')

# Step 2: Source the child document that processes .out files
source(here('Child_Docs', 'out_scraping.R'))

# ===================================================== #
#  â SECTION 2 Generate Replication Summary Table
# ===================================================== #
replication_summary_table <- replication_summary %>%
  gt() %>%
  tab_header(
    title = "Replication Summary",
    subtitle = paste0("Folder: ", output_folder)
  ) %>%
  fmt_number(
    columns = c("Total", "Replicated_Yes", "Replicated_No", "Error_Count"),
    decimals = 0
  ) %>%
  cols_label(
    FileName = "File Name",
    Total = "Total Replications",
    Replicated_Yes = "LL Replicated",
    Replicated_No = "LL Not Replicated",
    Error_Count = "Errors"
  ) %>%
  cols_align(
    align = "center",
    columns = everything()
  ) %>%
  tab_options(
    table.font.size = "small",
    heading.title.font.size = "medium",
    heading.subtitle.font.size = "small",
    table.width = pct(80)
  )

# Display the table
replication_summary_table

# ===================================================== #
#  â SECTION 3 Row Count Validation
# ===================================================== #
cat("Rows in final_data_with_actuals:", nrow(final_data_with_actuals), "\n")
cat("Rows in final_results:", nrow(final_results), "\n")
cat("Rows in replication_summary:", nrow(replication_summary), "\n")

###CHECK EXTRA ROWS
# Identify extra rows that are in final_results but not in final_data_with_actuals
extra_rows <- anti_join(final_results, final_data_with_actuals, by = c("FileName", "Replication"))

# Check if all extra rows have ErrorFlag == 1
all_errors <- all(extra_rows$ErrorFlag == 1, na.rm = TRUE)

# Message instead of printing raw data
if (all_errors) {
  message("â All extra rows have errors (ErrorFlag == 1).")
} else {
  message("â ï¸ Some extra rows do NOT have errors. Manual inspection needed.")
}
```

### Merge Errors with Main Data File

*Combine error information with main data file and calculate \***True** violators*

```{r}
#| label: "merge-errors"
#| echo: true
#| message: false
#| warning: false

final_data_with_actuals <- final_data_with_actuals %>%
  left_join(
    final_results %>% dplyr::select(FileName, Replication, ll_out, LL_Replicated, ErrorFlag), 
    by = c("FileName", "Replication")
  ) %>%
  mutate(
    Any_Violation = ifelse(is.na(Any_Violation), 0, Any_Violation),
    ErrorFlag = ifelse(is.na(ErrorFlag), 0, ErrorFlag),
    LL_Replicated = ifelse(LL_Replicated == "Yes", 1, 0),  # â Convert Yes/No to 1/0

    # ð¹ Create a new True Violation column
    True_Violation = case_when(
      Any_Violation == 1 | ErrorFlag == 1 | LL_Replicated == 0 ~ 1,  # â At least one violation
      TRUE ~ 0
    )
  )
```

Visualize differences between ll_out and ll_csv

```{r}

ll_check <- final_data_with_actuals %>%
  mutate(diff = round(ll_out - ll_csv, 3)) %>%  # Round before counting
  count(diff)

ll_check_table <- ll_check %>%
  gt() %>%
  tab_header(
    title = "LL Difference Summary",
    subtitle = "Comparison of LL values between CSV and OUT files"
  ) %>%
  cols_label(
    diff = "LL Difference",
    n = "Count"
  ) %>%
  fmt_number(
    columns = diff,
    decimals = 3
  ) %>%
  cols_align(
    align = "center",
    columns = everything()
  ) %>%
  tab_options(
    table.font.size = "small",
    heading.title.font.size = "medium",
    heading.subtitle.font.size = "small",
    table.width = pct(50)
  )

# Display the table
ll_check_table
```

Create DF of LL differences from .out and .csv files for inspection at the replication level

```{r}
ll_mismatch <- final_data_with_actuals %>%
  mutate(diff = round(ll_out - ll_csv, 3)) %>%
  filter(diff != 0 | is.na(ll_out) | is.na(ll_csv)) %>%
  dplyr::select(FileName, Replication, ll_out, ll_csv, diff)

```

### Scrape File Name Components

*Create Column Names from the File Name*

```{r}
#| label: "create-column-names-from-filename"
#| echo: true
#| message: false
#| warning: false
#| code-fold: false

# Add new columns based on the information in the FileName and set factors
final_data_with_actuals <- final_data_with_actuals %>%
  mutate(
    # Extract the sample size (N) from the FileName with the correct values
    N = case_when(
      grepl("n_4000", FileName) ~ 4,  # Correct value for N_4000
      grepl("n_500", FileName) ~ 1,   
      grepl("n_1000", FileName) ~ 2,  
      grepl("n_2000", FileName) ~ 3,  
      TRUE ~ NA_integer_
    ),
    # Map the TPs from the FileName to the appropriate Population labels
    Population = case_when(
      grepl("tp_1.385", FileName) ~ ".800",   # Use ".800" instead of "0.800"
      grepl("tp_0.85", FileName) ~ ".700",    # Use ".700" instead of "0.700"
      grepl("tp_0.41", FileName) ~ ".600",    # Use ".600" instead of "0.600"
      grepl("tp_-0.41", FileName) ~ ".400",   # Use ".400" instead of "0.400"
      grepl("tp_-0.85", FileName) ~ ".300",   # Use ".300" instead of "0.300"
      grepl("tp_-1.385", FileName) ~ ".200",  # Use ".200" instead of "0.200"
      TRUE ~ NA_character_
    ),
    # Create the Transitions variable based on Population values
    Transitions = case_when(
      Population %in% c(".200", ".300", ".400") ~ 1,  # Assign 1 for Population .200, .300, .400
      Population %in% c(".600", ".700", ".800") ~ 2,  # Assign 2 for Population .600, .700, .800
      TRUE ~ NA_integer_
    )
  ) %>%
  # Convert columns to factors, ordering N_4000 first in the factor levels
  mutate(
    N = factor(N, levels = c(4, 1, 2, 3), labels = c("N = 4000", "N = 500", "N = 1000", "N = 2000")),
    Population = factor(Population, levels = c(".800", ".700", ".600", ".400", ".300", ".200")),
    Transitions = factor(Transitions, levels = c(1, 2), labels = c("Mover", "Stayer"))
  )
```

### Calculate Violations

*Calculate Violation Percentages per Condition*

```{r}
#| label: "calculate-violations"
#| echo: true
#| message: false
#| warning: false

violation_summary <- final_data_with_actuals %>%
  mutate(
    N_numeric = as.numeric(gsub("N = ", "", as.character(N))),
    N_numeric = ifelse(is.na(N_numeric), 0, N_numeric)
  ) %>%
  group_by(FileName, Population, N, N_numeric) %>%
  summarize(
    Total_Rows = n(),                                
    Total_Violations = sum(Any_Violation, na.rm = TRUE),   
    Total_Errors = sum(ErrorFlag, na.rm = TRUE),           
    Total_LL_Failures = sum(LL_Replicated == 0, na.rm = TRUE),  
    Total_True_Violations = sum(True_Violation, na.rm = TRUE),  
    Percentage_Violations = round((Total_Violations / Total_Rows) * 100, 1),  
    True_Violation_Perc = round((Total_True_Violations / Total_Rows) * 100, 1),  
    ErrorRate = round((Total_Errors / Total_Rows) * 100, 1),  
    LL_Failure_Perc = round((Total_LL_Failures / Total_Rows) * 100, 1),  
    .groups = "drop"
  ) %>%
  mutate(
Adjusted_Replications_Needed = case_when(
  True_Violation_Perc >= 100 ~ NA_real_,
  TRUE ~ ceiling(500 / (1 - (True_Violation_Perc / 100 + 0.11)) + 55)
),
Adjusted_Replications_Needed = if_else(
  is.na(Adjusted_Replications_Needed) | Adjusted_Replications_Needed < 500, 
  500, 
  Adjusted_Replications_Needed
),
    TPs = case_when(
      Population == ".800" ~ 1.385,
      Population == ".700" ~ 0.85,
      Population == ".600" ~ 0.41,
      Population == ".400" ~ -0.41,
      Population == ".300" ~ -0.85,
      Population == ".200" ~ -1.385,
      TRUE ~ NA_real_
    )
  ) %>%
  arrange(factor(N_numeric, levels = c(500, 1000, 2000, 4000)), as.numeric(Population)) %>%
  mutate(
    N = factor(N, levels = c("N = 500", "N = 1000", "N = 2000", "N = 4000")),  
    Population = factor(Population, levels = c(".200", ".300", ".400", ".600", ".700", ".800"))  
  ) %>%
  dplyr::select(
    N, N_numeric, Population, TPs,   
    Total_Rows,  
    Total_Violations, Percentage_Violations,  
    Total_Errors, ErrorRate,  
    Total_LL_Failures, LL_Failure_Perc,  
    Total_True_Violations, True_Violation_Perc,  
    Adjusted_Replications_Needed  
  ) %>%
  arrange(N_numeric, Population) %>%
  mutate(N_numeric = trimws(as.numeric(N_numeric)))

# Write CSV
write.csv(violation_summary, here("Simulations", "STUDY_1", "2 Time Points", 'zdata', "violation_summary_l_r_2t.csv"), row.names = FALSE)

# Define the base dataset (assumed already created)
# violation_summary <- <your original code>

# Subsets for each computer (uncomment the line for the desired computer, set PROCESSES in Mplus)

# Main Computer: 9 conditions (N_numeric = 4000 all 6 TPs + N_numeric = 2000, TPs = 1.385, 0.85, 0.41) - 23 cores, PROCESSES = 23
#violation_summary <- violation_summary[(violation_summary$N_numeric == 4000) | 
#                                       (violation_summary$N_numeric == 2000 & #violation_summary$TPs %in% c(1.385, 0.85, 0.41)), ]

# Old Rig 1: 3 conditions (N_numeric = 2000, TPs = -0.41, -0.85, -1.385) - 5 cores, 
#violation_summary <- violation_summary[(violation_summary$N_numeric == 2000 & violation_summary$TPs %in% c(-0.41, -0.85, -1.385)), ]

# Old Rig 2: 3 conditions (N_numeric = 1000, TPs = 1.385, 0.85, 0.41) - 5 cores, 
#violation_summary <- violation_summary[(violation_summary$N_numeric == 1000 & violation_summary$TPs %in% c(1.385, 0.85, 0.41)), ]

# Old Rig 3: 3 conditions (N_numeric = 1000, TPs = -0.41, -0.85, -1.385) - 5 cores, 
#violation_summary <- violation_summary[(violation_summary$N_numeric == 1000 & violation_summary$TPs %in% c(-0.41, -0.85, -1.385)), ]

# Old Rig 4: 3 conditions (N_numeric = 500, TPs = 1.385, 0.85, 0.41) - 5 cores, 
#violation_summary <- violation_summary[(violation_summary$N_numeric == 500 & violation_summary$TPs %in% c(1.385, 0.85, 0.41)), ]

# Old Rig 5: 3 conditions (N_numeric = 500, TPs = -0.41, -0.85, -1.385) - 5 cores, 
#violation_summary <- violation_summary[(violation_summary$N_numeric == 500 & violation_summary$TPs %in% c(-0.41, -0.85, -1.385)), ]
```

### Summarize & Visualize Label Switching Percentage Results

```{r}
#| label: "summarize-violations"
#| echo: true
#| message: false
#| warning: false

create_flextable <- function(data) {

  # Ensure only the required columns are used
  data <- data %>%
    dplyr::select(
      N_numeric,  
      Population,  
      Total_Violations,
      Percentage_Violations,
      Total_Errors,
      ErrorRate,
      Total_LL_Failures,
      LL_Failure_Perc,
      Total_True_Violations,
      True_Violation_Perc,
      Adjusted_Replications_Needed
    ) %>%
    as.data.frame()  # Ensures proper structure before passing to flextable
  
  # Create the flextable
  ft <- flextable(data) %>%
    set_header_labels(
      N_numeric = "N",
      Population = "Tââ",  # Column remains "Population"
      Total_Violations = "V",
      Percentage_Violations = "V %",
      Total_Errors = "\u03B5",  # Epsilon
      ErrorRate = "\u03B5 %",
      Total_LL_Failures = "\u2112\u2097",  # ââ
      LL_Failure_Perc = "\u2112\u2097 %",  # ââ%
      Total_True_Violations = "\u03C4\u1D65",  # Tau subscript v (ðáµ¥)
      True_Violation_Perc = "\u03C4\u1D65 %",
      Adjusted_Replications_Needed = "\u2206 Reps Reqâd"  # Delta Symbol
    )

  # Apply special formatting to headers
  ft <- compose(ft, part = "header", j = "N_numeric", value = as_paragraph(as_i("N")))
  ft <- compose(ft, part = "header", j = "Population", value = as_paragraph(as_i("T"), as_sub("11")))

  # ð¹ Label Switching Violations
  ft <- compose(ft, part = "header", j = "Total_Violations", value = as_paragraph(as_i("V")))
  ft <- compose(ft, part = "header", j = "Percentage_Violations", value = as_paragraph(as_i("V"), "%"))

  # ð¹ Mplus Errors
  ft <- compose(ft, part = "header", j = "Total_Errors", value = as_paragraph(as_i("\u03B5")))  
  ft <- compose(ft, part = "header", j = "ErrorRate", value = as_paragraph(as_i("\u03B5"), "%"))

  # ð¹ NEW: LL Replication Failures (ââ)
  ft <- compose(ft, part = "header", j = "Total_LL_Failures", value = as_paragraph(as_i("\u2112"), as_sub("r")))
  ft <- compose(ft, part = "header", j = "LL_Failure_Perc", value = as_paragraph(as_i("\u2112"), as_sub("r"), "%"))

# ð¹ True Violations (ðáµ¥)
ft <- compose(ft, part = "header", j = "Total_True_Violations", value = as_paragraph(as_i("\u03C4"), as_sub(as_i("v"))))  
ft <- compose(ft, part = "header", j = "True_Violation_Perc", value = as_paragraph(as_i("\u03C4"), as_sub(as_i("v")), "%"))  

  ft <- compose(ft, part = "header", j = "Adjusted_Replications_Needed", value = as_paragraph(as_i("\u2206"), "\n", as_i("Reps"), "\n", "Req'd"))

  # Apply width settings
  ft <- width(ft, j = "N_numeric", width = 1.0)
  ft <- width(ft, j = "Population", width = 0.6)  
  ft <- width(ft, j = "Total_Violations", width = 0.6)
  ft <- width(ft, j = "Percentage_Violations", width = 0.6)
  ft <- width(ft, j = "Total_Errors", width = 0.5)
  ft <- width(ft, j = "ErrorRate", width = 0.5)
  ft <- width(ft, j = "Total_LL_Failures", width = 0.5)
  ft <- width(ft, j = "LL_Failure_Perc", width = 0.5)
  ft <- width(ft, j = "Total_True_Violations", width = 0.6)
  ft <- width(ft, j = "True_Violation_Perc", width = 0.6)
  ft <- width(ft, j = "Adjusted_Replications_Needed", width = 0.6)

  ft <- colformat_num(
  ft,
  j = c("Percentage_Violations", "ErrorRate", "LL_Failure_Perc", "True_Violation_Perc" ),  
  suffix = "%"  # â Adds percentage symbol
)
  # Add padding below the subheaders
#ft <- ft %>%
 # padding(part = "header", padding = c(0, 0, 6, 0))  # Adjust as needed for top, right, bottom, and left padding

  # Enable autofit
  ft <- set_table_properties(ft, layout = "fixed")

  # Center all cells
  ft <- align(ft, align = "center", part = "all")

  # Align header text at the bottom of the cells
  #ft <- valign(ft, part = "header", valign = "bottom")

  # Merge vertically identical rows in the "N_numeric" column
  ft <- merge_v(ft, j = "N_numeric")

  # Apply font to the entire table
  ft <- font(ft, fontname = "Avenir Next", part = "all")

  ft <- compose(
    ft,
    part = "body",
    j = "N_numeric",
    i = ~ !duplicated(N_numeric),
    value = as_paragraph(
      as_i("N"),  
      " =\u2009",  # THIN SPACE (Unicode U+2009)
      as.character(format(N_numeric, big.mark = ",", scientific = FALSE))  # Keeps proper formatting
    )
  )

  # Add subheader row
  ft <- add_header_row(
    ft,
    values = c("N Reps = 500", "Violations", "Errors", "LL Replication", "True Violations", "Adjustments"),  
    colwidths = c(2, 2, 2, 2, 2, 1)  
  )

  # Define a transparent border
  no_border <- fp_border(color = "transparent", width = 0)

  # **Remove ONLY the bottom border under the first three columns (the blank subheader)**
  ft <- hline(ft, i = 1, j = 1:2, border = no_border, part = "header")

  # Adding color with a correct method
  total_rows <- nrow(data)  # Get the total number of rows in your data
  color_rows <- rep(FALSE, total_rows)  # Initialize a logical vector for coloring rows
  for (i in seq(1, total_rows, by = 12)) {
    color_rows[i:(i+5)] <- TRUE  # Apply color to every 6 rows
  }

  # Apply background color with a lighter shade of gray
  ft <- bg(ft, i = color_rows, bg = "#f0f0f0", part = "body")

  return(ft)
}

# Generate formatted flextables for each subset
violation_summary_table <- create_flextable(violation_summary)

violation_summary_table
```

Save Table

```{r}
#| label: "render-violation-tables"
#| echo: true
#| message: false
#| warning: false

save_as_image(violation_summary_table, path = here('Simulations', 'STUDY_1', "2 Time Points", "zErrors", "l_r_e&v_1.svg")
   )
```

------------------------------------------------------------------------

# PART 2 Re-Run Simulation

------------------------------------------------------------------------

### Re-Run Simulation with Dynamic Replication Conditions

```{r,eval = FALSE}
#| label: "lta-rilta-simulation2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

  # Define the Mplus object with the dynamic replications
lta_rilta_func <- function(N_numeric, TPs, Adjusted_Replications_Needed) {

  # Manually construct the MONTECARLO section with dynamic NREPS
  montecarlo_section <- glue("
    NAMES = u11-u15 u21-u25;
    GENERATE = u11-u15 u21-u25(1);
    CATEGORICAL = u11-u15 u21-u25;
    GENCLASSES = c1(2) c2(2);
    CLASSES = c1(2) c2(2);
    NOBSERVATIONS = {N_numeric};
    SEED = 07252005;
    NREPS = {Adjusted_Replications_Needed};  ! Dynamic number of replications
    !!SAVE = repM1*.dat;
    RESULTS = LTA_RILTA_N_{N_numeric}_TP_{TPs}_TH_1.csv;
  ")

  # Define the Mplus model using MplusAutomation, using glue for the content
  LTA_RILTA <- mplusObject(
    TITLE = glue("Generate LTA_RILTA_N_{N_numeric}_TP_{TPs}_TH_1;"),
    MONTECARLO = montecarlo_section,  # Use the dynamically constructed MONTECARLO section
    
      ANALYSIS =
      "TYPE = MIXTURE;
      algorithm = integration;
      processors = 24;
      miterations = 1000; 
      starts= 250 100;
      logcriterion=0.00001;
      mconv=0.00001;",
    
    OUTPUT = "TECH9",

    MODELPOPULATION = glue("
      %OVERALL%
      [c1#1-c2#1*0];
      c2#1 on c1#1*{TPs};

      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);

      %c1#2%
      [u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);

      MODEL POPULATION-c2:
      %c2#1%
      [u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);

      %c2#2%
      [u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
    "),
    
    MODEL = glue("
      %OVERALL%
      [c1#1-c2#1*0](par1-par2);
      c2#1 on c1#1*{TPs} (par11);

      f by u11* u12 u13 u14-u15 (p1-p5)
           u21 u22 u23 u24 u25 (p1-p5);
      f@1;
      [f@0];

      MODEL c1:
      %c1#1%
      [u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);

      %c1#2%
      [u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);

      MODEL c2:
      %c2#1%
      [u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);

      %c2#2%
      [u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
    "),
      
    MODELCONSTRAINT =
      if (TPs == 1.385) {
        glue("
        New(
        trans11*.80 trans12*.20 trans21*.5 trans22*.5
        prob11*.5 prob12*.5 prob21*.65 prob22*.35);
        trans11 = 1/(1+exp(-(par2+par11)));
        trans12 = 1-trans11;
        trans21 = 1/(1+exp(-par2));
        trans22 = 1- trans21;
        !marginal probabilities at T1 and T2:
        prob11 = 1/(1+exp(-par1));
        prob12 = 1 - prob11;
        prob21 = prob11*trans11+prob12*trans21;
        prob22 = 1- prob21;
        ")
      } 
             else if (TPs == 0.85) {
        glue("
        New(
        trans11*.70 trans12*.30 trans21*.5 trans22*.5
        prob11*.5 prob12*.5 prob21*.60 prob22*.4);
        trans11 = 1/(1+exp(-(par2+par11)));
        trans12 = 1-trans11;
        trans21 = 1/(1+exp(-par2));
        trans22 = 1- trans21;
        !marginal probabilities at T1 and T2:
        prob11 = 1/(1+exp(-par1));
        prob12 = 1 - prob11;
        prob21 = prob11*trans11+prob12*trans21;
        prob22 = 1- prob21;
        ")
              } 
            else  if (TPs == 0.41) {
        glue("
        New(
        trans11*.60 trans12*.40 trans21*.5 trans22*.5
        prob11*.5 prob12*.5 prob21*.55 prob22*.45);
        trans11 = 1/(1+exp(-(par2+par11)));
        trans12 = 1-trans11;
        trans21 = 1/(1+exp(-par2));
        trans22 = 1- trans21;
        !marginal probabilities at T1 and T2:
        prob11 = 1/(1+exp(-par1));
        prob12 = 1 - prob11;
        prob21 = prob11*trans11+prob12*trans21;
        prob22 = 1- prob21;
        ")
              } 
             else if (TPs == -0.41) {
        glue("
        New(
        trans11*.40 trans12*.60 trans21*.5 trans22*.5
        prob11*.5 prob12*.5 prob21*.45 prob22*.55);
        trans11 = 1/(1+exp(-(par2+par11)));
        trans12 = 1-trans11;
        trans21 = 1/(1+exp(-par2));
        trans22 = 1- trans21;
        !marginal probabilities at T1 and T2:
        prob11 = 1/(1+exp(-par1));
        prob12 = 1 - prob11;
        prob21 = prob11*trans11+prob12*trans21;
        prob22 = 1- prob21;
        ")
              } 
             else if (TPs == -0.85) {
        glue("
        New(
        trans11*.30 trans12*.70 trans21*.5 trans22*.5
        prob11*.5 prob12*.5 prob21*.40 prob22*.60);
        trans11 = 1/(1+exp(-(par2+par11)));
        trans12 = 1-trans11;
        trans21 = 1/(1+exp(-par2));
        trans22 = 1- trans21;
        !marginal probabilities at T1 and T2:
        prob11 = 1/(1+exp(-par1));
        prob12 = 1 - prob11;
        prob21 = prob11*trans11+prob12*trans21;
        prob22 = 1- prob21;
        ")
              } 
        
        else if (TPs == -1.385) {
        glue("
         New(
        trans11*.20 trans12*.80 trans21*.5 trans22*.5
        prob11*.5 prob12*.5 prob21*.35 prob22*.65);

        trans11 = 1/(1+exp(-(par2+par11)));
        trans12 = 1-trans11;
        trans21 = 1/(1+exp(-par2));
        trans22 = 1- trans21;
        !marginal probabilities at T1 and T2:
        prob11 = 1/(1+exp(-par1));
        prob12 = 1 - prob11;
        prob21 = prob11*trans11+prob12*trans21;
        prob22 = 1- prob21;")
      }
  )

  # Run Mplus model
  LTA_RILTA_Model<- mplusModeler(LTA_RILTA, 
                                   dataout = here('Simulations', 'STUDY_1', '2 Time Points', "2_2T_LTA_GEN_RILTA_ANALYZED_REP", glue("LTA_RILTA_N_{N_numeric}_TP_{TPs}_TH_1.dat")),
                                   modelout = glue(here('Simulations', 'STUDY_1', '2 Time Points', "2_2T_LTA_GEN_RILTA_ANALYZED_REP", "LTA_RILTA_N_{N_numeric}_TP_{TPs}_TH_1.inp")),
                                   check = TRUE, run = TRUE, hashfilename = FALSE)
return(LTA_RILTA_Model)
}

library(parallel)
# Start the cluster
num_cores <- detectCores() - 1

# Step 2: dplyr::select the cluster type based on the system (PSOCK for Windows, FORK for macOS/Linux)
cluster_type <- ifelse(.Platform$OS.type == "windows", "PSOCK", "FORK")


cl <- makeCluster(num_cores, type = cluster_type)

# Export necessary objects to the cluster
clusterExport(cl, c("lta_rilta_func", "violation_summary", "here", "glue", "mplusModeler", "mplusObject"))

# Ensure required libraries are loaded on each node
clusterEvalQ(cl, {
  library(MplusAutomation)
  library(glue)
  library(here)
})

result_list <- parLapply(cl, 1:nrow(violation_summary), function(i) {
  lta_rilta_func(
    violation_summary$N_numeric[i], 
    violation_summary$TPs[i],  
    violation_summary$Adjusted_Replications_Needed[i]
  )
})

# Stop the cluster after the simulation
stopCluster(cl)
```

------------------------------------------------------------------------

## Check for Label Switching and Errors - Part 2

> In this section: we re conduct the steps for aggregating the label switching and errors to guarantee that we will have at minimum 500 replications per condition.

------------------------------------------------------------------------

*Load all CSV files and combine them into a single data frame.*

```{r}
#| label: "combine-csv-files-parallel2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: false

# Step 1: Set the correct CSV directory
csv_directory <- here('Simulations', 'STUDY_1', '2 Time Points', '2_2T_LTA_GEN_RILTA_ANALYZED_REP')

# Step 2: Source the child document
source(here('Child_Docs', 'data_scraping.R'))

# Will populate combine_data in global environment
```

*Extract data from the appropriate rows from each 9-row chunk and prepare the data for further processing.*

```{r}
#| label: "scrape-rows-process-data-parallel2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: false

# Step 2: Process the data using the child script
source(here('Child_Docs', 'step2_2t_RILTA.R'))

final_combined_data <- final_combined_data %>%
  mutate(
    TRANS11 = as.numeric(TRANS11),
    SE_11 = as.numeric(SE_11),
    across(starts_with("Ec"), as.numeric),  # Convert all Ec columns
    ll_csv = as.numeric(ll_csv)  # Convert Log-Likelihood values
  )

# Will will populate final_combined data in global environment
```

*Convert the logits to probabilities and add the known actual values to each row.*

```{r}
#| label: "convert-logits-to-probabilities2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: false

# Step 3 and 4: Process the data and return results
source(here('Child_Docs', 'step_3.R'))

# The objects `final_data_with_actuals` and `violators` should now be in the global environment
```

*Scrape output files for errors*

```{r}
#| label: "process-out-files-parallel2"
#| echo: true
#| message: false
#| warning: false

# Step 1: Set the correct output directory for .out files
output_folder <- here('Simulations', 'STUDY_1', '2 Time Points', '2_2T_LTA_GEN_RILTA_ANALYZED_REP')

# Step 2: Source the child document that processes .out files
source(here('Child_Docs', 'out_scraping.R'))

# ===================================================== #
#  â SECTION 1 Generate Replication Summary Table
# ===================================================== #
replication_summary_table <- replication_summary %>%
  gt() %>%
  tab_header(
    title = "Replication Summary",
    subtitle = paste0("Folder: ", output_folder)
  ) %>%
  fmt_number(
    columns = c("Total", "Replicated_Yes", "Replicated_No", "Error_Count"),
    decimals = 0
  ) %>%
  cols_label(
    FileName = "File Name",
    Total = "Total Replications",
    Replicated_Yes = "LL Replicated",
    Replicated_No = "LL Not Replicated",
    Error_Count = "Errors"
  ) %>%
  cols_align(
    align = "center",
    columns = everything()
  ) %>%
  tab_options(
    table.font.size = "small",
    heading.title.font.size = "medium",
    heading.subtitle.font.size = "small",
    table.width = pct(80)
  )

# Display the table
replication_summary_table

# ===================================================== #
#  â SECTION 2 Row Count Validation
# ===================================================== #
cat("Rows in final_data_with_actuals:", nrow(final_data_with_actuals), "\n")
cat("Rows in final_results:", nrow(final_results), "\n")
cat("Rows in replication_summary:", nrow(replication_summary), "\n")

###CHECK EXTRA ROWS
# Identify extra rows that are in final_results but not in final_data_with_actuals
extra_rows <- anti_join(final_results, final_data_with_actuals, by = c("FileName", "Replication"))

# Check if all extra rows have ErrorFlag == 1
all_errors <- all(extra_rows$ErrorFlag == 1, na.rm = TRUE)

# Message instead of printing raw data
if (all_errors) {
  message("â All extra rows have errors (ErrorFlag == 1).")
} else {
  message("â ï¸ Some extra rows do NOT have errors. Manual inspection needed.")
}
```

Delete extra rows if necessary:

```{r}
#| label: "delete-extra-rows"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Identify extra rows that are in final_results but not in final_data_with_actuals
extra_rows <- anti_join(final_results, final_data_with_actuals, by = c("FileName", "Replication"))

# Filter to keep only extra rows where ErrorFlag == 1
rows_to_delete <- extra_rows %>% filter(ErrorFlag == 1)

# Delete only the extra rows with errors
if (nrow(rows_to_delete) > 0) {
  final_results <- anti_join(final_results, rows_to_delete, by = c("FileName", "Replication"))
  cat("â Deleted", nrow(rows_to_delete), "extra rows with errors.\n")
} else {
  cat("â No extra rows with errors were found. No deletions made.\n")
}

cat("Rows in final_data_with_actuals:", nrow(final_data_with_actuals), "\n")
cat("Rows in final_results:", nrow(final_results), "\n")

```

### Merge Errors with Main Data File

*Combine error information with main data file*

```{r}
#| label: "merge-errors2"
#| echo: true
#| message: false
#| warning: false

final_data_with_actuals <- final_data_with_actuals %>%
  left_join(
    final_results %>% dplyr::select(FileName, Replication, ll_out, LL_Replicated, ErrorFlag), 
    by = c("FileName", "Replication")
  ) %>%
  mutate(
    Any_Violation = ifelse(is.na(Any_Violation), 0, Any_Violation),
    ErrorFlag = ifelse(is.na(ErrorFlag), 0, ErrorFlag),
    LL_Replicated = ifelse(LL_Replicated == "Yes", 1, 0),  # â Convert Yes/No to 1/0

    # ð¹ Create a new True Violation column
    True_Violation = case_when(
      Any_Violation == 1 | ErrorFlag == 1 | LL_Replicated == 0 ~ 1,  # â At least one violation
      TRUE ~ 0
    )
  )

```

Visualize differences between ll_out and ll_csv

```{r}

ll_check <- final_data_with_actuals %>%
  mutate(diff = round(ll_out - ll_csv, 3)) %>%  # Round before counting
  count(diff)

ll_check_table <- ll_check %>%
  gt() %>%
  tab_header(
    title = "LL Difference Summary",
    subtitle = "Comparison of LL values between CSV and OUT files"
  ) %>%
  cols_label(
    diff = "LL Difference",
    n = "Count"
  ) %>%
  fmt_number(
    columns = diff,
    decimals = 3
  ) %>%
  cols_align(
    align = "center",
    columns = everything()
  ) %>%
  tab_options(
    table.font.size = "small",
    heading.title.font.size = "medium",
    heading.subtitle.font.size = "small",
    table.width = pct(50)
  )

# Display the table
ll_check_table
```

Create DF of LL differences from .out and .csv files for inspection at the replication level

```{r}
# Create a dataframe with only rows where ll_out and ll_csv differ
ll_mismatch <- final_data_with_actuals %>%
  mutate(diff = round(ll_out - ll_csv, 3)) %>%
  filter(diff != 0) %>%
  dplyr::select(FileName, Replication, ll_out, ll_csv, diff)


```

### *Create Column Names from the File Name*

```{r}
#| label: "create-column-names-from-filename2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: false

# Add new columns based on the information in the FileName and set factors
final_data_with_actuals <- final_data_with_actuals %>%
  mutate(
    # Extract the sample size (N) from the FileName with the correct values
    N = case_when(
      grepl("n_4000", FileName) ~ 4,  # Correct value for N_4000
      grepl("n_500", FileName) ~ 1,   
      grepl("n_1000", FileName) ~ 2,  
      grepl("n_2000", FileName) ~ 3,  
      TRUE ~ NA_integer_
    ),
    # Map the TPs from the FileName to the appropriate Population labels
    Population = case_when(
      grepl("tp_1.385", FileName) ~ ".800",
      grepl("tp_0.85", FileName) ~ ".700",
      grepl("tp_0.41", FileName) ~ ".600",
      grepl("tp_-0.41", FileName) ~ ".400",
      grepl("tp_-0.85", FileName) ~ ".300",
      grepl("tp_-1.385", FileName) ~ ".200",
      TRUE ~ NA_character_
    ),
    # Create the Transitions variable based on Population values
    Transitions = case_when(
      Population %in% c(".200", ".300", ".400") ~ 1,  # Assign 1 for Population .200, .300, .400
      Population %in% c(".600", ".700", ".800") ~ 2,  # Assign 2 for Population .600, .700, .800
      TRUE ~ NA_integer_
    )
  ) %>%
  # Convert columns to factors, ordering N_4000 first in the factor levels
  mutate(
    N = factor(N, levels = c(4, 1, 2, 3), labels = c("N = 4000", "N = 500", "N = 1000", "N = 2000")),
    Population = factor(Population, levels = c(".800", ".700", ".600", ".400", ".300", ".200")),
    Transitions = factor(Transitions, levels = c(1, 2), labels = c("Mover", "Stayer"))
  )
```

### *Calculate Violation Percentages per Condition*

```{r}
#| label: "calculate-violations2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: false

violation_summary2 <- final_data_with_actuals %>%
  mutate(
    N_numeric = as.numeric(gsub("N = ", "", as.character(N))),
    N_numeric = ifelse(is.na(N_numeric), 0, N_numeric)
  ) %>%
  group_by(FileName, Population, N, N_numeric) %>%
  summarize(
    Total_Rows = n(),
    Total_Violations = sum(Any_Violation, na.rm = TRUE),   
    Total_Errors = sum(ErrorFlag, na.rm = TRUE),           
    Total_LL_Failures = sum(LL_Replicated == 0, na.rm = TRUE),  
    Total_True_Violations = sum(True_Violation, na.rm = TRUE),  
    Percentage_Violations = round((Total_Violations / Total_Rows) * 100, 1),  
    True_Violation_Perc = round((Total_True_Violations / Total_Rows) * 100, 1),  
    ErrorRate = round((Total_Errors / Total_Rows) * 100, 1),  
    LL_Failure_Perc = round((Total_LL_Failures / Total_Rows) * 100, 1),  
    .groups = "drop"
  ) %>%
  mutate(
    GoodReplications = Total_Rows - Total_True_Violations,
    GoodReplications = ifelse(GoodReplications < 0, 0, GoodReplications),
    Reanalysis_Needed = if_else(GoodReplications >= 500, "No", "Yes"),
Adjusted_Replications_Needed = case_when(
  True_Violation_Perc >= 100 ~ NA_real_,
  TRUE ~ ceiling(500 / (1 - (True_Violation_Perc / 100 + 0.11)) + 55)
),
Adjusted_Replications_Needed = if_else(
  is.na(Adjusted_Replications_Needed) | Adjusted_Replications_Needed < 500, 
  500, 
  Adjusted_Replications_Needed
),
    TPs = case_when(
      Population == ".800" ~ 1.385,
      Population == ".700" ~ 0.85,
      Population == ".600" ~ 0.41,
      Population == ".400" ~ -0.41,
      Population == ".300" ~ -0.85,
      Population == ".200" ~ -1.385,
      TRUE ~ NA_real_
    )
  ) %>%
  arrange(factor(N_numeric, levels = c(500, 1000, 2000, 4000)), as.numeric(Population)) %>%
  mutate(
    N = factor(N, levels = c("N = 500", "N = 1000", "N = 2000", "N = 4000")),
    Population = factor(Population, levels = c(".200", ".300", ".400", ".600", ".700", ".800"))
  ) %>%
  dplyr::select(
    FileName, Population, N, N_numeric, TPs,  
    Total_Rows,  
    Total_Violations, Percentage_Violations,  
    Total_Errors, ErrorRate,  
    Total_LL_Failures, LL_Failure_Perc,  
    Total_True_Violations, True_Violation_Perc,  
    GoodReplications,  
    Reanalysis_Needed,
    Adjusted_Replications_Needed
  ) %>%
  arrange(N_numeric, Population) %>%
  mutate(N_numeric = trimws(as.numeric(N_numeric)))

# Write CSV
write.csv(violation_summary2, here("Simulations", "STUDY_1", "2 Time Points", 'zdata', "violation_summary2_l_r_2t.csv"), row.names = FALSE)
```

*Summarize & Visualize Label Switching Percentage Results*

```{r}
#| label: "summarize-violations-errors2"
#| echo: true
#| message: false
#| warning: false

create_flextable <- function(data) {
  
  # Ensure only the required columns are used
  data <- data %>%
    dplyr::select(
      N_numeric,  
      Population,  
      Total_Violations,
      Percentage_Violations,
      Total_Errors,
      ErrorRate,
      Total_LL_Failures,
      LL_Failure_Perc,
      Total_True_Violations,
      True_Violation_Perc,
      GoodReplications,
      Reanalysis_Needed
    ) %>%
    as.data.frame()  # Ensure proper structure before passing to flextable
  
  # Create the flextable
  ft <- flextable(data) %>%
    set_header_labels(
      N_numeric = "N",
      Population = "T11",  
      Total_Violations = "V",
      Percentage_Violations = "V %",
      Total_Errors = "\u03B5",  
      ErrorRate = "\u03B5 %",
      Total_LL_Failures = "ââ",  
      LL_Failure_Perc = "ââ %",
      Total_True_Violations = "\u03C4áµ¥",  
      True_Violation_Perc = "\u03C4áµ¥ %",
      GoodReplications = "Good Reps",
      Reanalysis_Needed = "Reanalysis Needed"
    )

  # Apply special formatting to headers
  ft <- compose(ft, part = "header", j = "N_numeric", value = as_paragraph(as_i("N")))
  ft <- compose(ft, part = "header", j = "Population", value = as_paragraph(as_i("T"), as_sub("11")))

  # Label Switching Violations
  ft <- compose(ft, part = "header", j = "Total_Violations", value = as_paragraph(as_i("V")))
  ft <- compose(ft, part = "header", j = "Percentage_Violations", value = as_paragraph(as_i("V"), "%"))

  # Mplus Errors
  ft <- compose(ft, part = "header", j = "Total_Errors", value = as_paragraph(as_i("\u03B5")))
  ft <- compose(ft, part = "header", j = "ErrorRate", value = as_paragraph(as_i("\u03B5"), "%"))

  # LL Replication Failures
  ft <- compose(ft, part = "header", j = "Total_LL_Failures", value = as_paragraph(as_i("â"), as_sub("r")))  
  ft <- compose(ft, part = "header", j = "LL_Failure_Perc", value = as_paragraph(as_i("â"), as_sub("r"), "%"))

  # True Violations
  ft <- compose(ft, part = "header", j = "Total_True_Violations", value = as_paragraph(as_i("\u03C4"), as_sub("v")))  
  ft <- compose(ft, part = "header", j = "True_Violation_Perc", value = as_paragraph(as_i("\u03C4"), as_sub("v"), "%"))  

  # Good Replications and Reanalysis Needed
  ft <- compose(ft, part = "header", j = "GoodReplications", value = as_paragraph("Good", "\n", "Reps"))
  ft <- compose(ft, part = "header", j = "Reanalysis_Needed", value = as_paragraph("Reanalysis", "\n", "Needed?"))

  # Apply width settings
  ft <- width(ft, j = "N_numeric", width = 1.0)
  ft <- width(ft, j = "Population", width = 0.6)  
  ft <- width(ft, j = "Total_Violations", width = 0.6)
  ft <- width(ft, j = "Percentage_Violations", width = 0.6)
  ft <- width(ft, j = "Total_Errors", width = 0.5)
  ft <- width(ft, j = "ErrorRate", width = 0.5)
  ft <- width(ft, j = "Total_LL_Failures", width = 0.6)
  ft <- width(ft, j = "LL_Failure_Perc", width = 0.6)
  ft <- width(ft, j = "Total_True_Violations", width = 0.6)
  ft <- width(ft, j = "True_Violation_Perc", width = 0.6)
  ft <- width(ft, j = "GoodReplications", width = 0.6)
  ft <- width(ft, j = "Reanalysis_Needed", width = 0.7)

  ft <- colformat_num(
  ft,
  j = c("Percentage_Violations", "ErrorRate", "LL_Failure_Perc", "True_Violation_Perc" ),  
  suffix = "%"  # â Adds percentage symbol
)
  # Add padding below the subheaders
#ft <- ft %>%
 # padding(part = "header", padding = c(0, 0, 6, 0))  # Adjust as needed for top, right, bottom, and left padding

  # Enable autofit
  ft <- set_table_properties(ft, layout = "fixed")

  # Center all cells
  ft <- align(ft, align = "center", part = "all")

  # Align header text at the bottom of the cells
  #ft <- valign(ft, part = "header", valign = "bottom")

  # Merge vertically identical rows in the "N_numeric" column
  ft <- merge_v(ft, j = "N_numeric")

  # Apply font to the entire table
  ft <- font(ft, fontname = "Avenir Next LT Pro", part = "all")

  ft <- compose(
    ft,
    part = "body",
    j = "N_numeric",
    i = ~ !duplicated(N_numeric),
    value = as_paragraph(
      as_i("N"),  
      " =\u2009",  # THIN SPACE (Unicode U+2009)
      as.character(format(N_numeric, big.mark = ",", scientific = FALSE))  # Keeps proper formatting
    )
  )

  # Add subheader row
  ft <- add_header_row(
    ft,
    values = c("N Reps = Varies", "Violations", "Errors", "LL Replication", "True Violations", "Success?"),  
    colwidths = c(2, 2, 2, 2, 2, 2)  
  )

  # Define a transparent border
  no_border <- fp_border(color = "transparent", width = 0)

  # **Remove ONLY the bottom border under the first three columns (the blank subheader)**
  ft <- hline(ft, i = 1, j = 1:2, border = no_border, part = "header")

  # Adding color with a correct method
  total_rows <- nrow(data)  # Get the total number of rows in your data
  color_rows <- rep(FALSE, total_rows)  # Initialize a logical vector for coloring rows
  for (i in seq(1, total_rows, by = 12)) {
    color_rows[i:(i+5)] <- TRUE  # Apply color to every 6 rows
  }

  # Apply background color with a lighter shade of gray
  ft <- bg(ft, i = color_rows, bg = "#f0f0f0", part = "body")

  return(ft)
}
  
# Generate formatted flextables for each subset
violation_summary_table2 <- create_flextable(violation_summary2)
violation_summary_table2

```

```{r}
#| label: "render-violation-tables"
#| echo: true
#| message: false
#| warning: false

save_as_image(violation_summary_table, path = here('Simulations', 'STUDY_1', "2 Time Points", "zErrors", "zl_r_e&v_2.svg")
   )
```

### Prepare data for Submission Table

```{r}
#| label: "prepare-data-final-table"
#| echo: true
#| message: false
#| warning: false

# Step 1: Rename columns in violation_summary2 (except join keys)
violation_summary2 <- violation_summary2 %>%
  rename_with(~ paste0(.x, "_2"), 
              -c(Population, N, N_numeric))  # â Remove FileName from keys

# Step 2: Merge both datasets on common keys
violation_summary_final <- violation_summary %>%
  left_join(violation_summary2, by = c("Population", "N", "N_numeric")) %>%  # â Remove FileName from join
  mutate(
    Total_Rows = Total_Rows,

    # Initial and Final Violation Rates
    Violation_Rate = Percentage_Violations,  
    Final_Violation_Rate = Percentage_Violations_2,

    # Initial and Final LL Failure Rates
    LL_Failure_Rate = LL_Failure_Perc,
    Final_LL_Failure_Rate = LL_Failure_Perc_2,

    # Initial and Final Error Rates
    Error_Rate = ErrorRate,
    Final_Error_Rate = ErrorRate_2,

    # â NEW: Initial and Final True Violation Rates
    True_Violation_Rate = True_Violation_Perc,
    Final_True_Violation_Rate = True_Violation_Perc_2,

    # Replications & Success
    Reps_Needed_for_Success = Adjusted_Replications_Needed,
    Successful_Replications = GoodReplications_2,

    # Status: Check if we achieved 500+ successful replications
    Status = if_else(Successful_Replications >= 500, "â Fixed", "â ï¸ Additional Runs Required")
  ) %>%
  dplyr::select(
    N_numeric, Population, Total_Rows, 
    Violation_Rate, LL_Failure_Rate, Error_Rate, True_Violation_Rate,  # â Initial Rates
    Final_Violation_Rate, Final_LL_Failure_Rate, Final_Error_Rate, Final_True_Violation_Rate,  # â Final Rates
    Reps_Needed_for_Success, Successful_Replications, Status  # â Success Metrics
  ) %>%
  arrange(factor(N_numeric, levels = c(500, 1000, 2000, 4000)), Population) %>%
  mutate(N_numeric = trimws(as.numeric(N_numeric)))

# Write CSV
write.csv(violation_summary_final, here("Simulations", "STUDY_1", "2 Time Points", 'zdata', "violation_summary_final_l_r_2t.csv"), row.names = FALSE)
```

### Create flextable Function for Final Table

```{r}
#| label: "creat-final-error-table"
#| echo: true
#| message: false
#| warning: false

violation_summary_final <- read.csv(
  here("Simulations", "STUDY_1", "2 Time Points", "zdata", "violation_summary_final_l_r_2t.csv")
)

create_flextable <- function(data) {
  
  # Keep only the required columns
  data <- data %>%
  dplyr::select(
      N_numeric,  
      Population,  
      Violation_Rate,
      LL_Failure_Rate,
      Error_Rate,
      True_Violation_Rate,   # â NEW
      Reps_Needed_for_Success,
      Final_Violation_Rate,
      Final_LL_Failure_Rate,
      Final_Error_Rate,
      Final_True_Violation_Rate,   # â NEW
      Successful_Replications
    ) %>%
    as.data.frame()  

  # Create the flextable
  ft <- flextable(data) %>%
    set_header_labels(
      N_numeric = "N",
      Population = "T11",  
      Violation_Rate = "V %",
      LL_Failure_Rate = "ââ %",
      Error_Rate = "\u03B5 %",
      True_Violation_Rate = "\u03C4áµ¥ %",   # â NEW
      Reps_Needed_for_Success = "Reps Needed",
      Final_Violation_Rate = "V %",
      Final_LL_Failure_Rate = "ââ %",
      Final_Error_Rate = "\u03B5 %",
      Final_True_Violation_Rate = "\u03C4áµ¥ %",  # â NEW
      Successful_Replications = "Successful Reps"
    ) %>%
    compose(part = "header", j = "N_numeric", value = as_paragraph(as_i("N"))) %>%
    compose(part = "header", j = "Population", value = as_paragraph(as_i("T"), as_sub("11"))) %>%
    compose(part = "header", j = "Violation_Rate", value = as_paragraph(as_i("V"), "%")) %>%
    compose(part = "header", j = "LL_Failure_Rate", value = as_paragraph(as_i("â"), as_sub("r"), "%")) %>%
    compose(part = "header", j = "Error_Rate", value = as_paragraph(as_i("\u03B5"), "%")) %>%
    compose(part = "header", j = "True_Violation_Rate", value = as_paragraph(as_i("\u03C4"), as_sub("v"), "%")) %>%
    compose(part = "header", j = "Final_Violation_Rate", value = as_paragraph(as_i("V"), "%")) %>%
    compose(part = "header", j = "Final_LL_Failure_Rate", value = as_paragraph(as_i("â"), as_sub("r"), "%")) %>%
    compose(part = "header", j = "Final_Error_Rate", value = as_paragraph(as_i("\u03B5"), "%")) %>%
    compose(part = "header", j = "Final_True_Violation_Rate", value = as_paragraph(as_i("\u03C4"), as_sub("v"), "%")) %>%
    compose(part = "header", j = "Reps_Needed_for_Success", value = as_paragraph("Reps", "\n", "Needed")) %>%
    compose(part = "header", j = "Successful_Replications", value = as_paragraph("Final", "\n", "Reps")) %>%
    width(j = "N_numeric", width = .6) %>%
    width(j = "Population", width = 0.6) %>%
    width(j = "Violation_Rate", width = 0.6) %>%
    width(j = "LL_Failure_Rate", width = 0.6) %>%
    width(j = "Error_Rate", width = 0.4) %>%
    width(j = "True_Violation_Rate", width = 0.6) %>%
    width(j = "Reps_Needed_for_Success", width = .8) %>%
    width(j = "Final_Violation_Rate", width = 0.6) %>%
    width(j = "Final_LL_Failure_Rate", width = 0.6) %>%
    width(j = "Final_Error_Rate", width = 0.4) %>%
    width(j = "Final_True_Violation_Rate", width = 0.6) %>%
    width(j = "Successful_Replications", width = .6)

  # Merge N blocks and vertically center
  ft <- merge_v(ft, j = "N_numeric") %>%
    compose(
      part = "body",
      j = "N_numeric",
      i = setdiff(1:nrow(data), seq(1, nrow(data), by = 6)),
      value = as_paragraph("")
    ) %>%
    valign(j = "N_numeric", valign = "center", part = "body")

# Add top grouped header row
ft <- add_header_row(
  ft,
  values = c(" ", "Initial 500 Replications", " ", "Adjusted Replications", " "),
  colwidths = c(2, 4, 1, 4, 1)
)

  # Format numeric columns as %
  ft <- colformat_num(
    ft,
    j = c("Violation_Rate", "LL_Failure_Rate", "Error_Rate", "True_Violation_Rate",
          "Final_Violation_Rate", "Final_LL_Failure_Rate", "Final_Error_Rate", "Final_True_Violation_Rate"),
    suffix = "%"
  )

  # Color every 6-row block
  total_rows <- nrow(data)
  color_rows <- rep(FALSE, total_rows)
  for (i in seq(1, total_rows, by = 12)) {
    color_rows[i:(i+5)] <- TRUE
  }
  ft <- bg(ft, i = color_rows, bg = "#f0f0f0", part = "body")

thin <- fp_border(color = "black", width = 1)

ft <- ft %>%
  border_remove() %>%

  # â Reapply group-specific bottom borders manually
  border(i = 1, j = 3:6, part = "header", border.bottom = thin) %>%   # Under "Initial 500 Replications"
  border(i = 1, j = 8:11, part = "header", border.bottom = thin) %>%  # Under "Adjusted Replications"

  # â Add top + bottom of entire table (APA lines)
  hline_top(border = thin, part = "all") %>%
  hline_bottom(border = thin, part = "all") %>%

  # â Clean font, layout, and alignment
  font(fontname = "Avenir Next", part = "all") %>%
  fontsize(size = 14, part = "all") %>%
  align(align = "center", part = "all") %>%
  set_table_properties(layout = "fixed")


  return(ft)
}

# Generate formatted flextable
violation_summary_final_table <- create_flextable(violation_summary_final)
violation_summary_final_table

```

Save FINAL table

```{r}

invisible(save_as_image(violation_summary_final_table, path = here('Simulations', 'STUDY_1', "2 Time Points", "zErrors", "zl_r_e&v_FINAL.svg")
   ))
```

# Run True Violation ANOVA

```{r}
#| label: "violator-anova"
#| echo: true
#| message: false
#| warning: false
#| fig.width: 6
#| fig.height: 4

# Load libraries
library(ggplot2)
library(emmeans)
library(dplyr)
library(here)
library(car) # MODIFIED: Added for Type 3 SS
library(effectsize) # MODIFIED: Moved earlier for clarity

# Load data
violation_summary_final <- read.csv(
  here("Simulations", "STUDY_1", "2 Time Points", "zdata", "violation_summary_final_l_r_2t.csv")
) %>%
  filter(!is.na(Population), !is.na(N_numeric)) %>%
  mutate(
    Population = factor(Population,
                        levels = c(0.2, 0.3, 0.4, 0.6, 0.7, 0.8),
                        labels = c(".200", ".300", ".400", ".600", ".700", ".800")),
    N_numeric = factor(N_numeric)
  )

# Run ANOVA without interaction
anova_main <- aov(Final_True_Violation_Rate ~ N_numeric + Population, data = violation_summary_final)
anova_main_type3 <- Anova(anova_main, type = "III") # MODIFIED: Compute Type 3 SS
print(anova_main_type3) # MODIFIED: Print Type 3 ANOVA

# Get partial eta squared
eta_squared(anova_main_type3, partial = TRUE) # MODIFIED: Use Type 3 output

# Pairwise comparisons
em <- emmeans(anova_main, pairwise ~ Population)
pairwise_results <- summary(em$contrasts, infer = TRUE)

# Plot
violation_plot <- ggplot(violation_summary_final, aes(x = Population, y = Final_True_Violation_Rate, fill = N_numeric)) +
  stat_summary(fun = mean, geom = "bar", position = position_dodge(0.8), width = 0.7) +
  stat_summary(fun.data = mean_se, geom = "errorbar", position = position_dodge(0.8), width = 0.2) +
  labs(
    x = expression(italic(T)[11]),
    y = "Final True Violation Rate (%)",
    fill = expression(italic(N))
  ) +
  scale_y_continuous(limits = c(0, 100)) +
  theme_minimal(base_size = 12) +
  theme(
    #axis.title = element_text(face = "bold"),
    text = element_text(family = "Avenir Next"),
    legend.position = "bottom",
    #legend.title = element_text(face = "bold"),
    legend.text = element_text(size = 10)
  )

print(violation_plot)
```

Save Violations ANOVA fibure

```{r}
#| label: "save-violator-figure"
#| echo: true
#| message: false
#| warning: false

invisible(ggsave(
  filename = here("Simulations", "STUDY_1", "2 Time Points", "zposthoc", "l_r_2t_violation_visuals", "l_r_2t_violation_plot.svg"),
  plot = violation_plot,
  width = 7,
  height = 5,
  units = "in",
  dpi = 300
))

```

**Create Pairwise Comparisons Table**

```{r}
#| label: "pairwise-comparisons"
#| echo: true
#| message: false
#| warning: false

library(flextable)
library(dplyr)
library(stringr)
library(officer)

# Optional global default
set_flextable_defaults(word_wrap = FALSE)

#---------------------------
# STEP 1: Process pairwise_results
#---------------------------

pairwise_df <- as.data.frame(pairwise_results)

pairwise_df <- pairwise_df %>%
  mutate(
    Estimate   = round(as.numeric(estimate), 2),
    SE         = round(as.numeric(SE), 2),
    Lower_CL   = round(as.numeric(lower.CL), 2),
    Upper_CL   = round(as.numeric(upper.CL), 2),
    t_val      = round(as.numeric(t.ratio), 2),
    p_val      = round(as.numeric(p.value), 3),
    p          = ifelse(p_val < .001, "< .001", sub("^0", "", format(p_val, nsmall = 3))),
    Effect     = paste0(
      format(Estimate, nsmall = 2), " (",
      format(Lower_CL, nsmall = 2), ", ",
      format(Upper_CL, nsmall = 2), ")"
    )
  )

pairwise_clean <- pairwise_df[, c("contrast", "Effect", "SE", "df", "t_val", "p")]
colnames(pairwise_clean)[which(names(pairwise_clean) == "t_val")] <- "t"

#---------------------------
# STEP 2: Format contrast labels
#---------------------------

left_right <- str_match(pairwise_clean$contrast, "Population\\.(\\d{3}) - Population\\.(\\d{3})")

ft <- flextable(pairwise_clean) |>
  compose(
    j = "contrast",
    part = "body",
    value = as_paragraph(
      as_i("T"), as_sub("11"), " = .", left_right[, 2],
      " â ",
      as_i("T"), as_sub("11"), " = .", left_right[, 3]
    )
  ) |>
  set_header_labels(
    contrast = "Contrast",
    Effect   = "Estimate (95% CI)",
    SE       = "SE",
    df       = "df",
    t        = "t",
    p        = "p"
  ) |>
  compose(part = "header", j = "SE", value = as_paragraph(as_i("SE"))) |>
  compose(part = "header", j = "df", value = as_paragraph(as_i("df"))) |>
  compose(part = "header", j = "t",  value = as_paragraph(as_i("t"))) |>
  compose(part = "header", j = "p",  value = as_paragraph(as_i("p"))) |>
  colformat_num(j = "SE", digits = 2, align = "decimal") |>
  colformat_num(j = "t", digits = 2, align = "decimal") |>
  align(j = c("contrast", "Effect", "df", "p"), align = "center", part = "all") |>
  width(j = "contrast", width = 2.2) |>
  width(j = "Effect", width = 2.5) |>
  line_spacing(space = 0.9, part = "all") |>
  padding(j = "contrast", padding.top = 1, padding.bottom = 1, part = "all")

#---------------------------
# STEP 3: Bold significant p-values
#---------------------------

sig_rows <- which(pairwise_df$p_val < 0.05)
ft <- bold(ft, i = sig_rows, j = "p", bold = TRUE, part = "body")

#---------------------------
# STEP 4: APA styling
#---------------------------

theme_apa_flex <- function(ft_object) {
  thin <- fp_border(color = "black", width = 1)

  ft_object <- ft_object |>
    border_remove() |>
    font(fontname = "Avenir Next", part = "all") |>
    fontsize(size = 12, part = "all") |>
    align(align = "center", part = "all") |>
    set_table_properties(layout = "fixed") |>
    hline(i = 1, border = thin, part = "header") |>
    hline_top(border = thin, part = "all") |>
    hline_bottom(border = thin, part = "all")
}

ft <- theme_apa_flex(ft)

#---------------------------
# FINAL OUTPUT
#---------------------------

ft


```

Save Pairwise Table

```{r}
#| label: "save-comparisons-table"
#| echo: false
#| message: false
#| warning: false
invisible(save_as_image(
  ft,  # your flextable object
  path = here("Simulations", "STUDY_1", "2 Time Points", "zposthoc", "l_r_2t_violation_visuals", "l_r_2t_t11_pairwise.svg")
))

```

------------------------------------------------------------------------

# Final Data Preparation

------------------------------------------------------------------------

## Filter Cases with Violations and Errors

*Filter out cases with any violations, leaving only the clean data.*

```{r}
#| label: "delete-cases"
#| echo: true
#| message: false
#| warning: false
#| code-fold: false

# Filter out cases with no violations and no errors
filtered_data_with_no_violations <- final_data_with_actuals[
  final_data_with_actuals$True_Violation == 0, ]


# Check the number of remaining rows after filtering
cat("Remaining rows after filtering:", nrow(filtered_data_with_no_violations), "\n")

# Verify if there are any remaining violations or errors
cat("Any remaining violations:", sum(filtered_data_with_no_violations$Any_Violation), "\n")
cat("Any remaining errors:", sum(filtered_data_with_no_violations$ErrorFlag), "\n")
```

### Calculate Monte Carlo Values via Bootstrapping

*Calculate Monte Carlo values forÂ `TRANS11`, including population values, averages, standard errors, Mean Squared Error (MSE), coverage, power, and dichotomous variables for Power and Coverage,*

```{r}
library(dplyr)
library(purrr)

# 1. Create a function that calculates mc_values from raw replication-level data
calc_mc_values <- function(data) {
  # Step A: Clean and convert columns as needed
  cleaned_data <- data %>%
    mutate(
      Population = as.numeric(as.character(Population)),
      TRANS11 = as.numeric(as.character(TRANS11)),
      SE_11 = as.numeric(as.character(SE_11))
    )
  
  # Step B: Compute group-level summaries (without grouping by Transitions)
  mc_values <- cleaned_data %>%
    group_by(Population, N) %>%
    summarize(
      group_size   = n(),
      average      = round(mean(TRANS11, na.rm = TRUE), 3),
      average_SE   = round(mean(SE_11, na.rm = TRUE), 3),
      population_sd= round(sd(TRANS11, na.rm = TRUE), 3),
      MSE          = round(mean((TRANS11 - Population)^2, na.rm = TRUE), 3),
      Coverage     = round(mean((Population >= (TRANS11 - 1.96 * SE_11)) &
                                  (Population <= (TRANS11 + 1.96 * SE_11)), na.rm = TRUE), 3),
      Power        = round(mean(TRANS11 / SE_11 > 1.96, na.rm = TRUE), 3),
      Reps_Used    = n(),
      .groups = "drop"
    )
  
  # Step C: Merge in Transitions from the raw data (or from an auxiliary table if needed)
  mc_values <- cleaned_data %>%
    dplyr::select(FileName, Population, N, Transitions) %>%
    distinct() %>%
    right_join(mc_values, by = c("Population", "N"))
  
  # Step D: Calculate bias measures
  mc_values <- mc_values %>%
    mutate(
      Parameter_Bias_boot = round((average - Population) / Population * 100, 2),
      SE_Bias_boot        = round((average_SE - population_sd) / (population_sd + 1e-6) * 100, 2)
    )
  
  # (Optional: add any further transformations or dichotomizations)
  
  return(mc_values)
}

# 2. Create a parallelized bootstrap function that uses the above calculation on bootstrap samples
bootstrap_mc_values <- function(data, n_bootstrap, sample_size) {
  
  # Step A: Detect available cores and create a parallel cluster
  num_cores <- detectCores() - 1  # Use one less than total cores to avoid overloading the system
  cluster_type <- ifelse(.Platform$OS.type == "windows", "PSOCK", "FORK")  # Use FORK for Mac/Linux, PSOCK for Windows
  cl <- makeCluster(num_cores, type = cluster_type)  # Create the cluster
  
  # Step B: Export necessary functions and objects to the cluster workers
  clusterExport(cl, c("calc_mc_values", "sample_n", "%>%", "filtered_data_with_no_violations"))
  clusterEvalQ(cl, { library(dplyr) })  # Ensure each worker loads the required package

  # Step C: Group data by condition variables (Population, N, Transitions)
  grouped_data <- data %>%
    group_by(Population, N, Transitions) %>%
    group_split()  # Split data so each group runs separately in parallel
  
  # Step D: Perform bootstrapping in parallel across worker nodes
  boot_results <- parLapply(cl, grouped_data, function(group_data) {
    map_dfr(1:n_bootstrap, function(i) {
      # Step D1: Draw a bootstrap sample (with replacement) from the replications in this condition
      boot_sample <- group_data %>% sample_n(sample_size, replace = TRUE)
      
      # Step D2: Calculate MC values for the bootstrap sample
      boot_mc <- calc_mc_values(boot_sample)
      
      # Step D3: Add Bootstrap Iteration number
      boot_mc %>% mutate(Bootstrap_Iteration = i)
    })
  }) %>%
    bind_rows()  # Step E: Combine results from all parallel workers into a single dataframe

  # Step F: Stop the parallel cluster to free system resources
  stopCluster(cl)

  # Step G: Return the final bootstrapped MC values
  return(boot_results)
}

# 3. Run the bootstrap procedure on your raw replication-level data
set.seed(07252005)
boot_results <- bootstrap_mc_values(filtered_data_with_no_violations, n_bootstrap = 1000, sample_size = 500)

# 4. Aggregate the bootstrap results to get mean bootstrap estimates per condition:
bootstrap_aggregates <- boot_results %>%
  group_by(Population, N, Transitions) %>%
  summarize(
    Parameter_Bias = mean(Parameter_Bias_boot, na.rm = TRUE),
    SE_Bias       = mean(SE_Bias_boot, na.rm = TRUE),
    .groups = "drop"
  )

# 5. Calculate your original mc_values (using the full replication set) for comparison:
original_mc_values <- calc_mc_values(filtered_data_with_no_violations)

# 6. Merge the bootstrap aggregates back to the original values (if desired)
final_mc_values <- original_mc_values %>%
  left_join(bootstrap_aggregates, by = c("Population", "N", "Transitions")) %>%
  mutate(
    Power_Dic    = ifelse(Power >= 0.8, 1, 0),
    Coverage_Dic = ifelse(Coverage > 0.98 | Coverage < 0.91, 0, 1)
  )

# Save or inspect the results
# Save results
write.csv(final_mc_values, here("Simulations", "STUDY_1", "2 Time Points", "zbootstrapping", "l_r_2t_mc_final_mc_values.csv"), row.names = FALSE)
write.csv(boot_results, here("Simulations", "STUDY_1", "2 Time Points", "zbootstrapping", "l_r_2t_boot_results.csv"), row.names = FALSE)

```

# RUN Parameter Bias ANOVA

```{r}
#| label: "parameter-bias-anova"
#| echo: true
#| message: false
#| warning: false
#| fig-width: 6
#| fig-height: 4

library(ggplot2)
library(emmeans)
library(dplyr)
library(here)
library(stringr)
library(car)        # For aov() and Anova()
library(effectsize) # For eta_squared()

# Load the final MC aggregate data
final_mc_values <- read.csv(here("Simulations", "STUDY_1", "2 Time Points", "zbootstrapping", "l_r_2t_mc_final_mc_values.csv")) %>%
  filter(!is.na(Population), !is.na(N)) %>%
  mutate(
    Population = factor(Population,
                        levels = c(0.2, 0.3, 0.4, 0.6, 0.7, 0.8),
                        labels = c(".200", ".300", ".400", ".600", ".700", ".800")),
    N_numeric = as.numeric(str_remove(N, "N = ")),
    N = factor(str_remove(N, "N = "), levels = c("500", "1000", "2000", "4000"))
  )


# Run ANOVA on final Parameter_Bias
anova_bias <- aov(Parameter_Bias ~ N + Population, data = final_mc_values) # FIXED: Use N (factor) instead of N_numeric
anova_bias_type3 <- Anova(anova_bias, type = "III")
print(anova_bias_type3)

# Calculate effect sizes (partial eta-squared)
print(eta_squared(anova_bias_type3, partial = TRUE))

# Pairwise comparisons for Population
em_bias <- emmeans(anova_bias, pairwise ~ Population)
pairwise_bias_results <- summary(em_bias$contrasts, infer = TRUE)

# Pairwise comparisons for N
em_bias_N <- emmeans(anova_bias, pairwise ~ N)
pairwise_bias_N_results <- summary(em_bias_N$contrasts, infer = TRUE)


bias_plot <- ggplot(final_mc_values, aes(x = Population, y = Parameter_Bias, fill = N)) +
  stat_summary(fun = mean, geom = "bar", position = position_dodge(0.8), width = 0.7) +
  labs(
    x = expression(italic(T)[11]),
    y = "Parameter Bias (%)",
    fill = expression(italic(N))
  ) +
  scale_y_continuous(limits = c(-5, 5)) +
  theme_minimal(base_size = 12) +
  theme(
    axis.title = element_text(face = "plain"),
    text = element_text(family = "Avenir Next"),
    legend.position = "bottom",
    legend.title = element_text(face = "plain"),
    legend.text = element_text(size = 10)
  )

print(bias_plot)
```

Save bias figure

```{r}
#| label: "save-bias-figure"
#| echo: true
#| message: false
#| warning: false

invisible(ggsave(
  filename = here("Simulations", "STUDY_1", "2 Time Points", "zposthoc", "l_r_2t_bias_visuals", "l_r_2t_bias_plot.svg"),
  plot = bias_plot,
  width = 7,
  height = 5,
  units = "in",
  dpi = 300
))


```

**Create Pairwise Comparisons Table**

```{r}
#| label: "anova-pairwise-comparisons"
#| echo: true
#| message: false
#| warning: false

library(flextable)
library(dplyr)
library(stringr)
library(officer)

# Optional global default
set_flextable_defaults(word_wrap = FALSE)

#---------------------------
# STEP 1: Process pairwise_bias_results
#---------------------------

pairwise_df <- as.data.frame(pairwise_bias_results) %>%
  dplyr::mutate(
    Estimate   = round(as.numeric(estimate), 2),
    SE         = round(as.numeric(SE), 2),
    Lower_CL   = round(as.numeric(lower.CL), 2),
    Upper_CL   = round(as.numeric(upper.CL), 2),
    t_val      = round(as.numeric(t.ratio), 2),
    p_val      = round(as.numeric(p.value), 3),
    p          = ifelse(p_val < .001, "< .001", sub("^0", "", format(p_val, nsmall = 3))),
    Effect     = paste0(
      format(Estimate, nsmall = 2), " (",
      format(Lower_CL, nsmall = 2), ", ",
      format(Upper_CL, nsmall = 2), ")"
    )
  )

#---------------------------
# STEP 2: Format contrast labels in data frame
#---------------------------

# Extract left and right values
left_right <- str_match(pairwise_df$contrast, "Population\\.(\\d{3}) - Population\\.(\\d{3})")

# Create plain text contrast labels for mutate
pairwise_df <- pairwise_df %>%
  dplyr::mutate(
    contrast_formatted = paste0("Tââ = .", left_right[, 2], " - Tââ = .", left_right[, 3])
  )

#---------------------------
# STEP 3: Select columns for table
#---------------------------

pairwise_clean <- pairwise_df %>%
  dplyr::select(contrast_formatted, Effect, SE, df, t_val, p) %>%
  dplyr::rename(
    Contrast = contrast_formatted,
    t = t_val
  )

#---------------------------
# STEP 3.5: Define significant rows for bolding (p < .05)
#---------------------------

# Use the numeric p_val column to identify rows where p < .05
sig_rows <- which(pairwise_df$p_val < .05)

#---------------------------
# STEP 4: Create minimal flextable
#---------------------------

ft_bias <- flextable(pairwise_clean) %>%
  set_header_labels(
    Contrast = "Contrast",
    Effect   = "Estimate (95% CI)",
    SE       = "SE",
    df       = "df",
    t        = "t",
    p        = "p"
  ) %>%
  compose(part = "header", j = "SE", value = as_paragraph(as_i("SE"))) %>%
  compose(part = "header", j = "df", value = as_paragraph(as_i("df"))) %>%
  compose(part = "header", j = "t", value = as_paragraph(as_i("t"))) %>%
  compose(part = "header", j = "p", value = as_paragraph(as_i("p"))) %>%
  compose(
    j = "Contrast",
    value = as_paragraph(
      as_i("T"), "ââ = .", left_right[, 2], " â ",
      as_i("T"), "ââ = .", left_right[, 3]
    )
  ) %>%
  colformat_double(j = c("SE", "t"), digits = 2) %>%
  align(j = c("Contrast", "Effect", "df", "p"), align = "center", part = "all") %>%
  width(j = "Contrast", width = 2.2) %>%
  width(j = "Effect", width = 2.5) %>%
  line_spacing(space = 0.9, part = "all") %>%
  padding(j = "Contrast", padding.top = 1, padding.bottom = 1, part = "all") %>%
  bold(i = sig_rows, j = "p", bold = TRUE, part = "body") %>%
  border_remove() %>%
  font(fontname = "Avenir Next", part = "all") %>%
  fontsize(size = 12, part = "all") %>%
  align(align = "center", part = "all") %>%
  set_table_properties(layout = "fixed") %>%
  hline(i = 1, border = fp_border(color = "black", width = 1), part = "header") %>%
  hline_top(border = fp_border(color = "black", width = 1), part = "all") %>%
  hline_bottom(border = fp_border(color = "black", width = 1), part = "all")

#---------------------------
# FINAL OUTPUT
#---------------------------

ft_bias
```

Create N Bias Pairwise Table

```{r}
#| label: "anova-pairwise-comparisons-N"
#| echo: true
#| message: false
#| warning: false

library(flextable)
library(dplyr)
library(stringr)
library(officer)

# Optional global default
set_flextable_defaults(word_wrap = FALSE)

#---------------------------
# STEP 1: Process pairwise_bias_N_results
#---------------------------

pairwise_N_df <- as.data.frame(pairwise_bias_N_results) %>%
  dplyr::mutate(
    Estimate   = round(as.numeric(estimate), 2),
    SE         = round(as.numeric(SE), 2),
    Lower_CL   = round(as.numeric(lower.CL), 2),
    Upper_CL   = round(as.numeric(upper.CL), 2),
    t_val      = round(as.numeric(t.ratio), 2),
    p_val      = round(as.numeric(p.value), 3),
    p          = ifelse(p_val < .001, "< .001", sub("^0", "", format(p_val, nsmall = 3))),
    Effect     = paste0(
      format(Estimate, nsmall = 2), " (",
      format(Lower_CL, nsmall = 2), ", ",
      format(Upper_CL, nsmall = 2), ")"
    )
  )

#---------------------------
# STEP 2: Format contrast labels in data frame
#---------------------------

# Extract left and right values, stripping N prefix
left_right <- str_match(pairwise_N_df$contrast, "N(\\d+)\\s*-\\s*N(\\d+)")

# Create formatted contrast labels (plain text for mutate)
pairwise_N_df <- pairwise_N_df %>%
  dplyr::mutate(
    contrast_formatted = paste0("N = ", left_right[, 2], " - N = ", left_right[, 3])
  )

#---------------------------
# STEP 3: Select columns for table
#---------------------------

pairwise_N_clean <- pairwise_N_df %>%
  dplyr::select(contrast_formatted, Effect, SE, df, t_val, p) %>%
  dplyr::rename(
    Contrast = contrast_formatted,
    t = t_val
  )

#---------------------------
# STEP 4: Create minimal flextable
#---------------------------

#---------------------------
# STEP 4: Create minimal flextable (with italicized stat headers)
#---------------------------

ft_N <- flextable(pairwise_N_clean) %>%
  set_header_labels(
    Contrast = "Contrast",
    Effect   = "Estimate (95% CI)",
    SE       = "SE",
    df       = "df",
    t        = "t",
    p        = "p"
  ) %>%
  compose(part = "header", j = "SE", value = as_paragraph(as_i("SE"))) %>%
  compose(part = "header", j = "df", value = as_paragraph(as_i("df"))) %>%
  compose(part = "header", j = "t", value = as_paragraph(as_i("t"))) %>%
  compose(part = "header", j = "p", value = as_paragraph(as_i("p"))) %>%
  # Italicize N in contrast column
  compose(
    j = "Contrast",
    value = as_paragraph(
      as_i("N"), " = ", left_right[, 2], " â ",
      as_i("N"), " = ", left_right[, 3]
    )
  ) %>%
  colformat_double(j = c("SE", "t"), digits = 2) %>%
  align(j = c("Contrast", "Effect", "df", "p"), align = "center", part = "all") %>%
  width(j = "Contrast", width = 2.2) %>%
  width(j = "Effect", width = 2.5) %>%
  line_spacing(space = 0.9, part = "all") %>%
  padding(j = "Contrast", padding.top = 1, padding.bottom = 1, part = "all")


#---------------------------
# STEP 5: Bold significant p-values
#---------------------------

sig_rows <- which(pairwise_N_df$p_val < 0.05)
ft_N <- bold(ft_N, i = sig_rows, j = "p", bold = TRUE, part = "body")

#---------------------------
# STEP 6: APA styling
#---------------------------

theme_apa_flex <- function(ft_object) {
  thin <- fp_border(color = "black", width = 1)
  ft_object %>%
    border_remove() %>%
    font(fontname = "Avenir Next", part = "all") %>%
    fontsize(size = 12, part = "all") %>%
    align(align = "center", part = "all") %>%
    set_table_properties(layout = "fixed") %>%
    hline(i = 1, border = thin, part = "header") %>%
    hline_top(border = thin, part = "all") %>%
    hline_bottom(border = thin, part = "all")
}

ft_N <- theme_apa_flex(ft_N)

#---------------------------
# FINAL OUTPUT
#---------------------------

ft_N
```

```{r}
#| label: "save-comparisons-tables"
#| echo: false
#| message: false
#| warning: false

library(flextable)
library(here)

# Save Population pairwise comparisons table
invisible(save_as_image(
  ft_bias,
  path = here("Simulations", "STUDY_1", "2 Time Points", "zposthoc", "l_r_2t_bias_visuals", "l_r_2t_pairwise_bias_population.svg")
))

# Save N pairwise comparisons table
invisible(save_as_image(
  ft_N,
  path = here("Simulations", "STUDY_1", "2 Time Points", "zposthoc", "l_r_2t_bias_visuals", "l_r_2t_pairwise_bias_N.svg")
))
```

------------------------------------------------------------------------

## Prepare Data for Visualization

### Subset Data for Bias Plots

*Subset the Monte Carlo data into mover transition probabilities (.2, .3, .4) and stayer transition probabilities (.6, .7, .8) based on population values*

```{r}
#| label: "subset-data-for-bias-plots"
#| echo: true
#| message: false
#| warning: false

final_mc_values <- read.csv(here("Simulations", "STUDY_1", "2 Time Points", "zbootstrapping", "l_r_2t_mc_final_mc_values.csv"))

# Assuming Population is numeric in all_data
all_data <- final_mc_values

# Ensure that the Population_Label uses numeric levels without leading zeros but assigns expression-based labels
all_data$Population_Label <- factor(all_data$Population, 
    levels = c(0.2, 0.3, 0.4, 0.6, 0.7, 0.8),  # Numeric levels without leading zeros
    labels = c(
        expression(bold(italic(T))[11] ~ " = .200"),
        expression(bold(italic(T))[11] ~ " = .300"),
        expression(bold(italic(T))[11] ~ " = .400"),
        expression(bold(italic(T))[11] ~ " = .600"),
        expression(bold(italic(T))[11] ~ " = .700"),
        expression(bold(italic(T))[11] ~ " = .800")
    )
)

# Ensure that N is consistently factored and ordered
all_data$N <- factor(all_data$N, 
    levels = c("N = 500", "N = 1000", "N = 2000", "N = 4000")
)
all_data <- all_data %>%
  arrange(Population, N)

# Subset for Transitions movers (already correctly defined as "Mover")
subset_mover <- subset(all_data, Transitions == "Mover")

# Subset for Transitions stayers (already correctly defined as "Stayer")
subset_stayer <- subset(all_data, Transitions == "Stayer")

```

### Prepare Function for Bias Plots

```{r}
#| label: "plot-bias"
#| echo: true
#| message: false
#| warning: false
#| code-fold: false

create_plot <- function(data, title_suffix) {
  # Common theme for the plots
common_theme <- theme_minimal() +
  theme(
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    axis.text.x = element_text(size = 10),  # X-axis labels (tick marks)
    axis.text.y = element_text(size = 10),  
    axis.title.x = element_text(size = 12, margin = margin(t = 10, b = 10)),  # X-axis title
    axis.title.y = element_text(size = 12),
    axis.ticks = element_line(color = "black", linewidth = 0.5),
    legend.position = "bottom",
    legend.title = element_blank(),
    legend.text = element_text(size = 12),
    text = element_text(family = "Avenir Next", size = 12),
    legend.margin = margin(t = -10),
    plot.caption = element_text(size = 12, hjust = 0, margin = margin(t = 10)),
    strip.text = element_text(size = 12)
  )


  # Detect which legend items to show
  present_categories <- c("Parameter Bias", "Standard Error Bias")
  if (any(data$Coverage_Dic == 0)) present_categories <- c(present_categories, "Coverage Failure")
  if (any(data$Power_Dic == 0)) present_categories <- c(present_categories, "Power Failure")

  # Define colors and shapes for different categories
  colors <- c("Parameter Bias" = "#7030A0", "Standard Error Bias" = "#C830CC", 
              "Coverage Failure" = "#7030A0", "Power Failure" = "black")
  shapes <- c("Parameter Bias" = 16, "Standard Error Bias" = 18, 
              "Coverage Failure" = 1, "Power Failure" = 4)

  # Filter colors and shapes based on detected categories
  filtered_colors <- colors[present_categories]
  filtered_shapes <- shapes[present_categories]

  # Plotting
  ggplot(data = data, aes(x = factor(N))) +  
    geom_line(aes(y = Parameter_Bias, color = "Parameter Bias", group = Population_Label), linewidth = 1, linetype = "solid") +  
    geom_line(aes(y = SE_Bias, color = "Standard Error Bias", group = Population_Label), linewidth = 1, linetype = "solid") +  
    geom_point(aes(y = Parameter_Bias, color = "Parameter Bias"), shape = 16, size = 2.2, fill = "#7030A0", alpha = 1) +  
    geom_point(aes(y = SE_Bias, color = "Standard Error Bias"), shape = 18, size = 2.2, fill = "#C830CC", alpha = 1) +  
    geom_point(data = subset(data, Coverage_Dic == 0), aes(y = Parameter_Bias, color = "Coverage Failure"), shape = 1, size = 2, fill = "#7030A0", alpha = 1) +  
    geom_point(data = subset(data, Power_Dic == 0), aes(y = Parameter_Bias, color = "Power Failure"), shape = 4, size = 2, fill = "black", alpha = 1) + 
    geom_line(data = subset(data, Coverage_Dic == 0), aes(y = Parameter_Bias, color = "Coverage Failure", group = Population_Label), linewidth = 0.3, linetype = "solid") +
    geom_line(data = subset(data, Power_Dic == 0), aes(y = Parameter_Bias, color = "Power Failure", group = Population_Label), linewidth = 0.3, linetype = "solid") +
    scale_color_manual(
      values = filtered_colors, 
      labels = present_categories, 
      breaks = present_categories,
      guide = guide_legend(
        override.aes = list(shape = filtered_shapes)
      )
    ) +  
    labs(
      x = "Sample Size",
      y = "Bias (%)",
      color = "",
      title = paste("LTA Generated, RILTA Analyzed with", title_suffix, "Transition Probabilities")
    ) +
    coord_cartesian(ylim = c(-30, 30)) +  
    facet_wrap(~ as.character(Population_Label), scales = "free", labeller = label_parsed) +  
    scale_x_discrete(labels = c(expression(italic("N") ~ " = 500"), expression(italic("N") ~ " = 1000"), expression(italic("N") ~ " = 2000"), expression(italic("N") ~ " = 4000"))) +  
    scale_y_continuous(breaks = seq(-30, 30, by = 10)) +  
    common_theme +
    geom_hline(yintercept = c(-10, 10), linetype = "dashed", color = "#7030A0", linewidth = 0.7) +  
    geom_hline(yintercept = c(-5, 5), linetype = "dashed", color = "#C830CC", linewidth = 0.7) +
    theme(
      legend.position = "bottom", 
      strip.placement = "outside", 
      strip.background = element_blank(),
      panel.spacing = unit(0.5, "lines"),
      axis.text.x = element_text(angle = 45, hjust = 1, size = 10)
    )
}
```

### Render Bias Figures

```{r}
#| label: "plot-movers"
#| echo: true
#| message: false
#| warning: false

# Create and print plot for Mover
plot_mover <- create_plot(subset_mover, "Mover")
#| column: screen
#| fig-format: svg
print(plot_mover)

# Remove title for the saved version
plot_mover_no_title <- plot_mover + labs(title = NULL)

# Save Mover plot without title as .svg
ggsave(here('Simulations', 'STUDY_1', "2 Time Points", "zFIGURES", "x2t_lta_rilta_plots", "plot_mover.svg"), plot = plot_mover_no_title, width = 6, height = 3, dpi = 300, device = "svg")

```

```{r}
#| label: "plot-stayers"
#| echo: true
#| message: false
#| warning: false

# Create and print plot for Stayer
plot_stayer <- create_plot(subset_stayer, "Stayer")
#| column: screen
#| fig-format: svg
print(plot_stayer)

# Remove title for the saved version
plot_stayer_no_title <- plot_stayer + labs(title = NULL)

# Save Stayer plot without title as .svg
ggsave(here('Simulations', 'STUDY_1', "2 Time Points", "zFIGURES", "x2t_lta_rilta_plots", "plot_stayer.svg"), plot = plot_stayer_no_title, width = 6, height = 3, dpi = 300, device = "svg")
```

------------------------------------------------------------------------

## **Prepare Data for Heat Maps**

*Prepare data for heat map creation by ensuring correct formatting for population values, and subsetting the data based on class proportions and sample sizes.*

```{r}
#| label: "prepare-data-for-heatmaps"
#| echo: true
#| message: false
#| warning: false
#| code-fold: false

# Step 1: Separate the movers and stayers and ensure sorting by numeric N and Population
movers <- all_data %>%
  filter(Transitions == "Mover") %>%
  arrange(as.numeric(str_remove(N, "N = ")), Population)

stayers <- all_data %>%
  filter(Transitions == "Stayer") %>%
  arrange(as.numeric(str_remove(N, "N = ")), Population)

# Step 2: Create N_Label using stripped value of N
movers <- movers %>%
  group_by(N) %>%
  mutate(N_Label = ifelse(row_number() == 2, glue("*N* = {str_remove(N, 'N = ')}"), "")) %>%
  ungroup()

stayers <- stayers %>%
  group_by(N) %>%
  mutate(N_Label = ifelse(row_number() == 2, glue("*N* = {str_remove(N, 'N = ')}"), "")) %>%
  ungroup()


# Step 3: Combine movers and stayers back into one dataset, keeping them separate by transitions
all_data_sorted <- bind_rows(movers, stayers)

# Step 3.5: Relabel Population as factor with character labels for display
all_data_sorted <- all_data_sorted %>%
  mutate(Population = factor(
    Population,
    levels = c(0.2, 0.3, 0.4, 0.6, 0.7, 0.8),
    labels = c(".200", ".300", ".400", ".600", ".700", ".800")
  ))

# Step 4: Select necessary columns for the final display
test_map <- dplyr::select(all_data_sorted, N_Label, Population, average, Coverage, Power, Parameter_Bias, SE_Bias)

```

### Prepare Function for Heat Map Creation

```{r}
#| label: "create-heatmap-function"
#| echo: true
#| message: false
#| warning: false

# Function to create gt table based on subset data
create_gt_table <- function(subset, transition_probability) {
  # Create the gt object and set initial formatting
  gt_table <- subset %>%
    gt() %>%
    opt_table_font(font = "Avenir Next") %>%
    cols_label(
      N_Label = "Sample Size",
      Population = md("*T*<sub>11</sub>"),
      average = md("Estimated<br>*T*<sub>11</sub>"),
      Coverage = "Coverage",
      Power = "Power",
      Parameter_Bias = "Parameter <br>Bias",
      SE_Bias = "SE<br>Bias",
      .fn = md
    ) %>%
    fmt_markdown(columns = "N_Label") %>%   ### â THIS LINE RIGHT HERE
    tab_spanner(
      label = "Bias",
      columns = c("Parameter_Bias", "SE_Bias")
    ) %>%
    tab_row_group(
      label = md("*Stationary Probabilities*"),
      rows = c(13:24)
    ) %>%
    tab_row_group(
      label = md("*Non-Stationary Probabilities*"),
      rows = c(1:12)
    ) %>%
    tab_style(
      style = cell_text(style = "italic" # Apply bold and italic styling
      ),
      locations = cells_row_groups()  # Apply style to row subheaders
    ) %>%
    fmt_number(columns = c("Parameter_Bias", "SE_Bias"), decimals = 2) %>%  
    fmt_number(columns = 4, decimals = 3) %>%
text_transform(
  locations = cells_body(columns = c("average", "Coverage", "Power")),
  fn = function(x) sub("^0\\.", ".", x)
) %>%
    tab_options(
      row.striping.include_table_body      = FALSE,
      table.width                           = pct(75),  # keep this for horizontal width control
      data_row.padding                      = px(2),   # Tighter vertical padding
      heading.padding                       = px(0),
      column_labels.padding                 = px(2),
      row_group.padding                     = px(2),
      table_body.hlines.color               = "white",

      # ââ FIX THE TWO STRAY GREY LINES âââââââââââââââââââ
      table_body.border.top.color           = "black",
      table_body.border.top.width           = px(1),
      table_body.border.bottom.color        = "black",
      table_body.border.bottom.width        = px(1),

      table.border.top.color                = "black",
      table.border.top.width                = px(1),
      table.border.bottom.color             = "black",
      table.border.bottom.width             = px(1),

      heading.border.bottom.color           = "black",
      heading.border.bottom.width           = px(1),

      column_labels.border.top.color        = "black",
      column_labels.border.top.width        = px(1),
      column_labels.border.bottom.color     = "black",
      column_labels.border.bottom.width     = px(1),

      row_group.border.bottom.color         = "black",
      row_group.border.bottom.width         = px(1),
      row_group.border.top.color            = "black",
      row_group.border.top.width            = px(1)
    ) %>%
    cols_align(
      align = c("center"),
      columns = everything()
    )
  
  # Apply color highlighting for violations in Parameter Bias
  if (any(!(subset$Parameter_Bias >= -9.99 & subset$Parameter_Bias <= 9.99), na.rm = TRUE)) {
    gt_table <- gt_table %>%
      data_color(
        columns = "Parameter_Bias",
        rows = .data$Parameter_Bias < -9.99 | .data$Parameter_Bias > 9.99,  # Apply color only if outside the threshold
        method = "numeric",
        palette = c("#113386", "#DAE3FA", "#113386"),  # Darker blue for larger deviations
        domain = c(-40, 40)  # Adjust the domain to reflect the range of values
      ) %>%
      tab_footnote(
        footnote = md("Darker blue indicates larger deviations from zero *Parameter Bias* beyond the Â±9.99 threshold."),
        locations = cells_column_labels(columns = "Parameter_Bias")
      )
  }

  # Apply color highlighting for violations in SE Bias
  if (any(!(subset$SE_Bias >= -4.99 & subset$SE_Bias <= 4.99), na.rm = TRUE)) {
    gt_table <- gt_table %>%
      data_color(
        columns = "SE_Bias",
        rows = .data$SE_Bias < -4.99 | .data$SE_Bias > 4.99,  # Apply color only if outside the threshold
        method = "numeric",
        palette = c("#781049", "#FDEAF4", "#781049"),  # Darker red for larger deviations
        domain = c(-80, 80)  # Adjust the domain for the SE_Bias range
      ) %>%
      tab_footnote(
        footnote = md("Darker red indicates larger deviations from zero *Standard Error Bias* beyond the Â±4.99 threshold."),
        locations = cells_column_labels(columns = "SE_Bias")
      )
  }

  if (any(subset$Coverage < 0.91 | subset$Coverage > 0.979, na.rm = TRUE)) {
    gt_table <- gt_table %>%
      data_color(
        columns = "Coverage",
        rows = subset$Coverage < 0.91 | subset$Coverage > 0.979,
        method = "numeric",
        palette = c("#024F2D", "white"),  # Green for coverage issues
        domain = c(0, 1)
      ) %>%
      tab_footnote(
        footnote = md("Green indicates failure to achieve adequate *Coverage*."),
        locations = cells_column_labels(columns = "Coverage")
      )
  }

  if (any(subset$Power < 0.8, na.rm = TRUE)) {
    gt_table <- gt_table %>%
      data_color(
        columns = "Power",
        rows = subset$Power < 0.8,
        method = "numeric",
        palette = c("#502CD1", "white"),  # Purple for power issues
        domain = c(0, 1)
      ) %>%
      tab_footnote(
        footnote = md("Purple indicates failure to achieve adequate *Power*."),
        locations = cells_column_labels(columns = "Power")
      )
  }
  
  return(gt_table)
}

```

### Render Heat Map

```{r}

#| label: "render-heatmap"
#| echo: true
#| message: false
#| warning: false


gt_table <- create_gt_table(test_map, ".200 & .800")

gt_table
# Further operations on gt_table
gt_table |> tab_options(table.width = pct(75)) |> gtsave(here("Simulations", "STUDY_1", "2 Time Points", "zHEATMAPS", "z2t_l_r_heatmaps", "2t_L_r.png")
)
```
