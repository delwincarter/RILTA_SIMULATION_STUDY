fmt_number(
columns = diff,
decimals = 3
) %>%
cols_align(
align = "center",
columns = everything()
) %>%
tab_options(
table.font.size = "small",
heading.title.font.size = "medium",
heading.subtitle.font.size = "small",
table.width = pct(50)
)
# Display the table
ll_check_table
# Create a dataframe with only rows where ll_out and ll_csv differ
ll_mismatch <- final_data_with_actuals %>%
mutate(diff = round(ll_out - ll_csv, 3)) %>%
filter(diff != 0) %>%
select(FileName, Replication, ll_out, ll_csv, diff)
#| label: "create-column-names-from-filename"
#| echo: true
#| message: false
#| warning: false
#| code-fold: false
# Add new columns based on the information in the FileName
final_data_with_actuals <- final_data_with_actuals %>%
mutate(
N = case_when(
grepl("n_4000", FileName) ~ 4000,
grepl("n_500", FileName) ~ 500,
grepl("n_1000", FileName) ~ 1000,
grepl("n_2000", FileName) ~ 2000,
TRUE ~ NA_integer_
),
Population = case_when(
grepl("tp_1.385", FileName) ~ ".800",
grepl("tp_0.85", FileName) ~ ".700",
grepl("tp_0.41", FileName) ~ ".600",
grepl("tp_-0.41", FileName) ~ ".400",
grepl("tp_-0.85", FileName) ~ ".300",
grepl("tp_-1.385", FileName) ~ ".200",
TRUE ~ NA_character_
),
Lambda = case_when(
grepl("a_1$", FileName) ~ "1",
grepl("a_1\\.5", FileName) ~ "1.5",
grepl("a_2$", FileName) ~ "2",
grepl("a_2\\.5", FileName) ~ "2.5",
grepl("a_3$", FileName) ~ "3",
grepl("a_0", FileName) ~ "0",
TRUE ~ NA_character_
),
Transitions = case_when(
Population %in% c(".200", ".300", ".400") ~ 1,
Population %in% c(".600", ".700", ".800") ~ 2,
TRUE ~ NA_integer_
)
) %>%
mutate(
N = factor(N, levels = c(4000, 500, 1000, 2000), labels = c("N = 4000", "N = 500", "N = 1000", "N = 2000")),
Population = factor(Population, levels = c(".800", ".700", ".600", ".400", ".300", ".200")),
Transitions = factor(Transitions, levels = c(1, 2), labels = c("Mover", "Stayer"))
)
#| label: "calculate-violations"
#| echo: true
#| message: false
#| warning: false
violation_summary <- final_data_with_actuals %>%
mutate(
Any_Violation = ifelse(is.na(Any_Violation), 0, Any_Violation),
ErrorFlag = ifelse(is.na(ErrorFlag), 0, ErrorFlag),
N_numeric = as.numeric(gsub("N = ", "", as.character(N))),
N_numeric = ifelse(is.na(N_numeric), 0, N_numeric),
Lambda = as.numeric(Lambda)  # Ensure Lambda is numeric for proper sorting
) %>%
group_by(FileName, Population, N, N_numeric, Lambda) %>%
summarize(
Total_Rows = n(),
Total_Violations = sum(Any_Violation, na.rm = TRUE),
Total_Errors = sum(ErrorFlag, na.rm = TRUE),
Total_LL_Failures = sum(LL_Replicated == 0, na.rm = TRUE),
Total_True_Violations = sum(True_Violation, na.rm = TRUE),
Percentage_Violations = round((Total_Violations / Total_Rows) * 100, 1),
True_Violation_Perc = round((Total_True_Violations / Total_Rows) * 100, 1),
ErrorRate = round((Total_Errors / Total_Rows) * 100, 1),
LL_Failure_Perc = round((Total_LL_Failures / Total_Rows) * 100, 1),
.groups = "drop"
) %>%
mutate(
# Compute Good Replications
GoodReplications = Total_Rows - Total_True_Violations,
GoodReplications = ifelse(GoodReplications < 0, 0, GoodReplications),
# Reanalysis Needed Flag
Reanalysis_Needed = if_else(GoodReplications >= 500, "No", "Yes"),
# Compute Replications Needed
Additional_Runs = (500 + Total_Violations) * (Percentage_Violations / 100),
Replications_Needed = ceiling(500 + Total_Violations + Additional_Runs + 20),
Replications_Needed = if_else(Replications_Needed < 500, 500, Replications_Needed),
# Adjusted Replications Calculation
Adjusted_Replications_Needed = case_when(
ErrorRate >= 100 ~ NA_real_,
TRUE ~ ceiling(Replications_Needed / (1 - (ErrorRate / 100)))
),
Adjusted_Replications_Needed = if_else(
is.na(Adjusted_Replications_Needed) | Adjusted_Replications_Needed < 500,
500,
Adjusted_Replications_Needed
),
# Assign Transition Probabilities (TPs) based on Population
TPs = case_when(
Population == ".800" ~ 1.385,
Population == ".700" ~ 0.85,
Population == ".600" ~ 0.41,
Population == ".400" ~ -0.41,
Population == ".300" ~ -0.85,
Population == ".200" ~ -1.385,
TRUE ~ NA_real_
)
) %>%
arrange(
factor(N_numeric, levels = c(500, 1000, 2000, 4000)),
Lambda
) %>%
select(
FileName, Population, TPs, Lambda, N, N_numeric,
Total_Rows, Total_Violations, Total_True_Violations, True_Violation_Perc,
Percentage_Violations,
Total_Errors, ErrorRate,
Total_LL_Failures, LL_Failure_Perc,
GoodReplications, Reanalysis_Needed,
Replications_Needed, Adjusted_Replications_Needed
) %>%
arrange(N_numeric, Lambda) %>%
mutate(N_numeric = trimws(as.numeric(N_numeric)))
View(violation_summary)
violation_summary1 <- violation_summary %>%
filter(Total_LL_Failures > 24)
View(violation_summary1)
View(violation_summary1)
#| label: "simulation-conditions"
#| echo: true
#| message: false
#| warning: false
p1 <- expand.grid(N = c(500, 1000, 2000, 4000),
TPs = c(1.385, .85, .41, -.41, -.85, -1.385),
lambda = c(0, 1, 1.5, 2, 2.5, 3))
# Display the matrix using gt
p1 %>%
gt() %>%
tab_header(
title = "Simulation Conditions Matrix",
subtitle = "Combinations of Sample Sizes, Transition Probabilities, and Mixtures"
) %>%
cols_align(
align = "center",
columns = everything() # Centers all columns
)
# Split based on N values
p11 <- p1 %>% filter(N == 500)
p12 <- p1 %>% filter(N == 1000)
p13 <- p1 %>% filter(N == 2000)
# Split N = 4000 into two subsets
p14 <- p1 %>%
filter(N == 4000, TPs %in% c(1.385, 0.85, 0.41), lambda %in% c(0, 1, 1.5))
p15 <- p1 %>%
filter(N == 4000, TPs %in% c(-0.41, -0.85, -1.385), lambda %in% c(2, 2.5, 3))
# Verify counts for each subset
cat("Rows in p11:", nrow(p11), "\n")
cat("Rows in p12:", nrow(p12), "\n")
cat("Rows in p13:", nrow(p13), "\n")
cat("Rows in p14:", nrow(p14), "\n")
cat("Rows in p15:", nrow(p15), "\n")
# Split into groups:
p11 <- p1 %>% filter(N == 500)
p12 <- p1 %>% filter(N == 1000)
p13 <- p1 %>% filter(N == 2000)
# Correctly split N = 4000 into two halves:
p14 <- p1 %>% filter(N == 4000, TPs %in% c(1.385, 0.85, 0.41), lambda %in% c(0, 1, 1.5))
p15 <- p1 %>% filter(N == 4000, TPs %in% c(-0.41, -0.85, -1.385), lambda %in% c(2, 2.5, 3))
# Verify row counts
cat("Rows in p11:", nrow(p11), "\n")
cat("Rows in p12:", nrow(p12), "\n")
cat("Rows in p13:", nrow(p13), "\n")
cat("Rows in p14:", nrow(p14), "\n")
cat("Rows in p15:", nrow(p15), "\n")
#| label: "simulation-conditions"
#| echo: true
#| message: false
#| warning: false
p1 <- expand.grid(N = c(500, 1000, 2000, 4000),
TPs = c(1.385, .85, .41, -.41, -.85, -1.385),
lambda = c(0, 1, 1.5, 2, 2.5, 3))
# Display the matrix using gt
p1 %>%
gt() %>%
tab_header(
title = "Simulation Conditions Matrix",
subtitle = "Combinations of Sample Sizes, Transition Probabilities, and Mixtures"
) %>%
cols_align(
align = "center",
columns = everything() # Centers all columns
)
# Split into groups:
p11 <- p1 %>% filter(N == 500)
p12 <- p1 %>% filter(N == 1000)
p13 <- p1 %>% filter(N == 2000)
# Correctly split N = 4000 into two halves:
p14 <- p1 %>% filter(N == 4000, TPs %in% c(1.385, 0.85, 0.41), lambda %in% c(0, 1, 1.5))
p15 <- p1 %>% filter(N == 4000, TPs %in% c(-0.41, -0.85, -1.385), lambda %in% c(2, 2.5, 3))
# Verify row counts
cat("Rows in p11:", nrow(p11), "\n")
cat("Rows in p12:", nrow(p12), "\n")
cat("Rows in p13:", nrow(p13), "\n")
cat("Rows in p14:", nrow(p14), "\n")
cat("Rows in p15:", nrow(p15), "\n")
# Step 2: Split the data into groups
p11 <- p1 %>% filter(N == 500)
p12 <- p1 %>% filter(N == 1000)
p13 <- p1 %>% filter(N == 2000)
# Step 3: Correctly divide N = 4000 into two equal-sized groups
p14 <- p1 %>% filter(N == 4000 & TPs %in% c(1.385, 0.85, 0.41) & lambda %in% c(0, 1, 1.5))
p15 <- p1 %>% filter(N == 4000 & TPs %in% c(-0.41, -0.85, -1.385) & lambda %in% c(2, 2.5, 3))
# Step 4: Verify row counts
cat("Rows in p11:", nrow(p11), "\n")
cat("Rows in p12:", nrow(p12), "\n")
cat("Rows in p13:", nrow(p13), "\n")
cat("Rows in p14:", nrow(p14), "\n")
cat("Rows in p15:", nrow(p15), "\n")
# Step 1: Generate the full factorial design
p1 <- expand.grid(
N = c(500, 1000, 2000, 4000),
TPs = c(1.385, 0.85, 0.41, -0.41, -0.85, -1.385),
lambda = c(0, 1, 1.5, 2, 2.5, 3)
)
# Step 2: Split the data into groups for N = 500, 1000, 2000
p11 <- p1 %>% filter(N == 500)
p12 <- p1 %>% filter(N == 1000)
p13 <- p1 %>% filter(N == 2000)
# Step 3: Split N = 4000 correctly by Lambda values
p14 <- p1 %>% filter(N == 4000 & lambda %in% c(0, 1, 1.5))
p15 <- p1 %>% filter(N == 4000 & lambda %in% c(2, 2.5, 3))
# Step 4: Verify row counts
cat("Rows in p11:", nrow(p11), "\n")
cat("Rows in p12:", nrow(p12), "\n")
cat("Rows in p13:", nrow(p13), "\n")
cat("Rows in p14:", nrow(p14), "\n")
cat("Rows in p15:", nrow(p15), "\n")
#| label: "simulation-conditions"
#| echo: true
#| message: false
#| warning: false
#| code-fold: false
# Define the simulation conditions
p1 <- expand.grid(N = c(500, 1000, 2500, 5000),
TPs = c(3.179, 0.407),
mix = c(1, 2, 3))
# Display the matrix using gt
p1 %>%
gt() %>%
tab_header(
title = "Simulation Conditions Matrix",
subtitle = "Combinations of Sample Sizes, Transition Probabilities, and Mixtures"
) %>%
cols_align(
align = "center",
columns = everything() # Centers all columns
)
#| label: "lta-lta-simulation-Model 1"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
# Step 1: Create the cluster for parallel processing
num_cores <- detectCores() - 1  # Detect the number of available cores (minus 1)
cl <- makeCluster(num_cores, type = "PSOCK")    # Create the PSOCK cluster
# Step 2: Define the function for the simulation
lta_lta_func <- function(N, TPs, mix) {
# Step 2.1: Construct the MODELPOPULATION argument based on the value of 'mix'
MODELPOPULATION <- if (mix == 1) {
glue("
%OVERALL%
[c1#1*-1.897] ;
[c1#2*-0.798] ;
[c2#1*-1.1] ;
[c2#2*-1.1] ;
c2#1 on c1#1*{TPs};
c2#1 on c1#2*1.1;
c2#2 on c1#1*1.1;
c2#2 on c1#2*1.793147;
MODEL POPULATION-c1:
%c1#1%
[u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
%c1#2%
[u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
%c1#3%
[u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);
MODEL POPULATION-c2:
%c2#1%
[u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
%c2#2%
[u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
%c2#3%
[u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
")
} else if (mix == 2) {
glue("
%OVERALL%
[c1#1*0] ;
[c1#2*0] ;
[c2#1*-1.1] ;
[c2#2*-1.1] ;
c2#1 on c1#1*{TPs};
c2#1 on c1#2*1.1;
c2#2 on c1#1*1.1;
c2#2 on c1#2*1.793147;
MODEL POPULATION-c1:
%c1#1%
[u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
%c1#2%
[u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
%c1#3%
[u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);
MODEL POPULATION-c2:
%c2#1%
[u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
%c2#2%
[u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
%c2#3%
[u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
")
} else if (mix == 3) {
glue("
%OVERALL%
[c1#1*1.792] ;
[c1#2*1.099] ;
[c2#1*-1.1] ;
[c2#2*-1.1] ;
c2#1 on c1#1*{TPs};
c2#1 on c1#2*1.1;
c2#2 on c1#1*1.1;
c2#2 on c1#2*1.793147;
MODEL POPULATION-c1:
%c1#1%
[u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
%c1#2%
[u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
%c1#3%
[u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);
MODEL POPULATION-c2:
%c2#1%
[u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
%c2#2%
[u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
%c2#3%
[u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
")
}
# Step 2.2: Construct the MODEL argument based on the value of 'mix'
MODEL <- if (mix == 1) {
glue("
%OVERALL%
[c1#1*-1.897] ;
[c1#2*-0.798] ;
[c2#1*-1.1] (a1);
[c2#2*-1.1] (a2);
c2#1 on c1#1*{TPs} (b11);
c2#1 on c1#2*1.1 (b21);
c2#2 on c1#1*1.1 (b12);
c2#2 on c1#2*1.793147 (b22);
MODEL c1:
%c1#1%
[u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
%c1#2%
[u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
%c1#3%
[u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);
MODEL c2:
%c2#1%
[u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
%c2#2%
[u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
%c2#3%
[u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
")
} else if (mix == 2) {
glue("
%OVERALL%
[c1#1*0] ;
[c1#2*0] ;
[c2#1*-1.1] (a1);
[c2#2*-1.1] (a2);
c2#1 on c1#1*{TPs} (b11);
c2#1 on c1#2*1.1 (b21);
c2#2 on c1#1*1.1 (b12);
c2#2 on c1#2*1.793147 (b22);
MODEL c1:
%c1#1%
[u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
%c1#2%
[u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
%c1#3%
[u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);
MODEL c2:
%c2#1%
[u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
%c2#2%
[u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
%c2#3%
[u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
")
} else if (mix == 3) {
glue("
%OVERALL%
[c1#1*1.792] ;
[c1#2*1.099] ;
[c2#1*-1.1] (a1);
[c2#2*-1.1] (a2);
c2#1 on c1#1*{TPs} (b11);
c2#1 on c1#2*1.1 (b21);
c2#2 on c1#1*1.1 (b12);
c2#2 on c1#2*1.793147 (b22);
MODEL c1:
%c1#1%
[u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
%c1#2%
[u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
%c1#3%
[u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);
MODEL c2:
%c2#1%
[u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
%c2#2%
[u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
%c2#3%
[u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
")
}
# Step 2.3: Construct the MODELCONSTRAINT argument based on the value of 'TPs'
MODELCONSTRAINT <- if (TPs == 3.179) {
glue("
New(
trans11*.8 trans12*.1 trans13*.1
trans21*.25 trans22*.5 trans23*.25);
trans11 = exp(a1+b11)/(exp(a1+b11)+exp(a2+b12)+1);
trans12 = exp(a2+b12)/(exp(a1+b11)+exp(a2+b12)+1);
trans13 = 1-(trans11+trans12);
trans21 = exp(a1+b21)/(exp(a1+b21)+exp(a2+b22)+1);
trans22 = exp(a2+b22)/(exp(a1+b21)+exp(a2+b22)+1);
trans23 = 1-(trans21+trans22);
")
} else if (TPs == 0.407) {
glue("
New(
trans11*.2 trans12*.4 trans13*.4
trans21*.25 trans22*.5 trans23*.25);
trans11 = exp(a1+b11)/(exp(a1+b11)+exp(a2+b12)+1);
trans12 = exp(a2+b12)/(exp(a1+b11)+exp(a2+b12)+1);
trans13 = 1-(trans11+trans12);
trans21 = exp(a1+b21)/(exp(a1+b21)+exp(a2+b22)+1);
trans22 = exp(a2+b22)/(exp(a1+b21)+exp(a2+b22)+1);
trans23 = 1-(trans21+trans22);
")
}
# Step 3: Construct the Mplus object
LTA_LTA <- mplusObject(
TITLE = glue("Generate LTA_LTA_M1_N_{N}_TP_{TPs}_M_{mix}"),
MONTECARLO = glue("NAMES = u11-u15 u21-u25;
GENERATE = u11-u15 u21-u25(1);
CATEGORICAL = u11-u15 u21-u25;
GENCLASSES = c1(3) c2(3);
CLASSES = c1(3) c2(3);
NOBSERVATIONS = {N};
SEED = 07252005;
NREPS = 500;
!SAVE = repM1*.dat;
RESULTS = LTA_LTA_M1_N_{N}_TP_{TPs}_M_{mix}.csv;"),
ANALYSIS =
"TYPE = MIXTURE;
processors = 24;
miterations = 1000;
starts= 120 20;
logcriterion=0.00001;
mconv=0.00001;",
OUTPUT = "TECH9",
MODELPOPULATION = MODELPOPULATION,
MODEL = MODEL,
MODELCONSTRAINT = MODELCONSTRAINT
)
# Run Mplus model
LTA_LTA_Model <- mplusModeler(
LTA_LTA,
dataout = here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED', glue("LTA_LTA_N_{N}_TP_{TPs}_M_{mix}.dat")),
modelout = glue(here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED', "LTA_LTA_M1_N_{N}_TP_{TPs}_M_{mix}.inp")),
check = TRUE, run = TRUE, hashfilename = FALSE
)
return(LTA_LTA_Model)
}
# Step 4: Export necessary objects to the cluster
invisible(clusterExport(cl, c("lta_lta_func", "p1")))
# Ensure that the necessary packages are loaded on each cluster node
invisible(clusterEvalQ(cl, {
library(MplusAutomation)
library(glue)
library(here)
}))
# Step 5: Run the simulation in parallel using the cluster
result_list <- parLapply(cl, 1:nrow(p1), function(i) {
lta_lta_func(p1$N[i], p1$TPs[i], p1$mix[i])
})
