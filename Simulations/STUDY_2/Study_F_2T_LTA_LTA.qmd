---
title: "Understanding the Performance of Random Intercepts Latent Transition Analysis (RI-LTA): A Monte Carlo Simulation Study using MplusAutomation"
subtitle: "Study 2.1: LTA Generated, LTA Analyzed with 3 Classes and  2 Timepoints"
author: "Delwin Carter"
date: "`r format(Sys.time(), '%B %d, %Y')`"

format:
  html:
    toc: true
    toc-title: "Overview"
    toc-depth: 3
    toc-float:
      collapsed: false
      smooth-scroll: true
    theme: flatly
    fig-format: svg
    font:
      main: "Avenir Next LT Pro, Arial, sans-serif"
    page-layout: full
    code-tools: true

editor: visual

knitr:
  opts_chunk:
    echo: true
    out.width: "100%"
    fig.align: "center"
---

------------------------------------------------------------------------

::: {layout-ncol="2"}
![](images/LVG%20FINAL.png){width="300"}

![](images/UCSB_Gauchos_logo_PNG2.png){width="300"}
:::

------------------------------------------------------------------------

## Study 2.1: LTA Generated, LTA Analyzed

------------------------------------------------------------------------

![](images/LTA_LTA-01.png){width="324"}

------------------------------------------------------------------------

Load Packages

```{r}
#| label: "load-libraries"
#| echo: true
#| message: false
#| warning: false

library(tidyverse)
library(MplusAutomation)
library(here)
library(gt)
library(janitor)
library(glue)
library(ggtext)
library(rlang)
library(parallel)
library(tools)
library(webshot2)
library(flextable)
library(officer)
```

------------------------------------------------------------------------

# Simulation

------------------------------------------------------------------------

## Part 1: Conduct Simulation

> In this section, I am conducting a simulation where I am generating data as Latent Transition Analysis and analyzing it as Latent Transition Analysis to fully explore the model's performance. The simulation consists of over with 48 conditions including 3 different models, four sample sizes (N = 500, 1000, 2000, 4000)n six transition probabilities linked to logits (*betas;* 3.179, 0.407), corresponding to probabilities of .8 and .2., and 2 Mixing proportions (even; 33.3%,, 33.3%, 33.3%), (uneven; 10%, 30%, 60%). These conditions are iterated over programmatically using MplusAutomation to set up and execute the models. To speed up the process, I employ parallel processing, which distributes computations across multiple CPU cores, enabling efficient completion of the simulations across all scenarios.

Conditions:

Sample Size: N = 500, 1000, 2500, 5000

Transition logit (Probability): .800 (Stayer), .200 (Mover)

![](images/clipboard-2891141057.png){width="352"}

Mixing Proportion:

-   Mix 1: Small Proportion (10%, 30%, 60%)

-   Mix 2: Even Proportion (33.3%,, 33.3%, 33.3%),

-   Mix 3: Large Proportion (60%, 30%, 10%)

Thresholds: Model 1

![](images/clipboard-1751288251.png){width="334"}

\_Figure 1: Probability Plot of Model 1\_

------------------------------------------------------------------------

### Setting up the Simulation ConditionsÂ 

```{r}
#| label: "simulation-conditions"
#| echo: true
#| message: false
#| warning: false
#| code-fold: false

# Define the simulation conditions
p1 <- expand.grid(N = c(500, 1000, 2500, 5000),
                  TPs = c(3.179, 0.407),
                  Mix = c(1, 2, 3))

# Display the matrix using gt
p1 %>%
  gt() %>%
  tab_header(
    title = "Simulation Conditions Matrix",
    subtitle = "Combinations of Sample Sizes, Transition Probabilities, and Mixtures"
  ) %>%
  cols_align(
    align = "center",
    columns = everything() # Centers all columns
  )


```

### Run Simulations

## Model 1

```{r, eval=FALSE}
#| label: "lta-lta-simulation-Model 1"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Step 1: Create the cluster for parallel processing
num_cores <- detectCores() - 1  # Detect the number of available cores (minus 1)
cl <- makeCluster(num_cores, type = "PSOCK")    # Create the PSOCK cluster

# Step 2: Define the function for the simulation
lta_lta_func <- function(N, TPs, Mix) {
  
  # Step 2.1: Construct the MODELPOPULATION argument based on the value of 'Mix'
  MODELPOPULATION <- if (Mix == 1) { 
    glue("	
      %OVERALL%
      [c1#1*-1.897] ;
      [c1#2*-0.798] ;
      [c2#1*-1.1] ; 
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs};
      c2#1 on c1#2*1.1; 
      c2#2 on c1#1*1.1; 
      c2#2 on c1#2*1.793147;

      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
      %c1#2%
      [u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
      %c1#3%
      [u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);

      MODEL POPULATION-c2:  
      %c2#1%
      [u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
      %c2#2%
      [u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
      %c2#3%
      [u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
    ")
  } else if (Mix == 2) { 
    glue("	
      %OVERALL%
      [c1#1*0] ;
      [c1#2*0] ;
      [c2#1*-1.1] ; 
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs};
      c2#1 on c1#2*1.1; 
      c2#2 on c1#1*1.1; 
      c2#2 on c1#2*1.793147;

      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
      %c1#2%
      [u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
      %c1#3%
      [u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);

      MODEL POPULATION-c2:  
      %c2#1%
      [u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
      %c2#2%
      [u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
      %c2#3%
      [u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
    ")
  } else if (Mix == 3) { 
    glue("	
      %OVERALL%
      [c1#1*1.792] ;
      [c1#2*1.099] ;
      [c2#1*-1.1] ; 
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs};
      c2#1 on c1#2*1.1; 
      c2#2 on c1#1*1.1; 
      c2#2 on c1#2*1.793147;

      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
      %c1#2%
      [u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
      %c1#3%
      [u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);

      MODEL POPULATION-c2:  
      %c2#1%
      [u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
      %c2#2%
      [u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
      %c2#3%
      [u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
    ")
  }

  # Step 2.2: Construct the MODEL argument based on the value of 'Mix'
  MODEL <- if (Mix == 1) { 
    glue("	
      %OVERALL%
      [c1#1*-1.897] ;
      [c1#2*-0.798] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);

      MODEL c1:
      %c1#1%
      [u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
      %c1#2%
      [u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
      %c1#3%
      [u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);

      MODEL c2:  
      %c2#1%
      [u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
      %c2#2%
      [u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
      %c2#3%
      [u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
    ")
  } else if (Mix == 2) { 
    glue("	
      %OVERALL%
      [c1#1*0] ;
      [c1#2*0] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);

      MODEL c1:
      %c1#1%
      [u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
      %c1#2%
      [u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
      %c1#3%
      [u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);

      MODEL c2:  
      %c2#1%
      [u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
      %c2#2%
      [u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
      %c2#3%
      [u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
    ")
  } else if (Mix == 3) { 
    glue("	
      %OVERALL%
      [c1#1*1.792] ;
      [c1#2*1.099] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);

      MODEL c1:
      %c1#1%
      [u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
      %c1#2%
      [u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
      %c1#3%
      [u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);

      MODEL c2:  
      %c2#1%
      [u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
      %c2#2%
      [u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
      %c2#3%
      [u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
    ")
  }

  # Step 2.3: Construct the MODELCONSTRAINT argument based on the value of 'TPs'
  MODELCONSTRAINT <- if (TPs == 3.179) {
    glue("
      New(
        trans11*.8 trans12*.1 trans13*.1 
        trans21*.25 trans22*.5 trans23*.25);
      trans11 = exp(a1+b11)/(exp(a1+b11)+exp(a2+b12)+1);
      trans12 = exp(a2+b12)/(exp(a1+b11)+exp(a2+b12)+1);
      trans13 = 1-(trans11+trans12);
      trans21 = exp(a1+b21)/(exp(a1+b21)+exp(a2+b22)+1);
      trans22 = exp(a2+b22)/(exp(a1+b21)+exp(a2+b22)+1);
      trans23 = 1-(trans21+trans22);
    ")
  } else if (TPs == 0.407) {
    glue("
      New(
        trans11*.2 trans12*.4 trans13*.4 
        trans21*.25 trans22*.5 trans23*.25);
      trans11 = exp(a1+b11)/(exp(a1+b11)+exp(a2+b12)+1);
      trans12 = exp(a2+b12)/(exp(a1+b11)+exp(a2+b12)+1);
      trans13 = 1-(trans11+trans12);
      trans21 = exp(a1+b21)/(exp(a1+b21)+exp(a2+b22)+1);
      trans22 = exp(a2+b22)/(exp(a1+b21)+exp(a2+b22)+1);
      trans23 = 1-(trans21+trans22);
    ")
  }

  # Step 3: Construct the Mplus object
  LTA_LTA <- mplusObject(
    TITLE = glue("Generate LTA_LTA_M1_N_{N}_TP_{TPs}_M_{Mix}"),
    MONTECARLO = glue("NAMES = u11-u15 u21-u25;
      GENERATE = u11-u15 u21-u25(1);
      CATEGORICAL = u11-u15 u21-u25;
      GENCLASSES = c1(3) c2(3);
      CLASSES = c1(3) c2(3);
      NOBSERVATIONS = {N};
      SEED = 07252005;
      NREPS = 500;
      !SAVE = repM1*.dat;
      RESULTS = LTA_LTA_M1_N_{N}_TP_{TPs}_M_{Mix}.csv;"),
    
    ANALYSIS =
      "TYPE = MIXTURE;
      processors = 24;
      miterations = 1000;
      starts= 120 20;
      logcriterion=0.00001;
      mconv=0.00001;",
    
    OUTPUT = "TECH9",
    
    MODELPOPULATION = MODELPOPULATION,
    MODEL = MODEL,
    MODELCONSTRAINT = MODELCONSTRAINT
  )

  # Run Mplus model
  LTA_LTA_Model <- mplusModeler(
    LTA_LTA, 
    dataout = here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED', glue("LTA_LTA_N_{N}_TP_{TPs}_M_{Mix}.dat")),
    modelout = glue(here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED', "LTA_LTA_M1_N_{N}_TP_{TPs}_M_{Mix}.inp")),
    check = TRUE, run = TRUE, hashfilename = FALSE
  )
  
  return(LTA_LTA_Model)
}

# Step 4: Export necessary objects to the cluster
invisible(clusterExport(cl, c("lta_lta_func", "p1")))

# Ensure that the necessary packages are loaded on each cluster node
invisible(clusterEvalQ(cl, {
  library(MplusAutomation)
  library(glue)
  library(here)
}))

# Step 5: Run the simulation in parallel using the cluster
result_list <- parLapply(cl, 1:nrow(p1), function(i) {
  lta_lta_func(p1$N[i], p1$TPs[i], p1$Mix[i])
})
stopCluster(cl)
```

## Model 2:

Thresholds= Model 2

![](images/clipboard-3529114057.png){width="318"}

\_Figure 2: Probability Plot of Model 2\_

```{r, eval=FALSE}
#| label: "lta-lta-simulation-model2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Step 1: Create the cluster for parallel processing
num_cores <- detectCores() - 1  # Detect the number of available cores (minus 1)
cl <- makeCluster(num_cores, type = "PSOCK")    # Create the PSOCK cluster

# Step 2: Define the function for Model 2 simulation
lta_lta_func2 <- function(N, TPs, Mix) {

  # Step 2.1: Construct the MODELPOPULATION argument based on 'Mix'
  MODELPOPULATION <- if (Mix == 1) { 
    glue("	
      %OVERALL%
      [c1#1*-1.897] ;
      [c1#2*-0.798] ;
      [c2#1*-1.1] ; 
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs};
      c2#1 on c1#2*1.1; 
      c2#2 on c1#1*1.1; 
      c2#2 on c1#2*1.793147;

      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*-5 u12$1*-1.21 u13$1*-1.45 u14$1*-1.55 u15$1*-5] (p111-p115);
      %c1#2%
      [u11$1*5 u12$1*-5 u13$1*.94 u14$1*-.02 u15$1*-.89] (p121-p125);
      %c1#3%
      [u11$1*-5 u12$1*1.55 u13$1*4.17 u14$1*-.16 u15$1*-1.99] (p131-p135);
      
      MODEL POPULATION-c2:
      %c2#1%
      [u21$1*-5 u22$1*-1.21 u23$1*-1.45 u24$1*-1.55 u25$1*-5] (p111-p115);
      %c2#2%
      [u21$1*5 u22$1*-5 u23$1*.94 u24$1*-.02 u25$1*-.89] (p121-p125);
      %c2#3%
      [u21$1*-5 u22$1*1.55 u23$1*4.17 u24$1*-.16 u25$1*-1.99] (p131-p135);
    ")
  } else if (Mix == 2) {
    glue("	
      %OVERALL%
      [c1#1*0] ;
      [c1#2*0] ;
      [c2#1*-1.1] ; 
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs};
      c2#1 on c1#2*1.1; 
      c2#2 on c1#1*1.1; 
      c2#2 on c1#2*1.793147;

      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*-5 u12$1*-1.21 u13$1*-1.45 u14$1*-1.55 u15$1*-5] (p111-p115);
      %c1#2%
      [u11$1*5 u12$1*-5 u13$1*.94 u14$1*-.02 u15$1*-.89] (p121-p125);
      %c1#3%
      [u11$1*-5 u12$1*1.55 u13$1*4.17 u14$1*-.16 u15$1*-1.99] (p131-p135);
      
      MODEL POPULATION-c2:
      %c2#1%
      [u21$1*-5 u22$1*-1.21 u23$1*-1.45 u24$1*-1.55 u25$1*-5] (p111-p115);
      %c2#2%
      [u21$1*5 u22$1*-5 u23$1*.94 u24$1*-.02 u25$1*-.89] (p121-p125);
      %c2#3%
      [u21$1*-5 u22$1*1.55 u23$1*4.17 u24$1*-.16 u25$1*-1.99] (p131-p135);
    ")
  } else if (Mix == 3) {
    glue("	
      %OVERALL%
      [c1#1*1.792] ;
      [c1#2*1.099] ;
      [c2#1*-1.1] ; 
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs};
      c2#1 on c1#2*1.1; 
      c2#2 on c1#1*1.1; 
      c2#2 on c1#2*1.793147;

      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*-5 u12$1*-1.21 u13$1*-1.45 u14$1*-1.55 u15$1*-5] (p111-p115);
      %c1#2%
      [u11$1*5 u12$1*-5 u13$1*.94 u14$1*-.02 u15$1*-.89] (p121-p125);
      %c1#3%
      [u11$1*-5 u12$1*1.55 u13$1*4.17 u14$1*-.16 u15$1*-1.99] (p131-p135);
      
      MODEL POPULATION-c2:
      %c2#1%
      [u21$1*-5 u22$1*-1.21 u23$1*-1.45 u24$1*-1.55 u25$1*-5] (p111-p115);
      %c2#2%
      [u21$1*5 u22$1*-5 u23$1*.94 u24$1*-.02 u25$1*-.89] (p121-p125);
      %c2#3%
      [u21$1*-5 u22$1*1.55 u23$1*4.17 u24$1*-.16 u25$1*-1.99] (p131-p135);
    ")
  }

  # Step 2.2: Construct the MODEL argument based on 'Mix'
  MODEL <- if (Mix == 1) {
    glue("	
      %OVERALL%
      [c1#1*-1.897] ;
      [c1#2*-0.798] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);
      
      MODEL c1:
      %c1#1%
      [u11$1*-5 u12$1*-1.21 u13$1*-1.45 u14$1*-1.55 u15$1*-5] (p111-p115);
      %c1#2%
      [u11$1*5 u12$1*-5 u13$1*.94 u14$1*-.02 u15$1*-.89] (p121-p125);
      %c1#3%
      [u11$1*-5 u12$1*1.55 u13$1*4.17 u14$1*-.16 u15$1*-1.99] (p131-p135);
      
      MODEL c2:
      %c2#1%
      [u21$1*-5 u22$1*-1.21 u23$1*-1.45 u24$1*-1.55 u25$1*-5] (p111-p115);
      %c2#2%
      [u21$1*5 u22$1*-5 u23$1*.94 u24$1*-.02 u25$1*-.89] (p121-p125);
      %c2#3%
      [u21$1*-5 u22$1*1.55 u23$1*4.17 u24$1*-.16 u25$1*-1.99] (p131-p135);
    ")
  } else if (Mix == 2) {
    glue("	
      %OVERALL%
      [c1#1*0] ;
      [c1#2*0] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);
      
      MODEL c1:
      %c1#1%
      [u11$1*-5 u12$1*-1.21 u13$1*-1.45 u14$1*-1.55 u15$1*-5] (p111-p115);
      %c1#2%
      [u11$1*5 u12$1*-5 u13$1*.94 u14$1*-.02 u15$1*-.89] (p121-p125);
      %c1#3%
      [u11$1*-5 u12$1*1.55 u13$1*4.17 u14$1*-.16 u15$1*-1.99] (p131-p135);
      
      MODEL c2:
      %c2#1%
      [u21$1*-5 u22$1*-1.21 u23$1*-1.45 u24$1*-1.55 u25$1*-5] (p111-p115);
      %c2#2%
      [u21$1*5 u22$1*-5 u23$1*.94 u24$1*-.02 u25$1*-.89] (p121-p125);
      %c2#3%
      [u21$1*-5 u22$1*1.55 u23$1*4.17 u24$1*-.16 u25$1*-1.99] (p131-p135);
    ")
  } else if (Mix == 3) {
    glue("	
      %OVERALL%
      [c1#1*1.792] ;
      [c1#2*1.099] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);
      
      MODEL c1:
      %c1#1%
      [u11$1*-5 u12$1*-1.21 u13$1*-1.45 u14$1*-1.55 u15$1*-5] (p111-p115);
      %c1#2%
      [u11$1*5 u12$1*-5 u13$1*.94 u14$1*-.02 u15$1*-.89] (p121-p125);
      %c1#3%
      [u11$1*-5 u12$1*1.55 u13$1*4.17 u14$1*-.16 u15$1*-1.99] (p131-p135);
      
      MODEL c2:
      %c2#1%
      [u21$1*-5 u22$1*-1.21 u23$1*-1.45 u24$1*-1.55 u25$1*-5] (p111-p115);
      %c2#2%
      [u21$1*5 u22$1*-5 u23$1*.94 u24$1*-.02 u25$1*-.89] (p121-p125);
      %c2#3%
      [u21$1*-5 u22$1*1.55 u23$1*4.17 u24$1*-.16 u25$1*-1.99] (p131-p135);
    ")
  }

  # Step 2.3: Construct the MODELCONSTRAINT argument based on 'TPs'
  MODELCONSTRAINT <- if (TPs == 3.179) {
    glue("
      New(
        trans11*.8 trans12*.1 trans13*.1 
        trans21*.25 trans22*.5 trans23*.25);
      trans11 = exp(a1+b11)/(exp(a1+b11)+exp(a2+b12)+1);
      trans12 = exp(a2+b12)/(exp(a1+b11)+exp(a2+b12)+1);
      trans13 = 1-(trans11+trans12);
      trans21 = exp(a1+b21)/(exp(a1+b21)+exp(a2+b22)+1);
      trans22 = exp(a2+b22)/(exp(a1+b21)+exp(a2+b22)+1);
      trans23 = 1-(trans21+trans22);
    ")
  } else if (TPs == 0.407) {
    glue("
      New(
        trans11*.2 trans12*.4 trans13*.4 
        trans21*.25 trans22*.5 trans23*.25);
      trans11 = exp(a1+b11)/(exp(a1+b11)+exp(a2+b12)+1);
      trans12 = exp(a2+b12)/(exp(a1+b11)+exp(a2+b12)+1);
      trans13 = 1-(trans11+trans12);
      trans21 = exp(a1+b21)/(exp(a1+b21)+exp(a2+b22)+1);
      trans22 = exp(a2+b22)/(exp(a1+b21)+exp(a2+b22)+1);
      trans23 = 1-(trans21+trans22);
    ")
  }
  
  # Step 2.4: Create and run Mplus model
  LTA_LTA2 <- mplusObject(
    TITLE = glue("Generate LTA_LTA_M2_N_{N}_TP_{TPs}_M_{Mix}"),
    MONTECARLO = glue("NAMES = u11-u15 u21-u25;
      GENERATE = u11-u15 u21-u25(1);
      CATEGORICAL = u11-u15 u21-u25;
      GENCLASSES = c1(3) c2(3);
      CLASSES = c1(3) c2(3);
      NOBSERVATIONS = {N};
      SEED = 07252005;
      NREPS = 500;
      !SAVE = repM2*.dat;
      RESULTS = LTA_LTA_M2_N_{N}_TP_{TPs}_M_{Mix}.csv;"),
    
    ANALYSIS =
      "TYPE = MIXTURE;
      processors = 24;
      miterations = 1000;
      starts= 120 20;
      logcriterion=0.00001;
      mconv=0.00001;",
    
    OUTPUT = "TECH9",
    
    MODELPOPULATION = MODELPOPULATION,
    MODEL = MODEL,
    MODELCONSTRAINT = MODELCONSTRAINT
  )
  
  LTA_LTA_Model2 <- mplusModeler(
    LTA_LTA2, 
    dataout = here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED', glue("LTA_LTA_M2_N_{N}_TP_{TPs}_M_{Mix}.dat")),
    modelout = glue(here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED', "LTA_LTA_M2_N_{N}_TP_{TPs}_M_{Mix}.inp")),
    check = TRUE, run = TRUE, hashfilename = FALSE
  )
  return(LTA_LTA_Model2)
}

# Step 3: Export necessary objects to the cluster
invisible(clusterExport(cl, c("lta_lta_func2", "p1")))

# Ensure packages are loaded on each cluster node
invisible(clusterEvalQ(cl, {
  library(MplusAutomation)
  library(glue)
  library(here)
}))

# Step 4: Run the simulation in parallel using the cluster
result_list_model2 <- parLapply(cl, 1:nrow(p1), function(i) {
  lta_lta_func2(p1$N[i], p1$TPs[i], p1$Mix[i])
})

# Stop the cluster when done
stopCluster(cl)
```

## Model 3:

Thresholds= Model 3

![](images/clipboard-1996559007.png){width="344"}

\_Figure 3: Probability Plot for Model 3\_

```{r, eval=FALSE}
#| label: "lta-lta-simulation-model3"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Step 1: Create the cluster for parallel processing
num_cores <- detectCores() - 1  # Detect number of available cores (minus 1)
cl <- makeCluster(num_cores, type = "PSOCK")    # Create the PSOCK cluster

# Step 2: Define the function for Model 3 simulation
lta_lta_func3 <- function(N, TPs, Mix) {

  # Step 2.1: Construct the MODELPOPULATION argument for Model 3 based on 'Mix'
  MODELPOPULATION <- if (Mix == 1) { 
    glue("	
      %OVERALL%
      [c1#1*-1.897] ;
      [c1#2*-0.798] ;
      [c2#1*-1.1] ; 
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs};
      c2#1 on c1#2*1.1; 
      c2#2 on c1#1*1.1; 
      c2#2 on c1#2*1.793147;
  
      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*5 u12$1*2.38 u13$1*1.385 u14$1*4.59 u15$1*4.59] (p111-p115);
      %c1#2%
      [u11$1*.62 u12$1*.81 u13$1*.82 u14$1*.28 u15$1*1.39] (p121-p125);
      %c1#3%
      [u11$1*-1.45 u12$1*-2.44 u13$1*-5 u14$1*-1.70 u15$1*-.71] (p131-p135);

      MODEL POPULATION-c2:  
      %c2#1%
      [u21$1*5 u22$1*2.38 u23$1*1.385 u24$1*4.59 u25$1*4.59] (p111-p115);
      %c2#2%
      [u21$1*.62 u22$1*.81 u23$1*.82 u24$1*.28 u25$1*1.39] (p121-p125);
      %c2#3%
      [u21$1*-1.45 u22$1*-2.44 u23$1*-5 u24$1*-1.70 u25$1*-.71] (p131-p135);
    ")
  } else if (Mix == 2) { 
    glue("	
      %OVERALL%
      [c1#1*0] ;
      [c1#2*0] ;
      [c2#1*-1.1] ; 
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs};
      c2#1 on c1#2*1.1; 
      c2#2 on c1#1*1.1; 
      c2#2 on c1#2*1.793147;
      
      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*5 u12$1*2.38 u13$1*1.385 u14$1*4.59 u15$1*4.59] (p111-p115);
      %c1#2%
      [u11$1*.62 u12$1*.81 u13$1*.82 u14$1*.28 u15$1*1.39] (p121-p125);
      %c1#3%
      [u11$1*-1.45 u12$1*-2.44 u13$1*-5 u14$1*-1.70 u15$1*-.71] (p131-p135);

      MODEL POPULATION-c2:  
      %c2#1%
      [u21$1*5 u22$1*2.38 u23$1*1.385 u24$1*4.59 u25$1*4.59] (p111-p115);
      %c2#2%
      [u21$1*.62 u22$1*.81 u23$1*.82 u24$1*.28 u25$1*1.39] (p121-p125);
      %c2#3%
      [u21$1*-1.45 u22$1*-2.44 u23$1*-5 u24$1*-1.70 u25$1*-.71] (p131-p135);
    ")
  } else if (Mix == 3) { 
    glue("	
      %OVERALL%
      [c1#1*1.792] ;
      [c1#2*1.099] ;
      [c2#1*-1.1] ; 
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs};
      c2#1 on c1#2*1.1; 
      c2#2 on c1#1*1.1; 
      c2#2 on c1#2*1.793147;
      
      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*5 u12$1*2.38 u13$1*1.385 u14$1*4.59 u15$1*4.59] (p111-p115);
      %c1#2%
      [u11$1*.62 u12$1*.81 u13$1*.82 u14$1*.28 u15$1*1.39] (p121-p125);
      %c1#3%
      [u11$1*-1.45 u12$1*-2.44 u13$1*-5 u14$1*-1.70 u15$1*-.71] (p131-p135);

      MODEL POPULATION-c2:  
      %c2#1%
      [u21$1*5 u22$1*2.38 u23$1*1.385 u24$1*4.59 u25$1*4.59] (p111-p115);
      %c2#2%
      [u21$1*.62 u22$1*.81 u23$1*.82 u24$1*.28 u25$1*1.39] (p121-p125);
      %c2#3%
      [u21$1*-1.45 u22$1*-2.44 u23$1*-5 u24$1*-1.70 u25$1*-.71] (p131-p135);
    ")
  }
  

  # Step 2.2: Construct the MODEL argument for Model 3 based on 'Mix'
  MODEL <- if (Mix == 1) { 
    glue("	
      %OVERALL%
      [c1#1*-1.897] ;
      [c1#2*-0.798] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);

      MODEL c1:
      %c1#1%
      [u11$1*5 u12$1*2.38 u13$1*1.385 u14$1*4.59 u15$1*4.59] (p111-p115);
      %c1#2%
      [u11$1*.62 u12$1*.81 u13$1*.82 u14$1*.28 u15$1*1.39] (p121-p125);
      %c1#3%
      [u11$1*-1.45 u12$1*-2.44 u13$1*-5 u14$1*-1.70 u15$1*-.71] (p131-p135);
      
      MODEL c2: 	
      %c2#1%
      [u21$1*5 u22$1*2.38 u23$1*1.385 u24$1*4.59 u25$1*4.59] (p111-p115);
      %c2#2%
      [u21$1*.62 u22$1*.81 u23$1*.82 u24$1*.28 u25$1*1.39] (p121-p125);
      %c2#3%
      [u21$1*-1.45 u22$1*-2.44 u23$1*-5 u24$1*-1.70 u25$1*-.71] (p131-p135);
    ")      
  } else if (Mix == 2) { 
    glue("	
      %OVERALL%
      [c1#1*0] ;
      [c1#2*0] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);

      MODEL c1:
      %c1#1%
      [u11$1*5 u12$1*2.38 u13$1*1.385 u14$1*4.59 u15$1*4.59] (p111-p115);
      %c1#2%
      [u11$1*.62 u12$1*.81 u13$1*.82 u14$1*.28 u15$1*1.39] (p121-p125);
      %c1#3%
      [u11$1*-1.45 u12$1*-2.44 u13$1*-5 u14$1*-1.70 u15$1*-.71] (p131-p135);
      
      MODEL c2: 	
      %c2#1%
      [u21$1*5 u22$1*2.38 u23$1*1.385 u24$1*4.59 u25$1*4.59] (p111-p115);
      %c2#2%
      [u21$1*.62 u22$1*.81 u23$1*.82 u24$1*.28 u25$1*1.39] (p121-p125);
      %c2#3%
      [u21$1*-1.45 u22$1*-2.44 u23$1*-5 u24$1*-1.70 u25$1*-.71] (p131-p135);
    ")      
  } else if (Mix == 3) { 
    glue("	
      %OVERALL%
      [c1#1*1.792] ;
      [c1#2*1.099] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);

      MODEL c1:
      %c1#1%
      [u11$1*5 u12$1*2.38 u13$1*1.385 u14$1*4.59 u15$1*4.59] (p111-p115);
      %c1#2%
      [u11$1*.62 u12$1*.81 u13$1*.82 u14$1*.28 u15$1*1.39] (p121-p125);
      %c1#3%
      [u11$1*-1.45 u12$1*-2.44 u13$1*-5 u14$1*-1.70 u15$1*-.71] (p131-p135);
      
      MODEL c2: 	
      %c2#1%
      [u21$1*5 u22$1*2.38 u23$1*1.385 u24$1*4.59 u25$1*4.59] (p111-p115);
      %c2#2%
      [u21$1*.62 u22$1*.81 u23$1*.82 u24$1*.28 u25$1*1.39] (p121-p125);
      %c2#3%
      [u21$1*-1.45 u22$1*-2.44 u23$1*-5 u24$1*-1.70 u25$1*-.71] (p131-p135);
    ")      
  }
  
  # Step 2.3: Construct the MODELCONSTRAINT argument based on TPs
  MODELCONSTRAINT <- if (TPs == 3.179) {
    glue("
      New(
        trans11*.8 trans12*.1 trans13*.1 
        trans21*.25 trans22*.5 trans23*.25);
      trans11 = exp(a1+b11)/(exp(a1+b11)+exp(a2+b12)+1);
      trans12 = exp(a2+b12)/(exp(a1+b11)+exp(a2+b12)+1);
      trans13 = 1-(trans11+trans12);
      trans21 = exp(a1+b21)/(exp(a1+b21)+exp(a2+b22)+1);
      trans22 = exp(a2+b22)/(exp(a1+b21)+exp(a2+b22)+1);
      trans23 = 1-(trans21+trans22);
    ")
  } else if (TPs == 0.407) {
    glue("
      New(
        trans11*.2 trans12*.4 trans13*.4 
        trans21*.25 trans22*.5 trans23*.25);
      trans11 = exp(a1+b11)/(exp(a1+b11)+exp(a2+b12)+1);
      trans12 = exp(a2+b12)/(exp(a1+b11)+exp(a2+b12)+1);
      trans13 = 1-(trans11+trans12);
      trans21 = exp(a1+b21)/(exp(a1+b21)+exp(a2+b22)+1);
      trans22 = exp(a2+b22)/(exp(a1+b21)+exp(a2+b22)+1);
      trans23 = 1-(trans21+trans22);
    ")
  }

  # Step 2.4: Create and run Mplus model
  LTA_LTA3 <- mplusObject(
    TITLE = glue("Generate LTA_LTA_M3_N_{N}_TP_{TPs}_M_{Mix}"),
    MONTECARLO = glue("NAMES = u11-u15 u21-u25;
      GENERATE = u11-u15 u21-u25(1);
      CATEGORICAL = u11-u15 u21-u25;
      GENCLASSES = c1(3) c2(3);
      CLASSES = c1(3) c2(3);
      NOBSERVATIONS = {N};
      SEED = 07252005;
      NREPS = 500;
      !SAVE = repM3*.dat;
      RESULTS = LTA_LTA_M3_N_{N}_TP_{TPs}_M_{Mix}.csv;"),
    
    ANALYSIS =
      "TYPE = MIXTURE;
      processors = 24;
      miterations = 1000;
      starts= 120 20;
      logcriterion=0.00001;
      mconv=0.00001;",
    
    OUTPUT = "TECH9",
    
    MODELPOPULATION = MODELPOPULATION,
    MODEL = MODEL,
    MODELCONSTRAINT = MODELCONSTRAINT
  )

  # Run Mplus model
  LTA_LTA_Model3 <- mplusModeler(LTA_LTA3, 
                                 dataout = here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED', glue("LTA_LTA_M3_N_{N}_TP_{TPs}_M_{Mix}.dat")),
                                 modelout = glue(here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED', "LTA_LTA_M3_N_{N}_TP_{TPs}_M_{Mix}.inp")),
                                 check = TRUE, run = TRUE, hashfilename = FALSE)
  return(LTA_LTA_Model3)
}

# Step 3: Export necessary objects to the cluster
invisible(clusterExport(cl, c("lta_lta_func3", "p1")))

# Ensure packages are loaded on each cluster node
invisible(clusterEvalQ(cl, {
  library(MplusAutomation)
  library(glue)
  library(here)
}))

# Step 4: Run the simulation in parallel using the cluster
result_list_model3 <- parLapply(cl, 1:nrow(p1), function(i) {
  lta_lta_func3(p1$N[i], p1$TPs[i], p1$Mix[i])
})

# Stop the cluster when done
stopCluster(cl)
```

------------------------------------------------------------------------

# Data Processing and Verification

------------------------------------------------------------------------

## Check for Label Switching and Errors

> In this section: .csv files are first merged into a single data frame, from which specific parameters are extracted. Logit values are then converted to probabilities, and known class values are incorporated into the data frame. A subset of cases involving label switching is selected randomly and plotted for visual review. Output files are scanned for errors, which are subsequently merged back into the original data file. Additional columns derived from the file name are added, and the percentage of violations is calculated. Both errors and label switching violations are visually represented, and the total number of corrected replications is reported.

### Scrape Mplus CSV Files

*First, Load all CSV files and combine them into a single data frame.*

```{r}
#| label: "combine-csv-files-parallel"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Step 1: Set the correct CSV directory
csv_directory <- here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED')

# Step 2: Source the child document
source(here('Child_Docs', 'data_scraping.R'))
```

### Slice Data / Extract Parameters

*Extract data from the appropriate rows from each 9-row chunk and prepare the data for further processing.*

```{r}
#| label: "scrape-rows-process-data-parallel"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Step 2: Process the data using the child script
source(here('Child_Docs', 'step2_f_LTA.R'))

final_combined_data <- final_combined_data %>%
  mutate(
    TRANS11 = as.numeric(TRANS11),
    SE_11 = as.numeric(SE_11),
    across(starts_with("Ec"), as.numeric),  # Convert all Ec columns
    ll_csv = as.numeric(ll_csv)  # Convert Log-Likelihood values
  )
```

### Wrangle Data

*Convert the logits to probabilities and add the known actual values to each row.*

```{r}

#| label: "convert-logits-and-flags"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Step 3 and 4: Process the data and return results
source(here('Child_Docs', 'step_3_3k.R'))

# The objects `final_data_with_actuals` and `violators` should now be in the global environment

```

### Generate Plots of Label Switching

*Generate plots of randomly sampled violators for visual inspection using parallel processing.*

```{r, eval=FALSE}
#| label: "plot-violators"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Set plot width and height
plot_width <- 8
plot_height <- 6

# Take a random sample of 250 violators
set.seed(123)  # For reproducibility
sampled_violators <- violators[sample(nrow(violators), 250), ]

# Define the function to create plots sequentially (without parallelization)
plot_violator <- function(i) {
  row_data <- sampled_violators[i, ]
  
  # Extract the file name from the current row
  file_name <- row_data$FileName

  # Extract probability values for EC1 through AC3 (in order)
  probabilities <- c(
    as.numeric(row_data[c("Ec1u1", "Ec1u2", "Ec1u3", "Ec1u4", "Ec1u5")]),
    as.numeric(row_data[c("Ec2u1", "Ec2u2", "Ec2u3", "Ec2u4", "Ec2u5")]),
    as.numeric(row_data[c("Ec3u1", "Ec3u2", "Ec3u3", "Ec3u4", "Ec3u5")]),
    as.numeric(row_data[c("Ac1u1", "Ac1u2", "Ac1u3", "Ac1u4", "Ac1u5")]),
    as.numeric(row_data[c("Ac2u1", "Ac2u2", "Ac2u3", "Ac2u4", "Ac2u5")]),
    as.numeric(row_data[c("Ac3u1", "Ac3u2", "Ac3u3", "Ac3u4", "Ac3u5")])
  )
  
  # Create labels for the legend with actual values directly from the dataset
  labels <- c(
    paste0("EC1: (", round(row_data$Ec1u1, 3), ", ", round(row_data$Ec1u2, 3), ", ", round(row_data$Ec1u3, 3), ", ", round(row_data$Ec1u4, 3), ", ", round(row_data$Ec1u5, 3), ")"),
    paste0("EC2: (", round(row_data$Ec2u1, 3), ", ", round(row_data$Ec2u2, 3), ", ", round(row_data$Ec2u3, 3), ", ", round(row_data$Ec2u4, 3), ", ", round(row_data$Ec2u5, 3), ")"),
    paste0("EC3: (", round(row_data$Ec3u1, 3), ", ", round(row_data$Ec3u2, 3), ", ", round(row_data$Ec3u3, 3), ", ", round(row_data$Ec3u4, 3), ", ", round(row_data$Ec3u5, 3), ")"),
    paste0("AC1: (", round(row_data$Ac1u1, 3), ", ", round(row_data$Ac1u2, 3), ", ", round(row_data$Ac1u3, 3), ", ", round(row_data$Ac1u4, 3), ", ", round(row_data$Ac1u5, 3), ")"),
    paste0("AC2: (", round(row_data$Ac2u1, 3), ", ", round(row_data$Ac2u2, 3), ", ", round(row_data$Ac2u3, 3), ", ", round(row_data$Ac2u4, 3), ", ", round(row_data$Ac2u5, 3), ")"),
    paste0("AC3: (", round(row_data$Ac3u1, 3), ", ", round(row_data$Ac3u2, 3), ", ", round(row_data$Ac3u3, 3), ", ", round(row_data$Ac3u4, 3), ", ", round(row_data$Ac3u5, 3), ")")
  )

  # Step 6: Create a data frame for plotting
  plot_data <- data.frame(
    Items = rep(1:5, 6),
    Probabilities = probabilities,
    Class = rep(labels, each = 5)
  )

  # Step 7: Create the plot with the file name in the title
  p <- ggplot(plot_data, aes(x = Items, y = Probabilities, color = Class, group = Class)) +
    geom_line(size = 1.2) +
    geom_point(size = 3) +
    labs(title = file_name, x = "Items", y = "Probabilities") +  # Only the file name in the title
    theme_minimal(base_size = 16) +
    theme(panel.background = element_rect(fill = "white"),
          plot.background = element_rect(fill = "white"),
          plot.title = element_text(size = 14, hjust = 0.5)) +  # Adjust title size and center
    scale_color_manual(values = c(
      "darkblue", "darkgreen", "darkred",  # AC1 to AC3
      "lightblue", "lightgreen", "lightcoral"  # EC1 to EC3
    ))

  ggsave(filename = file.path("z2t_lta_lta_violator_plots", paste0("violator_plot_", i, "_", file_name, ".png")),
         plot = p, width = plot_width, height = plot_height)
}

# Apply the function to generate plots sequentially (without parallelization)

invisible(lapply(1:nrow(sampled_violators), plot_violator))


```

------------------------------------------------------------------------

# Error Handling

------------------------------------------------------------------------

### Scrape for Errors

*Scrape output files for errors*

```{r}
#| label: "summarize-errors"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Step 1: Set the correct output directory for .out files
output_folder <- here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED')

# Step 2: Source the child document that processes .out files
source(here('Child_Docs', 'out_scraping.R'))

# ===================================================== #
#  â SECTION 1 Generate Replication Summary Table
# ===================================================== #
replication_summary_table <- replication_summary %>%
  gt() %>%
  tab_header(
    title = "Replication Summary",
    subtitle = paste0("Folder: ", output_folder)
  ) %>%
  fmt_number(
    columns = c("Total", "Replicated_Yes", "Replicated_No", "Error_Count"),
    decimals = 0
  ) %>%
  cols_label(
    FileName = "File Name",
    Total = "Total Replications",
    Replicated_Yes = "LL Replicated",
    Replicated_No = "LL Not Replicated",
    Error_Count = "Errors"
  ) %>%
  cols_align(
    align = "center",
    columns = everything()
  ) %>%
  tab_options(
    table.font.size = "small",
    heading.title.font.size = "medium",
    heading.subtitle.font.size = "small",
    table.width = pct(80)
  )

# Display the table
replication_summary_table

# ===================================================== #
#  â SECTION 2 Row Count Validation
# ===================================================== #
cat("Rows in final_data_with_actuals:", nrow(final_data_with_actuals), "\n")
cat("Rows in final_results:", nrow(final_results), "\n")
cat("Rows in replication_summary:", nrow(replication_summary), "\n")
print(if (any(replication_summary$LL_Not_Replicated > 0, na.rm = TRUE)) {
  "â ï¸ WARNING: Some LL values were NOT replicated! Check the Replication Summary table."
} else {
  "â All LL values were successfully replicated."
})
all.equal(final_data_with_actuals$ll_csv, final_results$ll_out, tolerance = 1e-4)


```

### Merge Errors with Main Data File

*Combine error information with main data file*

```{r}
#| label: "merge-errors"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

final_data_with_actuals <- final_data_with_actuals %>%
  left_join(
    final_results %>% select(FileName, Replication, ll_out, LL_Replicated, ErrorFlag), 
    by = c("FileName", "Replication")
  ) %>%
  mutate(
    Any_Violation = ifelse(is.na(Any_Violation), 0, Any_Violation),
    ErrorFlag = ifelse(is.na(ErrorFlag), 0, ErrorFlag),
    LL_Replicated = ifelse(LL_Replicated == "Yes", 1, 0),  # â Convert Yes/No to 1/0

    # ð¹ Create a new True Violation column
    True_Violation = case_when(
      Any_Violation == 1 | ErrorFlag == 1 | LL_Replicated == 0 ~ 1,  # â At least one violation
      TRUE ~ 0
    )
  )

```

Visualize differences between ll_out and ll_csv

```{r}
ll_check <- final_data_with_actuals %>%
  mutate(diff = round(ll_out - ll_csv, 3)) %>%  # Round before counting
  count(diff)

ll_check_table <- ll_check %>%
  gt() %>%
  tab_header(
    title = "LL Difference Summary",
    subtitle = "Comparison of LL values between CSV and OUT files"
  ) %>%
  cols_label(
    diff = "LL Difference",
    n = "Count"
  ) %>%
  fmt_number(
    columns = diff,
    decimals = 3
  ) %>%
  cols_align(
    align = "center",
    columns = everything()
  ) %>%
  tab_options(
    table.font.size = "small",
    heading.title.font.size = "medium",
    heading.subtitle.font.size = "small",
    table.width = pct(50)
  )

# Display the table
ll_check_table
```

Create DF of LL differences from .out and .csv files for inspection at the replication level

```{r}
# Create a dataframe with only rows where ll_out and ll_csv differ
ll_mismatch <- final_data_with_actuals %>%
  mutate(diff = round(ll_out - ll_csv, 3)) %>%
  filter(diff != 0) %>%
  select(FileName, Replication, ll_out, ll_csv, diff)

```

### Scrape File Name Components

*Create Column Names from the file name*

```{r}
#| label: "create-columns"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true


# Add new columns based on the information in the FileName and set factors
final_data_with_actuals <- final_data_with_actuals %>%
  mutate(
    Model = case_when(
      grepl("m1", FileName) ~ "1",
      grepl("m2", FileName) ~ "2",
      grepl("m3", FileName) ~ "3",
      TRUE ~ NA_character_
    ),
    N = case_when(
      grepl("n_5000", FileName) ~ 4,  
      grepl("n_500", FileName) ~ 1,   
      grepl("n_1000", FileName) ~ 2,  
      grepl("n_2500", FileName) ~ 3,  
      TRUE ~ NA_integer_
    ),
    Mixing_proportion = case_when(
      grepl("m_1", FileName) ~ 1,  
      grepl("m_2", FileName) ~ 2,
      grepl("m_3", FileName) ~ 3,
      TRUE ~ NA_integer_
    ),
    # Add Population column based on FileName and convert it to a factor with formatted labels
    Population = case_when(
      grepl("tp_0.407", FileName) ~ "0.200",
      grepl("tp_3.179", FileName) ~ "0.800",
      TRUE ~ NA_character_
    )
  ) %>%
  # Convert columns to factors
  mutate(
    Model = factor(Model, levels = c(1, 2, 3), labels = c("Model 1", "Model 2", "Model 3")),
    N = factor(N, levels = c(1, 2, 3, 4), labels = c("N = 500", "N = 1000", "N = 2500", "N = 5000")),
    Mixing_proportion = factor(Mixing_proportion, levels = c(1, 2, 3), labels = c(".10, .30, .60", ".33, .33, .33", ".60, .30, .10")),
    Population = factor(Population, levels = c("0.200", "0.800"), labels = c(".200", ".800"))
  )

```

### Calculate Violations

*Calculate Violation Percentages per Condition*

```{r}
#| label: "calculate-violations"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

violation_summary <- final_data_with_actuals %>%
  # Step 1: Ensure `N` is converted from factor to character and extract numeric values
  mutate(
    N = as.character(N),
    N_numeric = as.numeric(gsub("N = ", "", N))  # Convert "N = 500" â 500
  ) %>%
  
  # Step 2: Proceed with grouping and summarization
  group_by(FileName, Model, Population, N, N_numeric, Mixing_proportion) %>%
  summarize(
    Total_Rows = n(),
    Total_Violations = sum(Any_Violation, na.rm = TRUE),
    Total_Errors = sum(ErrorFlag, na.rm = TRUE),
    Percentage_Violations = round((Total_Violations / Total_Rows) * 100, 1),
    .groups = "drop"
  ) %>%
  
  # Step 3: Calculate Replications Needed for label switching
  mutate(
    Additional_Runs = (500 + Total_Violations) * (Percentage_Violations / 100), 
    Replications_Needed = ceiling(500 + Total_Violations + Additional_Runs + 20),
    Replications_Needed = if_else(Replications_Needed < 500, 500, Replications_Needed),
    ErrorRate = round((Total_Errors / Total_Rows) * 100, 1),  
Adjusted_Replications_Needed = ceiling(Replications_Needed / (1 - (ErrorRate / 100))),
    Adjusted_Replications_Needed = if_else(Adjusted_Replications_Needed < 500, 500, Adjusted_Replications_Needed),
    
    # â Ensure `TPs` is calculated
    TPs = case_when(
      Population == ".800" ~ 3.179,
      Population == ".200" ~ 0.407,
      TRUE ~ NA_real_),
    # Create a numeric variable for Mixing Proportion (1 or 2)
    Mix = case_when(
      Mixing_proportion == ".10, .30, .60" ~ 1,
      Mixing_proportion == ".33, .33, .33" ~ 2,
      Mixing_proportion == ".60, .30, .10" ~ 3,
      TRUE ~ NA_integer_
    )
  ) %>%

  # Step 4: **Ensure `N_numeric` Exists Before Arranging**
  arrange(factor(N_numeric, levels = c(500, 1000, 2500, 5000)), as.numeric(Population)) %>%

  # Step 5: Convert `N` and `Population` back to factors for consistency
  mutate(
    N = factor(N, levels = c("N = 500", "N = 1000", "N = 2500", "N = 5000")),
    Population = factor(Population, levels = c(".200", ".800"))
  ) %>%
  
  # Step 6: Select and reorder columns
  select(
    FileName, Model, Population, TPs, N, N_numeric, Mix, Mixing_proportion,
    Total_Rows, Total_Violations, Total_Errors, ErrorRate,
    Percentage_Violations, Replications_Needed, Adjusted_Replications_Needed
  ) %>%
  
  # Step 7: Ensure `N_numeric` is properly formatted
  arrange(N_numeric, Population) %>%
  mutate(N_numeric = trimws(as.numeric(N_numeric)))   # Ensure it's numeric

# Split into separate datasets for each model
model1_data <- violation_summary %>% filter(Model == "Model 1")
model2_data <- violation_summary %>% filter(Model == "Model 2")
model3_data <- violation_summary %>% filter(Model == "Model 3")


```

### Create APA Flextable of Label Switching, Errors, and Replications Needed for PART 2

```{r}
#| label: "create-new-iterators"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true


library(flextable)
library(dplyr)

# Function to filter and format data for each model
create_combined_model_data <- function(data, model) {
  data %>%
    filter(Model == model) %>%
    select(
      N_numeric,  
      Population,  # â Changed from `Transition Probability` to `Population`
      Mix,                     
      Total_Violations,  
      Percentage_Violations,  
      Total_Errors,           
      ErrorRate,                  
      Replications_Needed,       
      Adjusted_Replications_Needed  
    )
}

# Generate datasets for each model
model1_data <- create_combined_model_data(violation_summary, "Model 1")
model2_data <- create_combined_model_data(violation_summary, "Model 2")
model3_data <- create_combined_model_data(violation_summary, "Model 3")

# Function to create a flextable
create_flextable <- function(data, title) {
  data <- data %>%
    as.data.frame()  # Ensures proper structure before passing to flextable

  # Create the flextable
  ft <- flextable(data) %>%
    set_header_labels(
      N_numeric = "N",     
      Population = "T11",  # â Display label as "T11", but column name remains "Population"
      Mix = "Mix",
      Total_Violations = "V",
      Percentage_Violations = "V %",
      Total_Errors = "Errors",
      ErrorRate = "Error %",
      Replications_Needed = "Reps Reqâd",
      Adjusted_Replications_Needed = "\u2206 Reps Reqâd"
    )

  # Apply header formatting
  ft <- compose(ft, part = "header", j = "N_numeric", value = as_paragraph(as_i("N")))
  ft <- compose(ft, part = "header", j = "Population", value = as_paragraph(as_i("T"), as_sub("11")))
  ft <- compose(ft, part = "header", j = "Total_Violations", value = as_paragraph(as_i("V")))
  ft <- compose(ft, part = "header", j = "Percentage_Violations", value = as_paragraph(as_i("V"), "%"))
  ft <- compose(ft, part = "header", j = "Total_Errors", value = as_paragraph("\u03B5"))
  ft <- compose(ft, part = "header", j = "ErrorRate", value = as_paragraph("\u03B5", "%"))
  ft <- compose(ft, part = "header", j = "Replications_Needed", value = as_paragraph("Reps", "\n", "Reqâd"))
  ft <- compose(ft, part = "header", j = "Adjusted_Replications_Needed", value = as_paragraph("\u2206", "\n", "Reps", "\n", "Reqâd"))

  # Adjust column widths
  ft <- width(ft, j = "N_numeric", width = 1.0)
  ft <- width(ft, j = "Population", width = 0.8)  
  ft <- width(ft, j = "Mix", width = 0.6)
  ft <- width(ft, j = "Total_Violations", width = 0.6)
  ft <- width(ft, j = "Percentage_Violations", width = 0.6)
  ft <- width(ft, j = "Total_Errors", width = 0.5)
  ft <- width(ft, j = "ErrorRate", width = 0.5)
  ft <- width(ft, j = "Replications_Needed", width = 0.8)
  ft <- width(ft, j = "Adjusted_Replications_Needed", width = 0.8)

  # Format percentage columns
  ft <- colformat_num(
    ft,
    j = c("Percentage_Violations", "ErrorRate"),  
    suffix = "%"
  )

  # Enable autofit
  ft <- set_table_properties(ft, layout = "fixed")

  # Center all cells
  ft <- align(ft, align = "center", part = "all")

  # Align header text at the bottom
  ft <- valign(ft, part = "header", valign = "bottom")

  # Merge vertically identical rows in the "N_numeric" column
  ft <- merge_v(ft, j = "N_numeric")

  # Apply font settings
  ft <- font(ft, fontname = "Avenir Next", part = "all")
    ft <- compose(
    ft,
    part = "body",
    j = "N_numeric",
    i = ~ !duplicated(N_numeric),
    value = as_paragraph(
      as_i("N"),  
      " =\u2009",  # THIN SPACE (Unicode U+2009)
      as.character(format(N_numeric, big.mark = ",", scientific = FALSE))  # Keeps proper formatting
    )
  )
    

  # Add alternating row color for readability
  #total_rows <- nrow(data)
  #color_rows <- rep(FALSE, total_rows)
  #for (i in seq(1, total_rows, by = 12)) {
  #  color_rows[i:(i+5)] <- TRUE  
 # }
  #ft <- bg(ft, i = color_rows, bg = "#f0f0f0", part = "body")

  # Add table title
  ft <- add_header_lines(ft, values = title)

  return(ft)
}

# Generate flextables for each model
model1_table <- create_flextable(model1_data, "Model 1: Monte Carlo Results")
model2_table <- create_flextable(model2_data, "Model 2: Monte Carlo Results")
model3_table <- create_flextable(model3_data, "Model 3: Monte Carlo Results")

# Display tables
model1_table
model2_table
model3_table


```

Save Tables

```{r}
#| label: "render-violation-tables"
#| echo: true
#| message: false
#| warning: false

invisible(save_as_image(violation_summary_table, path = here('Simulations', 'STUDY_1', "2 Time Points", "zErrors", "l_l_e&v_1.svg"))
   )
```

------------------------------------------------------------------------

# PART 2 Re-Run Simulations

------------------------------------------------------------------------

### Re-Run Simulation with Dynamic Replication Conditions

## Model 1

```{r, eval=FALSE}
#| label: "lta-lta-simulation-Model 1b"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

  # Define the Mplus object with the dynamic replications
lta_lta_func <- function(N_numeric, TPs, Mix, Adjusted_Replications_Needed) {
  
  # Step 2.1: Construct the MODELPOPULATION argument based on the value of 'Mix'
  MODELPOPULATION <- if (Mix == 1) { 
    glue("	
      %OVERALL%
      [c1#1*-1.897] ;
      [c1#2*-0.798] ;
      [c2#1*-1.1] ; 
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs};
      c2#1 on c1#2*1.1; 
      c2#2 on c1#1*1.1; 
      c2#2 on c1#2*1.793147;

      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
      %c1#2%
      [u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
      %c1#3%
      [u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);

      MODEL POPULATION-c2:  
      %c2#1%
      [u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
      %c2#2%
      [u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
      %c2#3%
      [u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
    ")
  } else if (Mix == 2) { 
    glue("	
      %OVERALL%
      [c1#1*0] ;
      [c1#2*0] ;
      [c2#1*-1.1] ;
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs} ; 
      c2#1 on c1#2*1.1 ; 
      c2#2 on c1#1*1.1 ; 
      c2#2 on c1#2*1.793147 ;

      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
      %c1#2%
      [u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
      %c1#3%
      [u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);

      MODEL POPULATION-c2:  
      %c2#1%
      [u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
      %c2#2%
      [u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
      %c2#3%
      [u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
    ")
  } else if (Mix == 3) { 
    glue("	
      %OVERALL%
      [c1#1*1.792] ;
      [c1#2*1.099] ;
      [c2#1*-1.1] ; 
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs};
      c2#1 on c1#2*1.1; 
      c2#2 on c1#1*1.1; 
      c2#2 on c1#2*1.793147;

      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
      %c1#2%
      [u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
      %c1#3%
      [u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);

      MODEL POPULATION-c2:  
      %c2#1%
      [u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
      %c2#2%
      [u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
      %c2#3%
      [u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
    ")
  }

  # Step 2.2: Construct the MODEL argument based on the value of 'Mix'
  MODEL <- if (Mix == 1) { 
    glue("	
      %OVERALL%
      [c1#1*-1.897] ;
      [c1#2*-0.798] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);	

      MODEL c1:
      %c1#1%
      [u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
      %c1#2%
      [u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
      %c1#3%
      [u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);

      MODEL c2: 	
      %c2#1%
      [u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
      %c2#2%
      [u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
      %c2#3%
      [u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
    ")
  } else if (Mix == 2) { 
    glue("	
      %OVERALL%
      [c1#1*0] ;
      [c1#2*0] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);	

      MODEL c1:
      %c1#1%
      [u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
      %c1#2%
      [u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
      %c1#3%
      [u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);

      MODEL c2: 	
      %c2#1%
      [u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
      %c2#2%
      [u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
      %c2#3%
      [u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
    ")
  } else if (Mix == 3) { 
    glue("	
      %OVERALL%
      [c1#1*1.792] ;
      [c1#2*1.099] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);	

      MODEL c1:
      %c1#1%
      [u11$1*1 u12$1*1 u13$1*1 u14$1*1 u15$1*1] (p111-p115);
      %c1#2%
      [u11$1*1 u12$1*1 u13$1*-1 u14$1*-1 u15$1*-1] (p121-p125);
      %c1#3%
      [u11$1*-1 u12$1*-1 u13$1*-1 u14$1*-1 u15$1*-1] (p131-p135);

      MODEL c2: 	
      %c2#1%
      [u21$1*1 u22$1*1 u23$1*1 u24$1*1 u25$1*1] (p111-p115);
      %c2#2%
      [u21$1*1 u22$1*1 u23$1*-1 u24$1*-1 u25$1*-1] (p121-p125);
      %c2#3%
      [u21$1*-1 u22$1*-1 u23$1*-1 u24$1*-1 u25$1*-1] (p131-p135);
    ")
  }

  # Step 2.3: Construct the MODELCONSTRAINT argument based on the value of 'TPs'
  MODELCONSTRAINT <- if (TPs == 3.179) {
    glue("
      New(
        trans11*.8 trans12*.1 trans13*.1 
        trans21*.25 trans22*.5 trans23*.25);
      trans11 = exp(a1+b11)/(exp(a1+b11)+exp(a2+b12)+1);
      trans12 = exp(a2+b12)/(exp(a1+b11)+exp(a2+b12)+1);
      trans13 = 1-(trans11+trans12);
      trans21 = exp(a1+b21)/(exp(a1+b21)+exp(a2+b22)+1);
      trans22 = exp(a2+b22)/(exp(a1+b21)+exp(a2+b22)+1);
      trans23 = 1-(trans21+trans22);
    ")
  } else if (TPs == 0.407) {
    glue("
      New(
        trans11*.2 trans12*.4 trans13*.4 
        trans21*.25 trans22*.5 trans23*.25);
      trans11 = exp(a1+b11)/(exp(a1+b11)+exp(a2+b12)+1);
      trans12 = exp(a2+b12)/(exp(a1+b11)+exp(a2+b12)+1);
      trans13 = 1-(trans11+trans12);
      trans21 = exp(a1+b21)/(exp(a1+b21)+exp(a2+b22)+1);
      trans22 = exp(a2+b22)/(exp(a1+b21)+exp(a2+b22)+1);
      trans23 = 1-(trans21+trans22);
    ")
  }

  # Step 3: Construct the Mplus object
  LTA_LTA <- mplusObject(
    TITLE = glue("Generate LTA_LTA_M1_N_{N_numeric}_TP_{TPs}_M_{Mix}"),
    MONTECARLO = glue("NAMES = u11-u15 u21-u25;
      GENERATE = u11-u15 u21-u25(1);
      CATEGORICAL = u11-u15 u21-u25;
      GENCLASSES = c1(3) c2(3);
      CLASSES = c1(3) c2(3);
      NOBSERVATIONS = {N_numeric};
      SEED = 07252005;
      NREPS = {Adjusted_Replications_Needed};
      !SAVE = repM1*.dat;
      RESULTS = LTA_LTA_M1_N_{N_numeric}_TP_{TPs}_M_{Mix}.csv;"),
    
      ANALYSIS =
      "TYPE = MIXTURE;
      processors = 24;
      miterations = 1000; 
      starts= 100 15;
      logcriterion=0.00001;
      mconv=0.00001;",
    
    OUTPUT = "TECH9",
    
    MODELPOPULATION = MODELPOPULATION,
    MODEL = MODEL,
    MODELCONSTRAINT = MODELCONSTRAINT
  )

  # Run Mplus model
  LTA_LTA_Model <- mplusModeler(
    LTA_LTA, 
    dataout = here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED_REP', glue("LTA_LTA_N_{N_numeric}_TP_{TPs}_M_{Mix}.dat")),
    modelout = glue(here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED_REP', "LTA_LTA_M1_N_{N_numeric}_TP_{TPs}_M_{Mix}.inp")),
    check = TRUE, run = TRUE, hashfilename = FALSE
  )
  
  return(LTA_LTA_Model)
}

library(parallel)

# Start the cluster
num_cores <- detectCores() - 1

# Step 2: Select the cluster type based on the system (PSOCK for Windows, FORK for macOS/Linux)
cluster_type <- ifelse(.Platform$OS.type == "windows", "PSOCK", "FORK")

cl <- makeCluster(num_cores, type = cluster_type)

# Export necessary objects to the cluster
invisible(clusterExport(cl, c("lta_lta_func", "model1_data", "here", "glue", "mplusModeler", "mplusObject")))

# Ensure required libraries are loaded on each node
invisible(clusterEvalQ(cl, {
  library(MplusAutomation)
  library(glue)
  library(here)
}))

result_list <- parLapply(cl, 1:nrow(model1_data), function(i) {
  lta_lta_func(
    model1_data$N_numeric[i], 
    model1_data$TPs[i],  
    model1_data$Mix[i],  
    model1_data$Adjusted_Replications_Needed[i]
  )
})

# Stop the cluster after the simulation
stopCluster(cl)
```

## Model 2

```{r, eval=FALSE}
#| label: "lta-lta-simulation-model2b"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

  # Define the Mplus object with the dynamic replications
lta_lta_func2 <- function(N_numeric, TPs, Mix, Adjusted_Replications_Needed) {

  # Step 2.1: Construct the MODELPOPULATION argument based on 'Mix'
  MODELPOPULATION <- if (Mix == 1) { 
    glue("	
      %OVERALL%
      [c1#1*-1.897] ;
      [c1#2*-0.798] ;
      [c2#1*-1.1] ; 
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs};
      c2#1 on c1#2*1.1; 
      c2#2 on c1#1*1.1; 
      c2#2 on c1#2*1.793147;

      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*-5 u12$1*-1.21 u13$1*-1.45 u14$1*-1.55 u15$1*-5] (p111-p115);
      %c1#2%
      [u11$1*5 u12$1*-5 u13$1*.94 u14$1*-.02 u15$1*-.89] (p121-p125);
      %c1#3%
      [u11$1*-5 u12$1*1.55 u13$1*4.17 u14$1*-.16 u15$1*-1.99] (p131-p135);
      
      MODEL POPULATION-c2:
      %c2#1%
      [u21$1*-5 u22$1*-1.21 u23$1*-1.45 u24$1*-1.55 u25$1*-5] (p111-p115);
      %c2#2%
      [u21$1*5 u22$1*-5 u23$1*.94 u24$1*-.02 u25$1*-.89] (p121-p125);
      %c2#3%
      [u21$1*-5 u22$1*1.55 u23$1*4.17 u24$1*-.16 u25$1*-1.99] (p131-p135);
    ")
  } else if (Mix == 2) {
    glue("	
      %OVERALL%
      [c1#1*0] ;
      [c1#2*0] ;
      [c2#1*-1.1] ; 
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs};
      c2#1 on c1#2*1.1; 
      c2#2 on c1#1*1.1; 
      c2#2 on c1#2*1.793147;

      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*-5 u12$1*-1.21 u13$1*-1.45 u14$1*-1.55 u15$1*-5] (p111-p115);
      %c1#2%
      [u11$1*5 u12$1*-5 u13$1*.94 u14$1*-.02 u15$1*-.89] (p121-p125);
      %c1#3%
      [u11$1*-5 u12$1*1.55 u13$1*4.17 u14$1*-.16 u15$1*-1.99] (p131-p135);
      
      MODEL POPULATION-c2:
      %c2#1%
      [u21$1*-5 u22$1*-1.21 u23$1*-1.45 u24$1*-1.55 u25$1*-5] (p111-p115);
      %c2#2%
      [u21$1*5 u22$1*-5 u23$1*.94 u24$1*-.02 u25$1*-.89] (p121-p125);
      %c2#3%
      [u21$1*-5 u22$1*1.55 u23$1*4.17 u24$1*-.16 u25$1*-1.99] (p131-p135);
    ")
  } else if (Mix == 3) {
    glue("	
      %OVERALL%
      [c1#1*1.792] ;
      [c1#2*1.099] ;
      [c2#1*-1.1] ; 
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs};
      c2#1 on c1#2*1.1; 
      c2#2 on c1#1*1.1; 
      c2#2 on c1#2*1.793147;

      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*-5 u12$1*-1.21 u13$1*-1.45 u14$1*-1.55 u15$1*-5] (p111-p115);
      %c1#2%
      [u11$1*5 u12$1*-5 u13$1*.94 u14$1*-.02 u15$1*-.89] (p121-p125);
      %c1#3%
      [u11$1*-5 u12$1*1.55 u13$1*4.17 u14$1*-.16 u15$1*-1.99] (p131-p135);
      
      MODEL POPULATION-c2:
      %c2#1%
      [u21$1*-5 u22$1*-1.21 u23$1*-1.45 u24$1*-1.55 u25$1*-5] (p111-p115);
      %c2#2%
      [u21$1*5 u22$1*-5 u23$1*.94 u24$1*-.02 u25$1*-.89] (p121-p125);
      %c2#3%
      [u21$1*-5 u22$1*1.55 u23$1*4.17 u24$1*-.16 u25$1*-1.99] (p131-p135);
    ")
  }

  # Step 2.2: Construct the MODEL argument based on 'Mix'
  MODEL <- if (Mix == 1) {
    glue("	
      %OVERALL%
      [c1#1*-1.897] ;
      [c1#2*-0.798] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);
      
      MODEL c1:
      %c1#1%
      [u11$1*-5 u12$1*-1.21 u13$1*-1.45 u14$1*-1.55 u15$1*-5] (p111-p115);
      %c1#2%
      [u11$1*5 u12$1*-5 u13$1*.94 u14$1*-.02 u15$1*-.89] (p121-p125);
      %c1#3%
      [u11$1*-5 u12$1*1.55 u13$1*4.17 u14$1*-.16 u15$1*-1.99] (p131-p135);
      
      MODEL c2:
      %c2#1%
      [u21$1*-5 u22$1*-1.21 u23$1*-1.45 u24$1*-1.55 u25$1*-5] (p111-p115);
      %c2#2%
      [u21$1*5 u22$1*-5 u23$1*.94 u24$1*-.02 u25$1*-.89] (p121-p125);
      %c2#3%
      [u21$1*-5 u22$1*1.55 u23$1*4.17 u24$1*-.16 u25$1*-1.99] (p131-p135);
    ")
  } else if (Mix == 2) {
    glue("	
      %OVERALL%
      [c1#1*0] ;
      [c1#2*0] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);
      
      MODEL c1:
      %c1#1%
      [u11$1*-5 u12$1*-1.21 u13$1*-1.45 u14$1*-1.55 u15$1*-5] (p111-p115);
      %c1#2%
      [u11$1*5 u12$1*-5 u13$1*.94 u14$1*-.02 u15$1*-.89] (p121-p125);
      %c1#3%
      [u11$1*-5 u12$1*1.55 u13$1*4.17 u14$1*-.16 u15$1*-1.99] (p131-p135);
      
      MODEL c2:
      %c2#1%
      [u21$1*-5 u22$1*-1.21 u23$1*-1.45 u24$1*-1.55 u25$1*-5] (p111-p115);
      %c2#2%
      [u21$1*5 u22$1*-5 u23$1*.94 u24$1*-.02 u25$1*-.89] (p121-p125);
      %c2#3%
      [u21$1*-5 u22$1*1.55 u23$1*4.17 u24$1*-.16 u25$1*-1.99] (p131-p135);
    ")
  } else if (Mix == 3) {
    glue("	
      %OVERALL%
      [c1#1*1.792] ;
      [c1#2*1.099] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);
      
      MODEL c1:
      %c1#1%
      [u11$1*-5 u12$1*-1.21 u13$1*-1.45 u14$1*-1.55 u15$1*-5] (p111-p115);
      %c1#2%
      [u11$1*5 u12$1*-5 u13$1*.94 u14$1*-.02 u15$1*-.89] (p121-p125);
      %c1#3%
      [u11$1*-5 u12$1*1.55 u13$1*4.17 u14$1*-.16 u15$1*-1.99] (p131-p135);
      
      MODEL c2:
      %c2#1%
      [u21$1*-5 u22$1*-1.21 u23$1*-1.45 u24$1*-1.55 u25$1*-5] (p111-p115);
      %c2#2%
      [u21$1*5 u22$1*-5 u23$1*.94 u24$1*-.02 u25$1*-.89] (p121-p125);
      %c2#3%
      [u21$1*-5 u22$1*1.55 u23$1*4.17 u24$1*-.16 u25$1*-1.99] (p131-p135);
    ")
  }

  # Step 2.3: Construct the MODELCONSTRAINT argument based on 'TPs'
  MODELCONSTRAINT <- if (TPs == 3.179) {
    glue("
      New(
        trans11*.8 trans12*.1 trans13*.1 
        trans21*.25 trans22*.5 trans23*.25);
      trans11 = exp(a1+b11)/(exp(a1+b11)+exp(a2+b12)+1);
      trans12 = exp(a2+b12)/(exp(a1+b11)+exp(a2+b12)+1);
      trans13 = 1-(trans11+trans12);
      trans21 = exp(a1+b21)/(exp(a1+b21)+exp(a2+b22)+1);
      trans22 = exp(a2+b22)/(exp(a1+b21)+exp(a2+b22)+1);
      trans23 = 1-(trans21+trans22);
    ")
  } else if (TPs == 0.407) {
    glue("
      New(
        trans11*.2 trans12*.4 trans13*.4 
        trans21*.25 trans22*.5 trans23*.25);
      trans11 = exp(a1+b11)/(exp(a1+b11)+exp(a2+b12)+1);
      trans12 = exp(a2+b12)/(exp(a1+b11)+exp(a2+b12)+1);
      trans13 = 1-(trans11+trans12);
      trans21 = exp(a1+b21)/(exp(a1+b21)+exp(a2+b22)+1);
      trans22 = exp(a2+b22)/(exp(a1+b21)+exp(a2+b22)+1);
      trans23 = 1-(trans21+trans22);
    ")
  }
  
  # Step 2.4: Create and run Mplus model
  LTA_LTA2 <- mplusObject(
    TITLE = glue("Generate LTA_LTA_M2_N_{N_numeric}_TP_{TPs}_M_{Mix}"),
    MONTECARLO = glue("NAMES = u11-u15 u21-u25;
      GENERATE = u11-u15 u21-u25(1);
      CATEGORICAL = u11-u15 u21-u25;
      GENCLASSES = c1(3) c2(3);
      CLASSES = c1(3) c2(3);
      NOBSERVATIONS = {N_numeric};
      SEED = 07252005;
      NREPS = {Adjusted_Replications_Needed};
      !SAVE = repM2*.dat;
      RESULTS = LTA_LTA_M2_N_{N_numeric}_TP_{TPs}_M_{Mix}.csv;"),
    
      ANALYSIS =
      "TYPE = MIXTURE;
      processors = 24;
      miterations = 1000; 
      starts= 100 15;
      logcriterion=0.00001;
      mconv=0.00001;",
    
    OUTPUT = "TECH9",
    
    MODELPOPULATION = MODELPOPULATION,
    MODEL = MODEL,
    MODELCONSTRAINT = MODELCONSTRAINT
  )
  
  LTA_LTA_Model2 <- mplusModeler(
    LTA_LTA2, 
    dataout = here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED_REP', glue("LTA_LTA_M2_N_{N_numeric}_TP_{TPs}_M_{Mix}.dat")),
    modelout = glue(here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED_REP', "LTA_LTA_M2_N_{N_numeric}_TP_{TPs}_M_{Mix}.inp")),
    check = TRUE, run = TRUE, hashfilename = FALSE
  )
  return(LTA_LTA_Model2)
}

library(parallel)

# Start the cluster
num_cores <- detectCores() - 1

# Step 2: Select the cluster type based on the system (PSOCK for Windows, FORK for macOS/Linux)
cluster_type <- ifelse(.Platform$OS.type == "windows", "PSOCK", "FORK")

cl <- makeCluster(num_cores, type = cluster_type)

# Export necessary objects to the cluster
invisible(clusterExport(cl, c("lta_lta_func2", "model2_data", "here", "glue", "mplusModeler", "mplusObject")))

# Ensure required libraries are loaded on each node
invisible(clusterEvalQ(cl, {
  library(MplusAutomation)
  library(glue)
  library(here)
}))

result_list <- parLapply(cl, 1:nrow(model2_data), function(i) {
  lta_lta_func2(
    model2_data$N_numeric[i], 
    model2_data$TPs[i],  
    model2_data$Mix[i],  
    model2_data$Adjusted_Replications_Needed[i]
  )
})

# Stop the cluster after the simulation
stopCluster(cl)
```

## Model 3

```{r, eval=FALSE}
#| label: "lta-lta-simulation-model3b"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

  # Define the Mplus object with the dynamic replications
lta_lta_func3 <- function(N_numeric, TPs, Mix, Adjusted_Replications_Needed) {

  # Step 2.1: Construct the MODELPOPULATION argument for Model 3 based on 'Mix'
  MODELPOPULATION <- if (Mix == 1) { 
    glue("	
      %OVERALL%
      [c1#1*-1.897] ;
      [c1#2*-0.798] ;
      [c2#1*-1.1] ; 
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs};
      c2#1 on c1#2*1.1; 
      c2#2 on c1#1*1.1; 
      c2#2 on c1#2*1.793147;
  
      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*5 u12$1*2.38 u13$1*1.385 u14$1*4.59 u15$1*4.59] (p111-p115);
      %c1#2%
      [u11$1*.62 u12$1*.81 u13$1*.82 u14$1*.28 u15$1*1.39] (p121-p125);
      %c1#3%
      [u11$1*-1.45 u12$1*-2.44 u13$1*-5 u14$1*-1.70 u15$1*-.71] (p131-p135);

      MODEL POPULATION-c2:  
      %c2#1%
      [u21$1*5 u22$1*2.38 u23$1*1.385 u24$1*4.59 u25$1*4.59] (p111-p115);
      %c2#2%
      [u21$1*.62 u22$1*.81 u23$1*.82 u24$1*.28 u25$1*1.39] (p121-p125);
      %c2#3%
      [u21$1*-1.45 u22$1*-2.44 u23$1*-5 u24$1*-1.70 u25$1*-.71] (p131-p135);
    ")
  } else if (Mix == 2) { 
    glue("	
      %OVERALL%
      [c1#1*0] ;
      [c1#2*0] ;
      [c2#1*-1.1] ; 
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs};
      c2#1 on c1#2*1.1; 
      c2#2 on c1#1*1.1; 
      c2#2 on c1#2*1.793147;
      
      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*5 u12$1*2.38 u13$1*1.385 u14$1*4.59 u15$1*4.59] (p111-p115);
      %c1#2%
      [u11$1*.62 u12$1*.81 u13$1*.82 u14$1*.28 u15$1*1.39] (p121-p125);
      %c1#3%
      [u11$1*-1.45 u12$1*-2.44 u13$1*-5 u14$1*-1.70 u15$1*-.71] (p131-p135);

      MODEL POPULATION-c2:  
      %c2#1%
      [u21$1*5 u22$1*2.38 u23$1*1.385 u24$1*4.59 u25$1*4.59] (p111-p115);
      %c2#2%
      [u21$1*.62 u22$1*.81 u23$1*.82 u24$1*.28 u25$1*1.39] (p121-p125);
      %c2#3%
      [u21$1*-1.45 u22$1*-2.44 u23$1*-5 u24$1*-1.70 u25$1*-.71] (p131-p135);
    ")
  } else if (Mix == 3) { 
    glue("	
      %OVERALL%
      [c1#1*1.792] ;
      [c1#2*1.099] ;
      [c2#1*-1.1] ; 
      [c2#2*-1.1] ; 
      c2#1 on c1#1*{TPs};
      c2#1 on c1#2*1.1; 
      c2#2 on c1#1*1.1; 
      c2#2 on c1#2*1.793147;
      
      MODEL POPULATION-c1:
      %c1#1%
      [u11$1*5 u12$1*2.38 u13$1*1.385 u14$1*4.59 u15$1*4.59] (p111-p115);
      %c1#2%
      [u11$1*.62 u12$1*.81 u13$1*.82 u14$1*.28 u15$1*1.39] (p121-p125);
      %c1#3%
      [u11$1*-1.45 u12$1*-2.44 u13$1*-5 u14$1*-1.70 u15$1*-.71] (p131-p135);

      MODEL POPULATION-c2:  
      %c2#1%
      [u21$1*5 u22$1*2.38 u23$1*1.385 u24$1*4.59 u25$1*4.59] (p111-p115);
      %c2#2%
      [u21$1*.62 u22$1*.81 u23$1*.82 u24$1*.28 u25$1*1.39] (p121-p125);
      %c2#3%
      [u21$1*-1.45 u22$1*-2.44 u23$1*-5 u24$1*-1.70 u25$1*-.71] (p131-p135);
    ")
  }

  # Step 2.2: Construct the MODEL argument for Model 3 based on 'Mix'
  MODEL <- if (Mix == 1) { 
    glue("	
      %OVERALL%
      [c1#1*-1.897] ;
      [c1#2*-0.798] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);

      MODEL c1:
      %c1#1%
      [u11$1*5 u12$1*2.38 u13$1*1.385 u14$1*4.59 u15$1*4.59] (p111-p115);
      %c1#2%
      [u11$1*.62 u12$1*.81 u13$1*.82 u14$1*.28 u15$1*1.39] (p121-p125);
      %c1#3%
      [u11$1*-1.45 u12$1*-2.44 u13$1*-5 u14$1*-1.70 u15$1*-.71] (p131-p135);
      
      MODEL c2: 	
      %c2#1%
      [u21$1*5 u22$1*2.38 u23$1*1.385 u24$1*4.59 u25$1*4.59] (p111-p115);
      %c2#2%
      [u21$1*.62 u22$1*.81 u23$1*.82 u24$1*.28 u25$1*1.39] (p121-p125);
      %c2#3%
      [u21$1*-1.45 u22$1*-2.44 u23$1*-5 u24$1*-1.70 u25$1*-.71] (p131-p135);
    ")      
  } else if (Mix == 2) { 
    glue("	
      %OVERALL%
      [c1#1*0] ;
      [c1#2*0] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);

      MODEL c1:
      %c1#1%
      [u11$1*5 u12$1*2.38 u13$1*1.385 u14$1*4.59 u15$1*4.59] (p111-p115);
      %c1#2%
      [u11$1*.62 u12$1*.81 u13$1*.82 u14$1*.28 u15$1*1.39] (p121-p125);
      %c1#3%
      [u11$1*-1.45 u12$1*-2.44 u13$1*-5 u14$1*-1.70 u15$1*-.71] (p131-p135);
      
      MODEL c2: 	
      %c2#1%
      [u21$1*5 u22$1*2.38 u23$1*1.385 u24$1*4.59 u25$1*4.59] (p111-p115);
      %c2#2%
      [u21$1*.62 u22$1*.81 u23$1*.82 u24$1*.28 u25$1*1.39] (p121-p125);
      %c2#3%
      [u21$1*-1.45 u22$1*-2.44 u23$1*-5 u24$1*-1.70 u25$1*-.71] (p131-p135);
    ")      
  } else if (Mix == 3) { 
    glue("	
      %OVERALL%
      [c1#1*1.792] ;
      [c1#2*1.099] ;
      [c2#1*-1.1] (a1);
      [c2#2*-1.1] (a2); 
      c2#1 on c1#1*{TPs} (b11); 
      c2#1 on c1#2*1.1 (b21); 
      c2#2 on c1#1*1.1 (b12); 
      c2#2 on c1#2*1.793147 (b22);

      MODEL c1:
      %c1#1%
      [u11$1*5 u12$1*2.38 u13$1*1.385 u14$1*4.59 u15$1*4.59] (p111-p115);
      %c1#2%
      [u11$1*.62 u12$1*.81 u13$1*.82 u14$1*.28 u15$1*1.39] (p121-p125);
      %c1#3%
      [u11$1*-1.45 u12$1*-2.44 u13$1*-5 u14$1*-1.70 u15$1*-.71] (p131-p135);
      
      MODEL c2: 	
      %c2#1%
      [u21$1*5 u22$1*2.38 u23$1*1.385 u24$1*4.59 u25$1*4.59] (p111-p115);
      %c2#2%
      [u21$1*.62 u22$1*.81 u23$1*.82 u24$1*.28 u25$1*1.39] (p121-p125);
      %c2#3%
      [u21$1*-1.45 u22$1*-2.44 u23$1*-5 u24$1*-1.70 u25$1*-.71] (p131-p135);
    ")      
  }
  
  # Step 2.3: Construct the MODELCONSTRAINT argument based on TPs
  MODELCONSTRAINT <- if (TPs == 3.179) {
    glue("
      New(
        trans11*.8 trans12*.1 trans13*.1 
        trans21*.25 trans22*.5 trans23*.25);
      trans11 = exp(a1+b11)/(exp(a1+b11)+exp(a2+b12)+1);
      trans12 = exp(a2+b12)/(exp(a1+b11)+exp(a2+b12)+1);
      trans13 = 1-(trans11+trans12);
      trans21 = exp(a1+b21)/(exp(a1+b21)+exp(a2+b22)+1);
      trans22 = exp(a2+b22)/(exp(a1+b21)+exp(a2+b22)+1);
      trans23 = 1-(trans21+trans22);
    ")
  } else if (TPs == 0.407) {
    glue("
      New(
        trans11*.2 trans12*.4 trans13*.4 
        trans21*.25 trans22*.5 trans23*.25);
      trans11 = exp(a1+b11)/(exp(a1+b11)+exp(a2+b12)+1);
      trans12 = exp(a2+b12)/(exp(a1+b11)+exp(a2+b12)+1);
      trans13 = 1-(trans11+trans12);
      trans21 = exp(a1+b21)/(exp(a1+b21)+exp(a2+b22)+1);
      trans22 = exp(a2+b22)/(exp(a1+b21)+exp(a2+b22)+1);
      trans23 = 1-(trans21+trans22);
    ")
  }

  # Step 2.4: Create and run Mplus model
  LTA_LTA3 <- mplusObject(
    TITLE = glue("Generate LTA_LTA_M3_N_{N_numeric}_TP_{TPs}_M_{Mix}"),
    MONTECARLO = glue("NAMES = u11-u15 u21-u25;
      GENERATE = u11-u15 u21-u25(1);
      CATEGORICAL = u11-u15 u21-u25;
      GENCLASSES = c1(3) c2(3);
      CLASSES = c1(3) c2(3);
      NOBSERVATIONS = {N_numeric};
      SEED = 07252005;
      NREPS = {Adjusted_Replications_Needed};
      !SAVE = repM3*.dat;
      RESULTS = LTA_LTA_M3_N_{N_numeric}_TP_{TPs}_M_{Mix}.csv;"),
    
      ANALYSIS =
      "TYPE = MIXTURE;
      processors = 24;
      miterations = 1000; 
      starts= 100 15;
      logcriterion=0.00001;
      mconv=0.00001;",
    
    OUTPUT = "TECH9",
    
    MODELPOPULATION = MODELPOPULATION,
    MODEL = MODEL,
    MODELCONSTRAINT = MODELCONSTRAINT
  )

  # Run Mplus model
  LTA_LTA_Model3 <- mplusModeler(LTA_LTA3, 
                                 dataout = here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED_REP', glue("LTA_LTA_M3_N_{N_numeric}_TP_{TPs}_M_{Mix}.dat")),
                                 modelout = glue(here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED_REP', "LTA_LTA_M3_N_{N_numeric}_TP_{TPs}_M_{Mix}.inp")),
                                 check = TRUE, run = TRUE, hashfilename = FALSE)
  return(LTA_LTA_Model3)
}

library(parallel)

# Start the cluster
num_cores <- detectCores() - 1

# Step 2: Select the cluster type based on the system (PSOCK for Windows, FORK for macOS/Linux)
cluster_type <- ifelse(.Platform$OS.type == "windows", "PSOCK", "FORK")

cl <- makeCluster(num_cores, type = cluster_type)

# Export necessary objects to the cluster
invisible(clusterExport(cl, c("lta_lta_func3", "model3_data", "here", "glue", "mplusModeler", "mplusObject")))

# Ensure required libraries are loaded on each node
invisible(clusterEvalQ(cl, {
  library(MplusAutomation)
  library(glue)
  library(here)
}))

result_list <- parLapply(cl, 1:nrow(model3_data), function(i) {
  lta_lta_func3(
    model3_data$N_numeric[i], 
    model3_data$TPs[i],  
    model3_data$Mix[i],  
    model3_data$Adjusted_Replications_Needed[i]
  )
})



# Stop the cluster after the simulation
stopCluster(cl)


```

### Check for Label Switching and Errors - Part 2

> In this section: we re conduct the steps for aggregating the label switching and errors to guarantee that we will have at minimum 500 replications per condition.

------------------------------------------------------------------------

*Load all CSV files and combine them into a single data frame.*

```{r}
#| label: "combine-csv-files-parallel2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true



# Step 1: Set the correct CSV directory
csv_directory <- here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED_REP')

# Step 2: Source the child document
source(here('Child_Docs', 'data_scraping.R'))
```

Extract data from the appropriate rows from each 9-row chunk and prepare the data for further processing.

```{r}
#| label: "scrape-rows-process-data-parallel2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Step 2: Process the data using the child script
source(here('Child_Docs', 'step2_f_LTA.R'))

final_combined_data <- final_combined_data %>%
  mutate(
    TRANS11 = as.numeric(TRANS11),
    SE_11 = as.numeric(SE_11),
    across(starts_with("Ec"), as.numeric),  # Convert all Ec columns
    ll_csv = as.numeric(ll_csv)  # Convert Log-Likelihood values
  )


```

*Convert the logits to probabilities and add the known actual values to each row.*

```{r}
#| label: "convert-logits-and-flags2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Step 3 and 4: Process the data and return results
source(here('Child_Docs', 'step_3_3k.R'))

# The objects `final_data_with_actuals` and `violators` should now be in the global environment

```

*Scrape Output Files for Errors*

```{r}
#| label: "summarize-errors2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Step 1: Set the correct output directory for .out files
output_folder <- here('Simulations', 'STUDY_2', '1_LTA_GEN_LTA_ANALYZED_REP')

# Step 2: Source the child document that processes .out files
source(here('Child_Docs', 'out_scraping.R'))

# ===================================================== #
#  â SECTION 1 Generate Replication Summary Table
# ===================================================== #
replication_summary_table <- replication_summary %>%
  gt() %>%
  tab_header(
    title = "Replication Summary",
    subtitle = paste0("Folder: ", output_folder)
  ) %>%
  fmt_number(
    columns = c("Total", "Replicated_Yes", "Replicated_No", "Error_Count"),
    decimals = 0
  ) %>%
  cols_label(
    FileName = "File Name",
    Total = "Total Replications",
    Replicated_Yes = "LL Replicated",
    Replicated_No = "LL Not Replicated",
    Error_Count = "Errors"
  ) %>%
  cols_align(
    align = "center",
    columns = everything()
  ) %>%
  tab_options(
    table.font.size = "small",
    heading.title.font.size = "medium",
    heading.subtitle.font.size = "small",
    table.width = pct(80)
  )

# Display the table
replication_summary_table

# ===================================================== #
#  â SECTION 2 Row Count Validation
# ===================================================== #
cat("Rows in final_data_with_actuals:", nrow(final_data_with_actuals), "\n")
cat("Rows in final_results:", nrow(final_results), "\n")
cat("Rows in replication_summary:", nrow(replication_summary), "\n")
print(if (any(replication_summary$LL_Not_Replicated > 0, na.rm = TRUE)) {
  "â ï¸ WARNING: Some LL values were NOT replicated! Check the Replication Summary table."
} else {
  "â All LL values were successfully replicated."
})
all.equal(final_data_with_actuals$ll_csv, final_results$ll_out, tolerance = 1e-4)


###CHECK EXTRA ROWS
# Identify extra rows that are in final_results but not in final_data_with_actuals
extra_rows <- anti_join(final_results, final_data_with_actuals, by = c("FileName", "Replication"))

# Check if all extra rows have ErrorFlag == 1
all_errors <- all(extra_rows$ErrorFlag == 1, na.rm = TRUE)

# Message instead of printing raw data
if (all_errors) {
  message("â All extra rows have errors (ErrorFlag == 1).")
} else {
  message("â ï¸ Some extra rows do NOT have errors. Manual inspection needed.")
}
```

```{r}

#| label: "delete-extra-rows"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Identify extra rows that are in final_results but not in final_data_with_actuals
extra_rows <- anti_join(final_results, final_data_with_actuals, by = c("FileName", "Replication"))

# Filter to keep only extra rows where ErrorFlag == 1
rows_to_delete <- extra_rows %>% filter(ErrorFlag == 1)

# Delete only the extra rows with errors
if (nrow(rows_to_delete) > 0) {
  final_results <- anti_join(final_results, rows_to_delete, by = c("FileName", "Replication"))
  cat("â Deleted", nrow(rows_to_delete), "extra rows with errors.\n")
} else {
  cat("â No extra rows with errors were found. No deletions made.\n")
}

cat("Rows in final_data_with_actuals:", nrow(final_data_with_actuals), "\n")
cat("Rows in final_results:", nrow(final_results), "\n")

```

\

### Merge Errors with Main Data File

*Combine error information with main data file*

```{r}
#| label: "merge-errors2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

final_data_with_actuals <- final_data_with_actuals %>%
  left_join(
    final_results %>% select(FileName, Replication, ll_out, LL_Replicated, ErrorFlag), 
    by = c("FileName", "Replication")
  ) %>%
  mutate(
    Any_Violation = ifelse(is.na(Any_Violation), 0, Any_Violation),
    ErrorFlag = ifelse(is.na(ErrorFlag), 0, ErrorFlag),
    LL_Replicated = ifelse(LL_Replicated == "Yes", 1, 0),  # â Convert Yes/No to 1/0

    # ð¹ Create a new True Violation column
    True_Violation = case_when(
      Any_Violation == 1 | ErrorFlag == 1 | LL_Replicated == 0 ~ 1,  # â At least one violation
      TRUE ~ 0
    )
  )

```

Visualize differences between ll_out and ll_csv

```{r}
# Create a dataframe with only rows where ll_out and ll_csv differ
ll_mismatch <- final_data_with_actuals %>%
  mutate(diff = round(ll_out - ll_csv, 3)) %>%
  filter(diff != 0) %>%
  select(FileName, Replication, ll_out, ll_csv, diff)


ll_check <- final_data_with_actuals %>%
  mutate(diff = round(ll_out - ll_csv, 3)) %>%  # Round before counting
  count(diff)

ll_check_table <- ll_check %>%
  gt() %>%
  tab_header(
    title = "LL Difference Summary",
    subtitle = "Comparison of LL values between CSV and OUT files"
  ) %>%
  cols_label(
    diff = "LL Difference",
    n = "Count"
  ) %>%
  fmt_number(
    columns = diff,
    decimals = 3
  ) %>%
  cols_align(
    align = "center",
    columns = everything()
  ) %>%
  tab_options(
    table.font.size = "small",
    heading.title.font.size = "medium",
    heading.subtitle.font.size = "small",
    table.width = pct(50)
  )

# Display the table
ll_check_table
```

*Create Column Names from the File Name*

```{r}
#| label: "create-column-names-from-filename"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

final_data_with_actuals <- final_data_with_actuals %>%
  mutate(
    Model = case_when(
      grepl("m1", FileName) ~ "1",
      grepl("m2", FileName) ~ "2",
      grepl("m3", FileName) ~ "3",
      TRUE ~ NA_character_
    ),
    N = case_when(
      grepl("n_5000", FileName) ~ 4,  
      grepl("n_500", FileName) ~ 1,   
      grepl("n_1000", FileName) ~ 2,  
      grepl("n_2500", FileName) ~ 3,  
      TRUE ~ NA_integer_
    ),
    Mixing_proportion = case_when(
      grepl("m_1", FileName) ~ 1,  
      grepl("m_2", FileName) ~ 2,
      grepl("m_3", FileName) ~ 3,
      TRUE ~ NA_integer_
    ),
    # Add Population column based on FileName and convert it to a factor with formatted labels
    Population = case_when(
      grepl("tp_0.407", FileName) ~ "0.200",
      grepl("tp_3.179", FileName) ~ "0.800",
      TRUE ~ NA_character_
    )
  ) %>%
  # Convert columns to factors
  mutate(
    Model = factor(Model, levels = c(1, 2, 3), labels = c("Model 1", "Model 2", "Model 3")),
    N = factor(N, levels = c(1, 2, 3, 4), labels = c("N = 500", "N = 1000", "N = 2500", "N = 5000")),
    Mixing_proportion = factor(Mixing_proportion, levels = c(1, 2, 3), labels = c(".10, .30, .60", ".33, .33, .33", ".60, .30, .10")),
    Population = factor(Population, levels = c("0.200", "0.800"), labels = c(".200", ".800"))
  )

```

*Calculate Violation Percentages per Condition*

```{r}
#| label: "calculate-violations2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

violation_summary2 <- final_data_with_actuals %>%
  mutate(
    # Ensure numeric conversion for N
    N_numeric = as.numeric(gsub("N = ", "", as.character(N))),
    N_numeric = ifelse(is.na(N_numeric), 0, N_numeric)  # Ensure no missing values
  ) %>%
group_by(FileName, Model, Population, N, N_numeric, Mixing_proportion) %>%
  summarize(
    Total_Rows = n(),

    # Label Switching Violations
    Total_Violations = sum(Any_Violation, na.rm = TRUE),   

    # Mplus Errors
    Total_Errors = sum(ErrorFlag, na.rm = TRUE),           

    # LL Replication Failures
    Total_LL_Failures = sum(LL_Replicated == 0, na.rm = TRUE),  

    # Compute True Violation Count
    Total_True_Violations = sum(True_Violation, na.rm = TRUE),  

    # Compute Violation Percentages
    Percentage_Violations = round((Total_Violations / Total_Rows) * 100, 1),  
    True_Violation_Perc = round((Total_True_Violations / Total_Rows) * 100, 1),  
    ErrorRate = round((Total_Errors / Total_Rows) * 100, 1),  
    LL_Failure_Perc = round((Total_LL_Failures / Total_Rows) * 100, 1),  

    .groups = "drop"
  ) %>%
  mutate(
    # Compute Good Replications
    GoodReplications = Total_Rows - Total_True_Violations,
    GoodReplications = ifelse(GoodReplications < 0, 0, GoodReplications),

    # Reanalysis Needed Flag
    Reanalysis_Needed = if_else(GoodReplications >= 500, "No", "Yes")
  ) %>%
  mutate(
    # Compute `TPs`
    TPs = case_when(
      Population == ".800" ~ 3.179,
      Population == ".200" ~ 0.407,
      TRUE ~ NA_real_
    ),
    # Create a numeric variable for Mixing Proportion
    Mix = case_when(
      Mixing_proportion == ".10, .30, .60" ~ 1,
      Mixing_proportion == ".33, .33, .33" ~ 2,
      Mixing_proportion == ".60, .30, .10" ~ 3,
      TRUE ~ NA_integer_
    )
  ) %>%
  # Ensure `N_numeric` exists before arranging
  arrange(factor(N_numeric, levels = c(500, 1000, 2500, 5000)), as.numeric(Population)) %>%
  # Convert `N` and `Population` back to factors for consistency
  mutate(
    N = factor(N, levels = c("N = 500", "N = 1000", "N = 2500", "N = 5000")),
    Population = factor(Population, levels = c(".200", ".800"))
  ) %>%
  # Select and reorder columns
  select(
    FileName, Model, Population, TPs, N, N_numeric, Mix, Mixing_proportion,  
    Total_Rows,  
    Total_Violations, Percentage_Violations,  
    Total_Errors, ErrorRate,  
    Total_LL_Failures, LL_Failure_Perc,  
    Total_True_Violations, True_Violation_Perc,  
    GoodReplications,  
    Reanalysis_Needed 
  ) %>%
  # Ensure `N_numeric` is properly formatted
  arrange(N_numeric, Population) %>%
  mutate(N_numeric = as.numeric(trimws(as.character(N_numeric))))   # Ensure it's numeric

# Split into separate datasets for each model
model1_data <- violation_summary2 %>% filter(Model == "Model 1")
model2_data <- violation_summary2 %>% filter(Model == "Model 2")
model3_data <- violation_summary2 %>% filter(Model == "Model 3")


```

*Summarize & Visualize Label Switching Percentage Results*

```{r}
#| label: "summarize-violations2"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

library(flextable)
library(dplyr)

# Function to filter and format data for each model
create_combined_model_data <- function(data, model) {
  data %>%
    filter(Model == model) %>%
    select(
      N_numeric,  
      Population,  
      Mix,                     
      Total_Violations,
      Percentage_Violations,
      Total_Errors,
      ErrorRate,
      Total_LL_Failures,
      LL_Failure_Perc,
      Total_True_Violations,
      True_Violation_Perc,
      GoodReplications,
      Reanalysis_Needed
    )
}

# Generate datasets for each model
model1_data <- create_combined_model_data(violation_summary2, "Model 1")
model2_data <- create_combined_model_data(violation_summary2, "Model 2")
model3_data <- create_combined_model_data(violation_summary2, "Model 3")

# Function to create a flextable
create_flextable <- function(data, title) {
  data <- data %>%
    as.data.frame()  # Ensures proper structure before passing to flextable

  # Create the flextable
  ft <- flextable(data) %>%
    set_header_labels(
      N_numeric = "N",     
      Population = "T11",  
      Mix = "Mix",
      Total_Violations = "V",
      Percentage_Violations = "V %",
      Total_Errors = "\u03B5",  
      ErrorRate = "\u03B5 %",
      Total_LL_Failures = "ââ",  
      LL_Failure_Perc = "ââ %",
      Total_True_Violations = "\u03C4áµ¥",  
      True_Violation_Perc = "\u03C4áµ¥ %",
      GoodReplications = "Good Reps",
      Reanalysis_Needed = "Reanalysis Needed"
    )

  # Apply header formatting
  ft <- compose(ft, part = "header", j = "N_numeric", value = as_paragraph(as_i("N")))
  ft <- compose(ft, part = "header", j = "Population", value = as_paragraph(as_i("T"), as_sub("11")))
  # Label Switching Violations
  ft <- compose(ft, part = "header", j = "Total_Violations", value = as_paragraph(as_i("V")))
  ft <- compose(ft, part = "header", j = "Percentage_Violations", value = as_paragraph(as_i("V"), "%"))

  # Mplus Errors
  ft <- compose(ft, part = "header", j = "Total_Errors", value = as_paragraph(as_i("\u03B5")))
  ft <- compose(ft, part = "header", j = "ErrorRate", value = as_paragraph(as_i("\u03B5"), "%"))

  # LL Replication Failures
  ft <- compose(ft, part = "header", j = "Total_LL_Failures", value = as_paragraph(as_i("â"), as_sub("â")))  
  ft <- compose(ft, part = "header", j = "LL_Failure_Perc", value = as_paragraph(as_i("â"), as_sub("â"), "%"))

  # True Violations
  ft <- compose(ft, part = "header", j = "Total_True_Violations", value = as_paragraph(as_i("\u03C4"), as_sub("áµ¥")))  
  ft <- compose(ft, part = "header", j = "True_Violation_Perc", value = as_paragraph(as_i("\u03C4"), as_sub("áµ¥"), "%"))  

  # Good Replications and Reanalysis Needed
  ft <- compose(ft, part = "header", j = "GoodReplications", value = as_paragraph("Good", "\n", "Reps"))
  ft <- compose(ft, part = "header", j = "Reanalysis_Needed", value = as_paragraph("Reanalysis", "\n", "Needed?"))

  # Adjust column widths
  ft <- width(ft, j = "N_numeric", width = 1.0)
  ft <- width(ft, j = "Population", width = 0.8)  
  ft <- width(ft, j = "Mix", width = 0.6)
  ft <- width(ft, j = "Total_Violations", width = 0.6)
  ft <- width(ft, j = "Percentage_Violations", width = 0.6)
  ft <- width(ft, j = "Total_Errors", width = 0.5)
  ft <- width(ft, j = "ErrorRate", width = 0.5)
  ft <- width(ft, j = "Total_LL_Failures", width = 0.6)
  ft <- width(ft, j = "LL_Failure_Perc", width = 0.6)
  ft <- width(ft, j = "Total_True_Violations", width = 0.6)
  ft <- width(ft, j = "True_Violation_Perc", width = 0.6)
  ft <- width(ft, j = "GoodReplications", width = 0.6)
  ft <- width(ft, j = "Reanalysis_Needed", width = 0.7)

  # Format percentage columns
  ft <- colformat_num(
    ft,
    j = c("Percentage_Violations", "ErrorRate"),  
    suffix = "%"
  )

  # Enable autofit
  ft <- set_table_properties(ft, layout = "fixed")

  # Center all cells
  ft <- align(ft, align = "center", part = "all")

  # Align header text at the bottom
  ft <- valign(ft, part = "header", valign = "bottom")

  # Merge vertically identical rows in the "N_numeric" column
  ft <- merge_v(ft, j = "N_numeric")

  # Apply font settings
  ft <- font(ft, fontname = "Avenir Next", part = "all")
    ft <- compose(
    ft,
    part = "body",
    j = "N_numeric",
    i = ~ !duplicated(N_numeric),
    value = as_paragraph(
      as_i("N"),  
      " =\u2009",  # THIN SPACE (Unicode U+2009)
      as.character(format(N_numeric, big.mark = ",", scientific = FALSE))  # Keeps proper formatting
    )
  )
    
  # Add table title
  ft <- add_header_lines(ft, values = title)

  return(ft)
}

# Generate flextables for each model
model1_table <- create_flextable(model1_data, "Model 1: Monte Carlo Results")
model2_table <- create_flextable(model2_data, "Model 2: Monte Carlo Results")
model3_table <- create_flextable(model3_data, "Model 3: Monte Carlo Results")

# Display tables
model1_table
model2_table
model3_table

```

Save the Table

```{r}
#| label: "render-violation-tables2"
#| echo: true
#| message: false
#| warning: false

invisible(save_as_image(violation_summary_table, path = here('Simulations', 'STUDY_1', "2 Time Points", "zErrors", "zl_l_e&v_2.svg")
   ))
```

Prepare data for Submission Table

```{r}
#| label: "prepare-data-final-table"
#| echo: true
#| message: false
#| warning: false

# Step 1: Rename columns in violation_summary2 (except join keys)
violation_summary2 <- violation_summary2 %>%
  rename_with(~ paste0(.x, "_2"), 
              -c(FileName, Population, N, N_numeric))

# Step 2: Merge both datasets on common keys
violation_summary_final <- violation_summary %>%
  left_join(violation_summary2, by = c("FileName", "Population", "N", "N_numeric")) %>%
  mutate(
    Total_Rows = Total_Rows,
    Violation_Rate = Percentage_Violations,  
    Error_Rate = ErrorRate,
    Final_Violation_Rate = Percentage_Violations_2,
    Final_Error_Rate = ErrorRate_2,
    Reps_Needed_for_Success = Replications_Needed,
    Successful_Replications = GoodReplications_2,
    Status = if_else(Successful_Replications >= 500, "â Fixed", "â ï¸ Additional Runs Required")
  ) %>%
  select(
    N_numeric, Population, Total_Rows, Violation_Rate, Error_Rate, Reps_Needed_for_Success, 
    Final_Violation_Rate, Final_Error_Rate, Successful_Replications, Status
  ) %>%
arrange(factor(N_numeric, levels = c(500, 1000, 2000, 4000)), Population) %>%
mutate(N_numeric = trimws(as.numeric(N_numeric)))


```

Create flextable Function for Final Table

```{r}
create_flextable <- function(data) {
  
  # Keep only the required columns
  data <- data %>%
    select(
      N_numeric,  
      Population,  
      Total_Rows,
      Violation_Rate,
      Error_Rate,
      Reps_Needed_for_Success,
      Final_Violation_Rate,
      Final_Error_Rate,
      Successful_Replications
    ) %>%
    as.data.frame()  

  # Create the flextable
  ft <- flextable(data) %>%
    set_header_labels(
      N_numeric = "N",
      Population = "T11",  
      Total_Rows = "N Reps",
      Violation_Rate = "V %",
      Error_Rate = "\u03B5 %",  
      Reps_Needed_for_Success = "Reps Needed",
      Final_Violation_Rate = "V %",
      Final_Error_Rate = "\u03B5 %",
      Successful_Replications = "Successful Reps"
    )

  # Apply special formatting to headers
  ft <- compose(ft, part = "header", j = "N_numeric", value = as_paragraph(as_i("N")))
  ft <- compose(ft, part = "header", j = "Population", value = as_paragraph(as_i("T"), as_sub("11")))
  ft <- compose(ft, part = "header", j = "Total_Rows", value = as_paragraph(as_i("N"), "\n", "Reps"))
  ft <- compose(ft, part = "header", j = "Violation_Rate", value = as_paragraph(as_i("V"), "%"))
  ft <- compose(ft, part = "header", j = "Error_Rate", value = as_paragraph("\u03B5", "%"))
  ft <- compose(ft, part = "header", j = "Final_Violation_Rate", value = as_paragraph(as_i("V"), "%"))
  ft <- compose(ft, part = "header", j = "Final_Error_Rate", value = as_paragraph("\u03B5", "%"))
  ft <- compose(ft, part = "header", j = "Reps_Needed_for_Success", value = as_paragraph("Reps", "\n", "Needed"))
  ft <- compose(ft, part = "header", j = "Successful_Replications", value = as_paragraph("Successful", "\n", "Reps"))

  # **Correct vertical centering: Merge "N = _" across 6-row blocks**
  ft <- merge_v(ft, j = "N_numeric")  

  # **Ensure "N = ..." appears only ONCE in the center of the 6-row block**
  ft <- compose(
    ft,
    part = "body",
    j = "N_numeric",
    i = seq(1, nrow(data), by = 6),  # â This controls correct positioning
    value = as_paragraph(
      as_i("N"),  
      " =\u2009",  # THIN SPACE (Unicode U+2009)
      as_character(format(N_numeric, big.mark = ",", scientific = FALSE))  
    )
  )

  # **Fully remove duplicate N values in merged rows**
  ft <- compose(
    ft,
    part = "body",
    j = "N_numeric",
    i = setdiff(1:nrow(data), seq(1, nrow(data), by = 6)),  
    value = as_paragraph("")
  )

  # **Align vertically centered**
  ft <- valign(ft, j = "N_numeric", valign = "center", part = "body")

  # Center all text
  ft <- align(ft, align = "center", part = "all")

  # Set column widths
  ft <- width(ft, j = "N_numeric", width = .9)
  ft <- width(ft, j = "Population", width = 0.6)  
  ft <- width(ft, j = "Total_Rows", width = 0.6) 
  ft <- width(ft, j = "Violation_Rate", width = 0.6)
  ft <- width(ft, j = "Error_Rate", width = 0.4)
  ft <- width(ft, j = "Reps_Needed_for_Success", width = .7)
  ft <- width(ft, j = "Final_Violation_Rate", width = 0.6)
  ft <- width(ft, j = "Final_Error_Rate", width = 0.4)
  ft <- width(ft, j = "Successful_Replications", width = .6)

  # Apply percentage formatting
  ft <- colformat_num(
    ft,
    j = c("Violation_Rate", "Error_Rate", "Final_Violation_Rate", "Final_Error_Rate"),  
    suffix = "%"  
  )
  
ft <- add_header_row(
  ft,
  values = c(" ", "Initial Reps", "Final Reps", " "),
  colwidths = c(2, 3, 3, 1)
)

  # Define a transparent border
  no_border <- fp_border(color = "transparent", width = 0)

  # **Remove ONLY the bottom border under the first three columns (the blank subheader)**
  ft <- hline(ft, i = 1, j = 1:2, border = no_border, part = "header")
  ft <- hline(ft, i = 1, j = 9, border = no_border, part = "header")

  # Autofit table layout
  ft <- set_table_properties(ft, layout = "fixed")

  # Apply font settings
  ft <- font(ft, fontname = "Avenir Next", part = "all")

  # Get total number of rows
total_rows <- nrow(data)

# Create a logical vector marking every 6 rows for coloring
color_rows <- rep(FALSE, total_rows)  
for (i in seq(1, total_rows, by = 12)) {  
  color_rows[i:(i+5)] <- TRUE  # â Color every 6-row block
}

# Apply background color
ft <- bg(ft, i = color_rows, bg = "#f0f0f0", part = "body")

  return(ft)
}

# Generate formatted flextable
violation_summary_final_table <- create_flextable(violation_summary_final)
violation_summary_final_table

```

Save FINAL table

```{r}

invisible(save_as_image(violation_summary_final_table, path = here('Simulations', 'STUDY_1', "2 Time Points", "zErrors", "zl_l_e&v_FINAL.svg")
   ))
```

------------------------------------------------------------------------

# Final Data Preparation

------------------------------------------------------------------------

## Filter Cases with Violations and Errors

*Filter out cases with any violations, leaving only the clean data.*

```{r}
#| label: "delete-cases"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Filter out cases with no violations and no errors
filtered_data_with_no_violations <- final_data_with_actuals[
  final_data_with_actuals$True_Violation == 0, ]

# Check the number of remaining rows after filtering
cat("Remaining rows after filtering:", nrow(filtered_data_with_no_violations), "\n")

# Verify if there are any remaining violations or errors
cat("Any remaining violations:", sum(filtered_data_with_no_violations$True_Violation), "\n")
cat("Any remaining errors:", sum(filtered_data_with_no_violations$ErrorFlag), "\n")

```

------------------------------------------------------------------------

## Calculate Monte Carlo Values via Bootstrapping

*Calculate Monte Carlo values forÂ `TRANS11`, including population values, averages, standard errors, Mean Squared Error (MSE), coverage, power, and dichotomous variables for Power and Coverage,*

```{r}
library(dplyr)
library(purrr)

# 1. Create a function that calculates mc_values from raw replication-level data
calc_mc_values <- function(data) {
  # Step A: Clean and convert columns as needed
  cleaned_data <- data %>%
    mutate(
      Population = as.numeric(as.character(Population)),
      TRANS11 = as.numeric(as.character(TRANS11)),
      SE_11 = as.numeric(as.character(SE_11))
    )
  
  # Step B: Compute group-level summaries (without grouping by Transitions)
  mc_values <- cleaned_data %>%
    group_by(Model, Population, N, Mixing_proportion) %>%
    summarize(
      group_size   = n(),
      average      = round(mean(TRANS11, na.rm = TRUE), 3),
      average_SE   = round(mean(SE_11, na.rm = TRUE), 3),
      population_sd= round(sd(TRANS11, na.rm = TRUE), 3),
      MSE          = round(mean((TRANS11 - Population)^2, na.rm = TRUE), 3),
      Coverage     = round(mean((Population >= (TRANS11 - 1.96 * SE_11)) &
                                  (Population <= (TRANS11 + 1.96 * SE_11)), na.rm = TRUE), 3),
      Power        = round(mean(TRANS11 / SE_11 > 1.96, na.rm = TRUE), 3),
      Reps_Used    = n(),
      .groups = "drop"
    )
  
  # Step C: Merge in Transitions from the raw data (or from an auxiliary table if needed)
  mc_values <- cleaned_data %>%
    select(FileName, Model, Population, N, Mixing_proportion) %>%
    distinct() %>%
    right_join(mc_values, by = c("Model", "Population", "N", "Mixing_proportion"))
  
  # Step D: Calculate bias measures
  mc_values <- mc_values %>%
    mutate(
      Parameter_Bias_boot = round((average - Population) / Population * 100, 2),
      SE_Bias_boot        = round((average_SE - population_sd) / (population_sd + 1e-6) * 100, 2)
    )
  
  # (Optional: add any further transformations or dichotomizations)
  
  return(mc_values)
}

# 2. Create a parallelized bootstrap function that uses the above calculation on bootstrap samples
bootstrap_mc_values <- function(data, n_bootstrap, sample_size) {
  
  # Step A: Detect available cores and create a parallel cluster
  num_cores <- detectCores() - 1  # Use one less than total cores to avoid overloading the system
  cluster_type <- ifelse(.Platform$OS.type == "windows", "PSOCK", "FORK")  # Use FORK for Mac/Linux, PSOCK for Windows
  cl <- makeCluster(num_cores, type = cluster_type)  # Create the cluster
  
  # Step B: Export necessary functions and objects to the cluster workers
  clusterExport(cl, c("calc_mc_values"))
  clusterEvalQ(cl,library(dplyr))  # Ensure each worker loads the required package

  # Step C: Group data by condition variables (Population, N, Transitions)
  grouped_data <- data %>%
    group_by(Model, Population, N, Mixing_proportion) %>%
    group_split()  # Split data so each group runs separately in parallel
  
  # Step D: Perform bootstrapping in parallel across worker nodes
  boot_results <- parLapply(cl, grouped_data, function(group_data) {
    map_dfr(1:n_bootstrap, function(i) {
      # Step D1: Draw a bootstrap sample (with replacement) from the replications in this condition
      boot_sample <- group_data %>% sample_n(sample_size, replace = TRUE)
      
      # Step D2: Calculate MC values for the bootstrap sample
      boot_mc <- calc_mc_values(boot_sample)
      
      # Step D3: Add Bootstrap Iteration number
      boot_mc %>% mutate(Bootstrap_Iteration = i)
    })
  }) %>%
    bind_rows()  # Step E: Combine results from all parallel workers into a single dataframe

  # Step F: Stop the parallel cluster to free system resources
  stopCluster(cl)

  # Step G: Return the final bootstrapped MC values
  return(boot_results)
}

# 3. Run the bootstrap procedure on your raw replication-level data
set.seed(07252005)
boot_results <- bootstrap_mc_values(filtered_data_with_no_violations, n_bootstrap = 1000, sample_size = 500)

# 4. Aggregate the bootstrap results to get mean bootstrap estimates per condition:
bootstrap_aggregates <- boot_results %>%
  group_by(Model, Population, N, Mixing_proportion) %>%
  summarize(
    Parameter_Bias = mean(Parameter_Bias_boot, na.rm = TRUE),
    SE_Bias       = mean(SE_Bias_boot, na.rm = TRUE),
    .groups = "drop"
  )

# 5. Calculate your original mc_values (using the full replication set) for comparison:
original_mc_values <- calc_mc_values(filtered_data_with_no_violations)

# 6. Merge the bootstrap aggregates back to the original values (if desired)
final_mc_values <- original_mc_values %>%
  left_join(bootstrap_aggregates, by = c("Model", "Population", "N", "Mixing_proportion")) %>%
  mutate(
    Power_Dic    = ifelse(Power >= 0.8, 1, 0),
    Coverage_Dic = ifelse(Coverage > 0.98 | Coverage < 0.91, 0, 1)
  )

# Save or inspect the results
# Save results
write.csv(final_mc_values, here("Simulations", "STUDY_2", "zbootstrapping", "l_l_2t_mc_final_mc_values.csv"), row.names = FALSE)
write.csv(boot_results, here("Simulations", "STUDY_2", "zbootstrapping", "l_l_2t_boot_results.csv"), row.names = FALSE)

```

------------------------------------------------------------------------

## Prepare Data for Visualization

### Subset Data for Bias Plots

*Subset the Monte Carlo data into mover transition probabilities (.2) and stayer transition probabilities (.8) based on population values*

```{r}
#| label: "subset-data-movers-stayers"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

final_mc_values <- final_mc_values %>%
  mutate(
    N = factor(N, levels = c("N = 500", "N = 1000", "N = 2500", "N = 5000")),
    Model = factor(Model, levels = c("Model 1", "Model 2", "Model 3")),
    Mixing_proportion = factor(Mixing_proportion, 
                               levels = c(".10, .30, .60", ".33, .33, .33", ".60, .30, .10"))
  ) %>%
  arrange(Model, Mixing_proportion, N)


# Step 1: Subset data for transitions movers (Population == 0.2)
subset_mover <- subset(final_mc_values, Population == 0.2)

# Step 2: Subset data for transitions stayers (Population == 0.8)
subset_stayer <- subset(final_mc_values, Population == 0.8)



```

### Prepare Function for Bias Plots

```{r}
#| label: "create-bias-plots"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Step 1: Define a custom theme (used for both plots)
common_theme <- theme_minimal() +
  theme(
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.major.y = element_line(color = "gray", linewidth = 0.2),  # Major y-axis lines
    panel.grid.minor.y = element_blank(),
    axis.text.x = element_text(size = 8, color = "black"),  # Style for x-axis text
    axis.ticks = element_line(color = "black", size = 0.6),
    legend.position = "bottom",
    legend.title = element_blank(),
    text = element_text(family = "Times New Roman"),
    axis.title.x = element_text(margin = margin(t = 10, b = 10)),
    legend.margin = margin(t = -10),
    plot.caption = element_text(hjust = 0, margin = margin(t = 10))
  )

# Step 2: Define common labels function
common_labels <- function(title) {
  labs(
    x = "Sample Size",  
    y = "Bias (%)",
    color = "",
    title = title
  )
}

# Step 3: Create the plot function using the common theme and labels
create_bias_plot <- function(data, title, ylim_range) {
  
  # Identify which legends are present in the data
  present_categories <- c("Parameter Bias", "Standard Error Bias")
  if (any(data$Coverage_Dic == 0)) present_categories <- c(present_categories, "Coverage Failure")
  if (any(data$Power_Dic == 0)) present_categories <- c(present_categories, "Power Failure")
  
  # Define colors and shapes
  colors <- c("Parameter Bias" = "#7030A0", "Standard Error Bias" = "#C830CC", 
              "Coverage Failure" = "#7030A0", "Power Failure" = "black")
  shapes <- c("Parameter Bias" = 16, "Standard Error Bias" = 18, 
              "Coverage Failure" = 1, "Power Failure" = 4)
  
  # Filter the colors and shapes based on present categories
  filtered_colors <- colors[present_categories]
  filtered_shapes <- shapes[present_categories]
  
  ggplot(data, aes(x = factor(N))) +  
    geom_line(aes(y = Parameter_Bias, color = "Parameter Bias", group = Model), linewidth = 0.5, linetype = "solid") +  
    geom_line(aes(y = SE_Bias, color = "Standard Error Bias", group = Model), linewidth = 0.5, linetype = "solid") +  
    geom_point(aes(y = Parameter_Bias, color = "Parameter Bias"), shape = 16, size = 1.7, fill = "#7030A0", alpha = 1) +  
    geom_point(aes(y = SE_Bias, color = "Standard Error Bias"), shape = 18, size = 2.5, fill = "#C830CC", alpha = 1) +  
    geom_point(data = subset(data, Coverage_Dic == 0), aes(y = Parameter_Bias, color = "Coverage Failure"), shape = 1, size = 3, fill = "#7030A0", alpha = 1) +  
    geom_point(data = subset(data, Power_Dic == 0), aes(y = Parameter_Bias, color = "Power Failure"), shape = 4, size = 3, fill = "black", alpha = 1) +  
    scale_color_manual(
      values = filtered_colors, 
      labels = present_categories, 
      breaks = present_categories,
      guide = guide_legend(
        override.aes = list(
          shape = filtered_shapes
        )
      )
    ) +  
    common_labels(title) +  # Using the common labels function
    coord_cartesian(ylim = ylim_range) +  
    facet_grid(Mixing_proportion ~ Model, scales = "free", space = "free_y") + 
    scale_x_discrete(labels = c(expression(italic("N") ~ " = 500"), expression(italic("N") ~ " = 1000"), expression(italic("N") ~ " = 2500"), expression(italic("N") ~ " = 5000"))) +  
    scale_y_continuous(breaks = seq(ylim_range[1], ylim_range[2], by = 20)) +  
    common_theme +  # Apply the common theme
    theme(
      legend.position = "bottom", 
      strip.placement = "top",  # Move facet labels to the top
      strip.background = element_blank(),
      panel.spacing = unit(0.5, "lines"),
      axis.text.x = element_text(angle = 45, hjust = 1, size = 8),  # Rotate x-axis labels for readability
      plot.margin = margin(r = 20)  # Add margin to the right side
    ) +
    geom_hline(yintercept = c(-10, 10), linetype = "dashed", color = "#7030A0", linewidth = 0.3) +  
    geom_hline(yintercept = c(-5, 5), linetype = "dashed", color = "#C830CC", linewidth = 0.3)
}

```

### Render Bias Figures

```{r}
#| label: "plot-movers"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Plot for movers (population = 0.2)
plot_mover <- create_bias_plot(subset_mover, "LTA Generated / LTA Analyzed with Mover Transition Probabilities", c(-100, 60))
print(plot_mover)


```

```{r}
# Plot for movers (population = 0.2)
plot_mover <- create_bias_plot(subset_mover, "LTA Generated / LTA Analyzed with Mover Transition Probabilities", c(-20, 20))
print(plot_mover)
```

```{r}
#| label: "plot-stayers"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Plot for stayers (population = 0.8)
plot_stayer <- create_bias_plot(subset_stayer, "LTA Generated / LTA Analyzed with Stationary Transition Probabilities", c(-60, 40))
print(plot_stayer)

```

```{r}
#| label: "plot-stayers"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Plot for stayers (population = 0.8)
plot_stayer <- create_bias_plot(subset_stayer, "LTA Generated / LTA Analyzed with Stationary Transition Probabilities", c(-10, 10))
print(plot_stayer)

```

------------------------------------------------------------------------

### **Prepare Data for Heat Maps**

*Prepare data for heat map creation by ensuring correct formatting for population values, and subsetting the data based on class proportions and sample sizes.*

```{r}
#| label: "prepare-data-for-heatmaps"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Step 1: Ensure N is treated as a factor with the correct levels in order 
# No need to create N_Label; N is already a factor with correct labels
# Step 2: Order heatmap_data by population, Mixing_proportion, Model, and N
# Convert 'Population' into a factor with proper levels
heatmap_data <- mc_values %>%
  mutate(Population = factor(Population, levels = c(0.2, 0.8), labels = c(".200", ".800"))) %>%
  arrange(Population, Mixing_proportion, Model, N)


# Step 3: Create subsets for each combination of population and class proportions
subset_0.2_even_proportions <- subset(heatmap_data, Population == ".200" & Mixing_proportion == "Even Proportions",
                                       select = c(N, average, Coverage, Power, Parameter_Bias, SE_Bias))

subset_0.2_uneven_proportions <- subset(heatmap_data, Population == ".200" & Mixing_proportion == "Uneven Proportions",
                                         select = c(N, average, Coverage, Power, Parameter_Bias, SE_Bias))

subset_0.8_even_proportions <- subset(heatmap_data, Population == ".800" & Mixing_proportion == "Even Proportions",
                                       select = c(N, average, Coverage, Power, Parameter_Bias, SE_Bias))

subset_0.8_uneven_proportions <- subset(heatmap_data, Population == ".800" & Mixing_proportion == "Uneven Proportions",
                                         select = c(N, average, Coverage, Power, Parameter_Bias, SE_Bias))

# Step 4: Store subsets in a list for easier access and management
subset_list <- list(
  subset_0.2_even_proportions = subset_0.2_even_proportions,
  subset_0.2_uneven_proportions = subset_0.2_uneven_proportions,
  subset_0.8_even_proportions = subset_0.8_even_proportions,
  subset_0.8_uneven_proportions = subset_0.8_uneven_proportions
)

```

### Prepare Function for Heat Map Creation

```{r}
#| label: "create-heatmap-function"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true


# Function to create the gt heatmap table
create_table <- function(subset, transition_probability) {

  
  # Step 2: Create the gt object and set initial formatting
  gt_table <- subset %>%
    gt() %>%
    opt_table_font(stack = "geometric-humanist") %>%
    tab_header(
      title = paste("LTA Generated & LTA Analyzed with Transition Probability of", transition_probability)
    ) %>%
    cols_label(
      N = "Sample Size",  # This will now use the ordered N values
      average = "Estimated<br>Probability",
      Coverage = "Coverage",
      Power = "Power",
      Parameter_Bias = "Parameter<br>Bias",
      SE_Bias = "Standard Error<br>Bias",
      .fn = md
    ) %>%
    tab_spanner(
      label = "Bias",
      columns = c("Parameter_Bias", "SE_Bias")
    ) %>%
    tab_row_group(label = "Model 3", rows = 9:12) %>%
    tab_row_group(label = "Model 2", rows = 5:8) %>%
    tab_row_group(label = "Model 1", rows = 1:4) %>%
    tab_style(
      style = cell_text(font = "bold italic"),  # Bold and italic styling for row subheaders
      locations = cells_row_groups()
    ) %>% 
    fmt_number(columns = c("Parameter_Bias", "SE_Bias"), decimals = 2) %>%  
    fmt_number(columns = 4, decimals = 3) %>%
    tab_options(
      table_body.hlines.color = "white",
      table.border.top.color = "black",
      table.border.bottom.color = "black",
      heading.border.bottom.color = "black",
      column_labels.border.top.color = "black",
      column_labels.border.bottom.color = "black",
      row_group.border.top.color = "black",
      row_group.border.bottom.color = "black"
    ) %>%
    cols_align(align = "center", columns = everything())

  # Apply color highlighting for violations in Parameter Bias
  if (any(!(subset$Parameter_Bias >= -9.99 & subset$Parameter_Bias <= 9.99), na.rm = TRUE)) {
    gt_table <- gt_table %>%
      data_color(
        columns = "Parameter_Bias",
        rows = .data$Parameter_Bias < -9.99 | .data$Parameter_Bias > 9.99,  # Apply color only if outside the threshold
        method = "numeric",
        palette = c("#113386", "#DAE3FA", "#113386"),  # Darker blue for larger deviations
        domain = c(-40, 40)  # Adjust the domain to reflect the range of values
      ) %>%
      tab_footnote(
        footnote = md("Darker blue indicates larger deviations from zero *Parameter Bias* beyond the Â±9.99 threshold."),
        locations = cells_column_labels(columns = "Parameter_Bias")
      )
  }

  # Apply color highlighting for violations in SE Bias
  if (any(!(subset$SE_Bias >= -4.99 & subset$SE_Bias <= 4.99), na.rm = TRUE)) {
    gt_table <- gt_table %>%
      data_color(
        columns = "SE_Bias",
        rows = .data$SE_Bias < -4.99 | .data$SE_Bias > 4.99,  # Apply color only if outside the threshold
        method = "numeric",
        palette = c("#B4186E", "#F9D5E9", "#B4186E"),  # Darker red for larger deviations
        domain = c(-80, 80)  # Adjust the domain for the SE_Bias range
      ) %>%
      tab_footnote(
        footnote = md("Darker red indicates larger deviations from zero *Standard Error Bias* beyond the Â±4.99 threshold."),
        locations = cells_column_labels(columns = "SE_Bias")
      )
  }

  if (any(subset$Coverage < 0.93 | subset$Coverage > 0.979, na.rm = TRUE)) {
    gt_table <- gt_table %>%
      data_color(
        columns = "Coverage",
        rows = subset$Coverage < 0.93 | subset$Coverage > 0.979,
        method = "numeric",
        palette = c("#93C6B1", "white"),  # Green for coverage issues
        domain = c(0, 1)
      ) %>%
      tab_footnote(
        footnote = md("Green indicates failure to achieve adequate *Coverage*."),
        locations = cells_column_labels(columns = "Coverage")
      )
  }

  if (any(subset$Power < 0.8, na.rm = TRUE)) {
    gt_table <- gt_table %>%
      data_color(
        columns = "Power",
        rows = subset$Power < 0.8,
        method = "numeric",
        palette = c("#502CD1", "white"),  # Purple for power issues
        domain = c(0, 1)
      ) %>%
      tab_footnote(
        footnote = md("Purple indicates failure to achieve adequate *Power*."),
        locations = cells_column_labels(columns = "Power")
      )
  }
  return(gt_table)
}

```

### Render Heat maps

**Heatmap forÂ `.200, Equal Proportions`:**

```{r, eval=TRUE}
#| label: "heatmap-0.2-equal-save"
#| echo: true
#| message: false
#| warning: false

subset_02_table_even_proportions <- create_table(subset_0.2_even_proportions, ".200, Even Mixing Proportions")

subset_02_table_even_proportions

subset_02_table_even_proportions |> tab_options(table.width = pct(55)) |> gtsave(here('Simulations', 'STUDY_2', 'zHeatmaps', 'z2t_lta_rilta_tables', '2T_L_R_.200_Even Proportions.png'), expand = 8)
```

Heatmap forÂ `.200, Unequal Proportions`:

```{r, eval=TRUE}
#| label: "heatmap-0.2-unequal-save"
#| echo: true
#| message: false
#| warning: false

# Heatmap for .200, Unequal Proportions
subset_0.2_table_uneven_proportions <- create_table(subset_0.2_uneven_proportions, ".200, Uneven Mixing Proportions")

subset_0.2_table_uneven_proportions

subset_0.2_table_uneven_proportions |> tab_options(table.width = pct(55)) |> gtsave(here('Simulations', 'STUDY_2', 'zHeatmaps', 'z2t_lta_rilta_tables','2T_L_R_.200_Uneven Proportions.png'), expand = 8)
```

Heatmap forÂ `.800, Equal Proportions`:

```{r, eval=TRUE}
#| label: "heatmap-0.8-equal-save"
#| echo: true
#| message: false
#| warning: false

# Heatmap for .800, Equal Proportions
subset_0.8_table_even_proportions <- create_table(subset_0.8_even_proportions, ".800, Even Mixing Proportions")

subset_0.8_table_even_proportions

subset_0.8_table_even_proportions |> tab_options(table.width = pct(55)) |> gtsave(here('Simulations', 'STUDY_2', 'zHeatmaps', 'z2t_lta_rilta_tables', '2T_L_R_.800_Even Proportions.png'), expand = 8)
```

Heatmap forÂ `.800, Unequal Proportions`:

```{r, eval=TRUE}
#| label: "heatmap-0.8-unequal-save"
#| echo: true
#| message: false
#| warning: false

# Heatmap for .800, Unequal Proportions
subset_0.8_table_uneven_proportions <- create_table(subset_0.8_uneven_proportions, ".800, Uneven Mixing Proportions")

subset_0.8_table_uneven_proportions

subset_0.8_table_uneven_proportions |> tab_options(table.width = pct(55)) |> gtsave(here('Simulations', 'STUDY_2', 'zHeatmaps', 'z2t_lta_rilta_tables', '2T_L_R_.800_Uneven Proportions.png'), expand = 8)
```
